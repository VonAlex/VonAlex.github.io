<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/images/dolphin.png"><link rel="icon" type="image/png" href="/images/dolphin.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="Happen"><meta name="keywords" content=""><title>Redis 源码分析之数据迁移 (1) - Happen&#39;s Memo</title><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css"><link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"><link rel="stylesheet" href="/css/main.css"><link defer="defer" rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/custom.css"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"> <a class="navbar-brand" href="/">&nbsp;<strong>Happen's Memo</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"> <a class="nav-link" href="/">首页</a></li><li class="nav-item"> <a class="nav-link" href="/archives/">归档</a></li><li class="nav-item"> <a class="nav-link" href="/categories/">分类</a></li><li class="nav-item"> <a class="nav-link" href="/tags/">标签</a></li><li class="nav-item"> <a class="nav-link" href="/about/">关于</a></li><li class="nav-item" id="search-btn"> <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a></li></ul></div></div></nav><div class="view intro-2" id="background" parallax="true" style="background:url(/images/about-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask rgba-black-light flex-center"><div class="container text-center white-text fadeInUp"><span class="h2" id="subtitle"></span><p class="mt-3 post-meta"><i class="fas fa-calendar-alt" aria-hidden="true"></i> 2020/04/02, 星期四, 18:11</p><p class="mt-1"><span class="post-meta"><i class="far fa-chart-bar"></i> 5k 字</span><span class="post-meta"><i class="far fa-clock"></i> 21 分钟</span><span id="busuanzi_container_page_pv" class="post-meta" style="display:none"><i class="far fa-eye" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span> 次</span></p></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5 z-depth-3" id="board"><div class="post-content mx-auto" id="post"><p class="note note-warning">本文最后更新于：2020/04/03, 星期五, 02:47</p><div class="markdown-body"><p>redis 中的数据迁移是以 key 为单位的，整个迁移过程由一系列命令组成，在官方提供的 ruby 实现的 trib 工具中对整个过程进行了包装串联，在更新的版本的 redis 中，已经将这些逻辑移植到了 redis-cli 中，使用 C 进行了重写。下面进行分步详细讲解。</p><a id="more"></a><h2 id="标记 -importing">标记 importing</h2><p>在 <strong>目的节点</strong> B 执行命令 <code>SETSLOT 10 IMPORTING &lt;A 的 nodeID&gt;</code>，标记有一个 slot (10) 将要从源节点 A 迁入到本节点 B。<br> 此时，在 B 上使用 <code>cluster nodes</code> 命令查看集群路由现状，可以发现，在 B 负责的 slot 信息里有这样的标记<code>[10-&lt;-A nodeid]</code>。（其他节点不知道这件事）</p><p>具体代码执行逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {
    .....
    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;setslot&quot;) &amp;&amp; c-&gt;argc &gt;= 4) {
        .....
        else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;importing&quot;) &amp;&amp; c-&gt;argc == 5) {if (server.cluster-&gt;slots[slot] == myself) {addReplyErrorFormat(c, &quot;I'm already the owner of hash slot %u&quot;,slot);
                return;
            }
            if ((n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr)) == NULL) {addReplyErrorFormat(c,&quot;I don't know about node %s&quot;, (char*)c-&gt;argv[3]-&gt;ptr);
                return;
            }
            server.cluster-&gt;importing_slots_from[slot] = n;
        }
        .....
    }
    .....
}
</code></pre><p>当接收到 <code>setslot</code> 命令时，匹配到关于设置 slot importing 状态的逻辑。</p><p>首先是一些参数的校验。</p><ul><li>检查 slot x 是不是已经属于我了，如果是，那么报错 <strong>I’m already the owner of hash slot x</strong>。（slot x 已经是我的了，不需要再迁给我）</li><li>检查源节点我是否认识，如果不认识的话，报错 <strong>I don’t know about node</strong>。（不认识源节点，我从哪儿迁入呢？）</li></ul><p>然后，修改 <code>server.cluster</code> 结构体的相应变量，表示已经记下了。</p><p>在每个 cluster 节点中，都有一个 <code>clusterState</code> 结构体，用来保存集群信息，其中 <code>importing_slots_from</code> 变量表示要迁入本节点的 slot 信息，而 <code>migrating_slots_to</code> 变量表示要迁出本节点的 slot 信息，它们都是 16384 长度的数组。</p><h2 id="标记 -migrating">标记 migrating</h2><p>在源节点 A 执行命令 <code>SETSLOT 10 MIGRATING &lt;B 的 nodeID&gt;</code>，标记有一个 slot (10) 将要从本节点 A 迁出到目标节点 B。<br> 此时，在 A 上使用 <code>cluster nodes</code> 命令查看集群路由现状，可以发现，在 A 负责的 slot 信息里有这样的标记<code>[10-&gt;-B nodeid]</code>。（其他节点不知道这件事）</p><p>具体代码执行逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {
    ....
    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;setslot&quot;) &amp;&amp; c-&gt;argc &gt;= 4) {
        ....
          if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;migrating&quot;) &amp;&amp; c-&gt;argc == 5) {addReplyErrorFormat(c,&quot;I'm not the owner of hash slot %u&quot;,slot);
                return;
            }
            if ((n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr)) == NULL) {addReplyErrorFormat(c,&quot;I don't know about node %s&quot;, (char*)c-&gt;argv[4]-&gt;ptr);
                return;
            }
            server.cluster-&gt;migrating_slots_to[slot] = n; // 标记 slot 的目的地
        }
        ....
    }
    .....
}
</code></pre><p>当接收到 <code>setslot</code> 命令时，匹配到关于设置 slot migrating 状态的逻辑。<br> 首先是一些参数的校验。</p><ul><li>检查 slot x 是不是我负责的，如果不是，报错 <strong>I’m not the owner of hash slot x</strong>。（不是我负责的 slot，我无权迁出）</li><li>检查目的节点我是否认识，如果不认识的话，报错 <strong>I don’t know about node</strong>。（不认识目的节点，我怎么迁出？）</li></ul><p>然后，修改 <code>server.cluster</code> 结构体相应变量，表示已经记下了。</p><p class="note note-warning"> 应该先在迁入节点标记 slot 的 importing 状态，后在迁出节点标记 slot 的 migrating 状态。若颠倒顺序的话，会有一些问题。<br><br> 假设这样的场景，在迁出节点设置了 slot 的 migrating 状态。之后访问迁出节点 slot 的写命令，会被重定向到迁入节点（没有 key 就会重定向），但是此时迁入节点 slot 还没有做标记，所以又会产出一个 MOVED 错误，如此循环往复。说到底还是因为这些命令的执行是分开的，而非原子的。</p><h2 id="源节点从 -slot- 中取 -key">源节点从 slot 中取 key</h2><p>经过前面两步，将要迁移的 slot 在源节点和目的节点都进行的标记。 现有的 redis cluster 中数据迁移的基本单位是 key，因此要先取出要迁移的一部分 key，有 <code>GETKEYSINSLOT</code> 命令可以使用，全格式为 <code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>。</p><p>具体代码逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {
    ......
    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;getkeysinslot&quot;) &amp;&amp; c-&gt;argc == 4) {
        /* CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt; */
        long long maxkeys, slot;
        unsigned int numkeys, j;
        robj **keys;
        if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;slot,NULL) != C_OK)
            return;
        if (getLongLongFromObjectOrReply(c,c-&gt;argv[3],&amp;maxkeys,NULL)
            != C_OK)
            return;
        if (slot &lt; 0 || slot &gt;= CLUSTER_SLOTS || maxkeys &lt; 0) {addReplyError(c,&quot;Invalid slot or number of keys&quot;);
            return;
        }

        keys = zmalloc(sizeof(robj*)*maxkeys);
        numkeys = getKeysInSlot(slot, keys, maxkeys);
        addReplyMultiBulkLen(c,numkeys);
        for (j = 0; j &lt; numkeys; j++) addReplyBulk(c,keys[j]);
        zfree(keys);
    }
    .....
}
</code></pre><p>首先，解析参数，</p><ul><li><p>从哪个 slot 取数据？存到变量 slot 中。</p></li><li><p>这一次取多少个 key？存到变量 maxkeys 中。</p></li></ul><p>然后，分配内存，使用 <code>getKeysInSlot</code> 函数从跳表 <code>server.cluster-&gt;slots_to_keys</code> 中取出 slot x 里最多 maxkeys 个 key，存入数组 keys 中，<code>getKeysInSlot</code> 函数返回实际取得的 key 的数量。<br> 最后，响应客户端 OK，并释放内存。</p><h2 id="migrate-keys- 过程">migrate keys 过程</h2><h3 id="源节点处理">源节点处理</h3><p>使用上一步取出来的 key，使用 <code>MIGRATE</code> 命令进行 key 的搬迁。</p><pre><code class="language-c">MIGRATE host port &quot;&quot; dbid timeout [COPY | REPLACE] KEYS key1 key2 ... keyN
</code></pre><p>正常流程中，将 key 搬迁到目标节点以后，会其从源节点删除掉，但是命令中的 <strong>COPY</strong> 和 <strong>REPLACE</strong> 选项会使得此过程有不同的表现。</p><ul><li><p>COPY ：目的节点如果已经存在要搬迁的 key，会报错。且 key 搬迁完成后，源节点也不会删掉这个 key。</p></li><li><p>REPLACE：不管目的节点是否存在要迁移的 key，都覆盖它。</p></li><li><p>两个选项都不要。目的节点如果已经存在要搬迁的 key，会报错。</p></li></ul><h4 id="一些初始化">一些初始化</h4><p><code>MIGRATE</code> 命令使用函数 <code>migrateCommand</code> 进行处理。</p><p>首先，进行一些参数校验以及变量的初始化。<br> 如果 timeout 选项解析出来 &lt;=0，那么设置为默认值 1s。timeout 值用来做建链接接超时，以及后面的读写超时。<br> 将要迁移的 key 保存到数组 kv 中，相应的 value 保存到数组 ov 中 ，代码如下，</p><pre><code class="language-c">ov = zrealloc(ov,sizeof(robj*)*num_keys);
kv = zrealloc(kv,sizeof(robj*)*num_keys);
int oi = 0;
for (j = 0; j &lt; num_keys; j++) {if ((ov[oi] = lookupKeyRead(c-&gt;db,c-&gt;argv[first_key+j])) != NULL) {kv[oi] = c-&gt;argv[first_key+j];
        oi++;
    }
}
num_keys = oi;
if (num_keys == 0) {zfree(ov); zfree(kv);
    addReplySds(c,sdsnew(&quot;+NOKEY\r\n&quot;));
    return;
}
</code></pre><p class="note note-warning"> 由于 key 的过期或者主从删除等原因，这里的 oi 的值很可能跟 num_keys 是不一致的，如果 key 都没有了，也就是不用再迁移了，那么返回信息 +NOKEY。</p><h4 id="建立连接">建立连接</h4><p>然后，跟要迁入 key 的目的节点建立连接。代码如下，</p><pre><code class="language-c">/* Connect */
cs = migrateGetSocket(c,c-&gt;argv[1],c-&gt;argv[2],timeout);
if (cs == NULL) {zfree(ov); zfree(kv);
    return; /* error sent to the client by migrateGetSocket() */}
</code></pre><p>可以看到，代码中根据命令参数 host 和 port 使用 <code>migrateGetSocket</code> 函数可拿到一个可用的连接，该函数逻辑可以参考附录。</p><h4 id="填充 -cmd- 信息">填充 cmd 信息</h4><p>拿到可用的连接后，接着就需要将要搬迁的 key 以 <strong>redis 协议的格式</strong> 发送到目的节点，具体格式如下，</p><pre><code class="language-c">*4\r\n (或 *5\r\n)
$14\r\nRESTORE-ASKING\r\n (或 $7\r\nRESTORE\r\n)
$&lt;count&gt;\r\n&lt;payload&gt;\r\n (key 信息)
$&lt;count&gt;\r\n&lt;payload&gt;\r\n (ttl 信息)
$&lt;count&gt;\r\n&lt;payload&gt;\r\n (value dump 信息)
$7\r\nREPLACE\r\n (根据情况决定是否有这个参数)
</code></pre><p>可以看到使用的是 <code>RESTORE-ASKING</code> 或者 <code>RESTORE</code> 的命令。</p><p>下面看填充 cmd 的具体代码分析。</p><pre><code class="language-c">rio cmd, payload;
rioInitWithBuffer(&amp;cmd,sdsempty());
</code></pre><p>首先，使用 <code>rio</code> 类型的变量 cmd 存放要发给目的节点的 redis 协议格式的命令，下面就开始使用要迁移的 key/value 组装数据。<br> 看下是否需要切换数据库，有必要的话，强制发 <code>SELECT &lt;dbid&gt;</code> 。</p><pre><code class="language-c">int select = cs-&gt;last_dbid != dbid; /* Should we emit SELECT? */
if (select) {serverAssertWithInfo(c,NULL,rioWriteBulkCount(&amp;cmd,'*',2));
    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;SELECT&quot;,6));
    serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,dbid));
}
</code></pre><p>下面是针对每一个 key 进行的处理，具体代码如下，</p><pre><code class="language-c">long long ttl = 0;
long long expireat = getExpire(c-&gt;db,kv[j]);
if (expireat != -1) {ttl = expireat-mstime();
    if (ttl &lt; 1) ttl = 1;
}
</code></pre><p>首先将 key 的过期时间从绝对时间转成相对时间，记录在 ttl 中。<br> 根据前面命令传入的选项是 replace 还是 copy，决定发送命令的参数个数。</p><pre><code class="language-c">serverAssertWithInfo(c,NULL,rioWriteBulkCount(&amp;cmd,'*',replace ? 5 : 4));
</code></pre><pre><code class="language-c">if (server.cluster_enabled)
    serverAssertWithInfo(c,NULL,
                rioWriteBulkString(&amp;cmd,&quot;RESTORE-ASKING&quot;,14));
else
    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;RESTORE&quot;,7));
</code></pre><p>如果当前处于集群模式下，则向 cmd 中填充 <code>RESTORE-ASKING</code> 命令，否则填充 <code>RESTORE</code> 命令。<br> 然后，对每个 key 的信息进行填充，</p><pre><code class="language-c">// 填充 key 的信息
serverAssertWithInfo(c,NULL,sdsEncodedObject(kv[j]));
serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,kv[j]-&gt;ptr,
                sdslen(kv[j]-&gt;ptr)));

// 填充 ttl 信息
serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,ttl));

// 填充 value 的信息
createDumpPayload(&amp;payload,ov[j]);
serverAssertWithInfo(c,NULL,
rioWriteBulkString(&amp;cmd,payload.io.buffer.ptr,
    sdslen(payload.io.buffer.ptr)));
sdsfree(payload.io.buffer.ptr);
</code></pre><p>value 的值，要使用 <code>createDumpPayload</code> 函数进行 rdb 序列化，具体格式如下，</p><pre><code class="language-c">/* Write the footer, this is how it looks like:
 * ----------------+---------------------+---------------+
 * ... RDB payload | 2 bytes RDB version | 8 bytes CRC64 |
 * ----------------+---------------------+---------------+
 * RDB version and CRC are both in little endian.
 */
</code></pre><p>序列化过程在函数 <code>createDumpPayload</code> 中，在此就不做分析了。<br> 最后根据 replace 变量，决定是否要填充 <strong>REPLACE</strong>，即，</p><pre><code class="language-c">if (replace)
    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;REPLACE&quot;,7));
</code></pre><p>这样，所有要迁移的 key 也就序列化到 cmd 这个 <code>rio</code> 变量里了。下面就要发给目的节点了。</p><h4 id="发送到目的节点">发送到目的节点</h4><p>组装完 cmd，就要把它们发送到对端，代码逻辑如下，</p><pre><code class="language-c">sds buf = cmd.io.buffer.ptr;
size_t pos = 0, towrite;
int nwritten = 0;
while ((towrite = sdslen(buf)-pos) &gt; 0) {towrite = (towrite &gt; (64*1024) ? (64*1024) : towrite);
    nwritten = syncWrite(cs-&gt;fd,buf+pos,towrite,timeout);
    if (nwritten != (signed)towrite) {
        write_error = 1;
        goto socket_err;
     }
     pos += nwritten;
}
</code></pre><p>循环调用 <code>syncWrite</code> 函数，向远端 Redis <strong>同步</strong> 发送 cmd 中的内容，每次最多发送 <strong>64k</strong> 个字节。</p><h4 id="对目的节点回复的处理">对目的节点回复的处理</h4><p>定义两个变量，接收对端的回复。</p><pre><code class="language-c">char buf1[1024]; /* Select reply. */
char buf2[1024]; /* Restore reply. */
</code></pre><pre><code class="language-c">// 如果前面发送了 select 命令，那么需要先读取此命令的回复
if (select &amp;&amp; syncReadLine(cs-&gt;fd, buf1, sizeof(buf1), timeout) &lt;= 0)
    goto socket_err;
</code></pre><p>下面同步读取每一个 restore key 的返回值，具体逻辑如下，</p><pre><code class="language-c">if (syncReadLine(cs-&gt;fd, buf2, sizeof(buf2), timeout) &lt;= 0) {
     socket_error = 1;
     break;
}

if ((select &amp;&amp; buf1[0] == '-') || buf2[0] == '-') {
    /* On error assume that last_dbid is no longer valid. */
   if (!error_from_target) {
       cs-&gt;last_dbid = -1;
       addReplyErrorFormat(c,&quot;Target instance replied with error: %s&quot;,
           (select &amp;&amp; buf1[0] == '-') ? buf1+1 : buf2+1);
       error_from_target = 1;
   }
} else {if (!copy) {
        /* No COPY option: remove the local key, signal the change. */
        dbDelete(c-&gt;db,kv[j]);
        signalModifiedKey(c-&gt;db,kv[j]);
        server.dirty++;
        /* Populate the argument vector to replace the old one. */
         newargv[del_idx++] = kv[j];
         incrRefCount(kv[j]);
    }
}
</code></pre><p>首先将对端回复读取变量 <strong>buf2</strong> 里。<br> 如果 <strong>buf1</strong> 或者 <strong>buf2</strong> 首字母是字符 <code>-</code>，说明遇到了错误，那么将连接中的 <code>last_dbid</code> 置为 -1，这样下次再使用时，会强制发送 <code>SELECT</code> 命令。<br> 如果 <code>MIGRATE</code> 命令中没有使用 <strong>COPY</strong> 选项，那么需要将搬迁到目标节点的 key 从本地删除掉。同时记录在数组 <code>newargv</code> 中，<strong>以方便后面修改命令，传播到副本中</strong>。</p><p>具体逻辑如下，</p><pre><code class="language-c">if (!copy) {if (del_idx &gt; 1) {newargv[0] = createStringObject(&quot;DEL&quot;,3);
        replaceClientCommandVector(c,del_idx,newargv);
        argv_rewritten = 1;
    } else {zfree(newargv);
    }
   newargv = NULL;
}
</code></pre><p>将 <code>MIGRATE</code> 命令改成 <code>DEL</code> 命令。</p><h4 id="回复 -client- 与错误处理">回复 client 与错误处理</h4><pre><code class="language-c">if (socket_error) migrateCloseSocket(c-&gt;argv[1],c-&gt;argv[2]);
if (!copy) {....}
</code></pre><p><code>socket_error</code> 在同步读取对端回复时，有可能遇到。当发生这个错误时，直接关掉这个 socket。</p><p class="note note-warning"> 这里并没有返回，这是因为，对于已经迁移成功的 key，后面还是要做命令转换的，因此不能直接返回。</p><p>如果没有发生错误，就可以给 client 正确的回复了。</p><pre><code class="language-c">if (!error_from_target) {
    cs-&gt;last_dbid = dbid;
    addReply(c,shared.ok);
} else {
}
</code></pre><p>成功了，更改连接中的 <code>last_dbid</code> 为本次使用的 dbid，留着下一次用，避免下次再发送 <code>SELECT</code> 命令。<br> 如果写命令或者读回复发生错误，而且若 <strong>不是超时错误</strong> 的话，那么可以重试一次。</p><pre><code class="language-c">if (errno != ETIMEDOUT &amp;&amp; may_retry) {
    may_retry = 0;
    goto try_again;
}
</code></pre><p><strong>try_again</strong> 会跳到前面重新填 cmd，再来一遍，否则会回复 client 错误。</p><pre><code class="language-c">addReplySds(c, sdscatprintf(sdsempty(),
    &quot;-IOERR error or timeout %s to target instance\r\n&quot;,
    write_error ? &quot;writing&quot; : &quot;reading&quot;));
</code></pre><p class="note note-danger"> 从上面的分析，<br><br> 为了避免同一个 key 出现在两个节点中，在源节点上，涉及到向目标节点建链、发送命令和等待回复的过程，都是同步的。如果遇到大 key，那么搬迁时间会比较长，此时会堵塞住进来请求的 client，甚至有可能触发 failover。<br><br> 所以，不建议一次性搬移过多的 key，而且要提前解决掉 大 key 的问题。<br><br> 目前业界已经有以主从复制的思路，以 slot 为单位进行数据搬迁了，能很好解决大 key 问题。</p><h3 id="目的节点的处理">目的节点的处理</h3><p>对端接收到 <code>RESTORE-ASKING</code> 或 <code>RESTORE</code> 命令后，使用函数 <code>restoreCommand</code> 进行逻辑处理。<br> 首先检查第 4 个参数是否为 replace。</p><pre><code class="language-c">for (j = 4; j &lt; c-&gt;argc; j++) {if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;replace&quot;)) {replace = 1;} else {addReply(c,shared.syntaxerr);
         return;
    }
}
</code></pre><p><strong>如果有</strong> 第 4 个参数，那么一定是 replace ，否则就报语法错误 <strong>-ERR syntax error</strong>。当然也有可能没有，这时 replace = 0。<br> 如果 replace = 0，且当前数据库中已经有个这个 key，报错 <strong>-BUSYKEY Target key name already exists</strong><br> 取出 ttl 信息，且它一定是个 &gt; 0 的数值。</p><pre><code class="language-c">if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;ttl,NULL) != C_OK) {return;} else if (ttl &lt; 0) {addReplyError(c,&quot;Invalid TTL value, must be &gt;= 0&quot;);
    return;
}
</code></pre><p>接着解析第 3 个参数，应该是 value 的 dump 信息了。</p><pre><code class="language-c">/* Verify RDB version and data checksum. */
if (verifyDumpPayload(c-&gt;argv[3]-&gt;ptr,sdslen(c-&gt;argv[3]-&gt;ptr)) == C_ERR) {addReplyError(c,&quot;DUMP payload version or checksum are wrong&quot;);
    return;
}

rioInitWithBuffer(&amp;payload,c-&gt;argv[3]-&gt;ptr);
if (((type = rdbLoadObjectType(&amp;payload)) == -1) ||
    ((obj = rdbLoadObject(type,&amp;payload)) == NULL)) {addReplyError(c,&quot;Bad data format&quot;);
    return;
}
</code></pre><p>先校验一下这个 dump 信息是否符合规范，然后分别使用 <code>rdbLoadObjectType</code> 函数和 <code>rdbLoadObject</code> 函数，将 type 和 obj 还原。<br> 接着对本地数据库进行处理，代码如下，</p><pre><code class="language-c">if (replace) dbDelete(c-&gt;db,c-&gt;argv[1]);

/* Create the key and set the TTL if any */
dbAdd(c-&gt;db,c-&gt;argv[1],obj);

if (ttl) setExpire(c-&gt;db,c-&gt;argv[1],mstime()+ttl);
signalModifiedKey(c-&gt;db,c-&gt;argv[1]);
addReply(c,shared.ok);
server.dirty++;
</code></pre><p>如果有 replace，就要从本地删除原来的 key，使用从源节点传过来的值进行覆盖。<br> 有 ttl 的话，再设置一下过期时间。<br> 最后，回复客户端 &quot;OK&quot; 信息；</p><p><strong>以上，就完成了一个 key 的迁移过程。</strong></p><h2 id="设置 -slot- 最终归属">设置 slot 最终归属</h2><p>当 slot 中的 key 全部搬迁完之后，<br> 使用 <code>CLUSTER SETSLOT &lt;SLOT&gt; NODE &lt;NODE ID&gt;</code> 命令设置 slot。</p><p>先在目标节点设置，消除 importing 标记。<br> 再在源节点设置， 消除 migrating 标记。</p><p>为了让整个集群都感知到新的 slot 归属，可以给集群其他节点都发一遍，当然了，也可以等着 gossip 消息，但是在大集群中扩散过程就比较慢了。</p><p class="note note-warning"> 注意上面的顺序!!<br><br> 如果先取消到 migrating 标记，且还没有取消 importing 标记，那么迁出节点会认为这个 slot 属于迁入节点了，所以读写访问时，会 MOVED 到迁入节点，但是在迁入节点来看这个节点不属于自己，且没有 ASK 重定向，所以会重新 MOVED 到迁出节点。所以产生一个 pingpong 的过程。<br><br> 而按照上面的顺序的话，如果有访问到正在迁出的 slot，那么会 ASK 重定向到迁入节点，在迁入节点看来，这个 slot 是属于自己的，正常处理，不会发生错误。</p><p class="note note-primary"> 这个顺序跟开始迁移时是一致的，先处理迁入节点，再处理迁出节点。</p><p>下面看这个命令的实际处理过程，部分代码如下，</p><pre><code class="language-c">else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;node&quot;) &amp;&amp; c-&gt;argc == 5) {clusterNode *n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr);
    if (!n) {addReplyErrorFormat(c,&quot;Unknown node %s&quot;, (char*)c-&gt;argv[4]-&gt;ptr);
        return;
    }
    ...
}
</code></pre><pre><code class="language-c">if (server.cluster-&gt;slots[slot] == myself &amp;&amp; n != myself) {if (countKeysInSlot(slot) != 0) {
        addReplyErrorFormat(c,
            &quot;Can't assign hashslot %d to a different node &quot;
             &quot;while I still hold keys for this hash slot.&quot;, slot);
        return;
     }
}
</code></pre><p>首先还是一些参数校验。</p><ul><li><p>参数传入的 node 我是否认识，不认识的话，报错退出。</p></li><li><p>参数传入的 slot 是我负责的，且 node 是别人。这时就要看下，这个 slot 里的 key 是否已经全部搬迁完了，如果不是，那么报错。（key 都没有迁完，怎么能把 slot 给别人呢？会丢数据的）。如果 slot 不是我的，那么我就抱着看热闹的心态，跳过这个检查就好了。</p></li></ul><p>下面就是 slot 状态的消除了，主要代码如下，</p><pre><code class="language-c"> if (countKeysInSlot(slot) == 0 &amp;&amp;
     server.cluster-&gt;migrating_slots_to[slot])
     server.cluster-&gt;migrating_slots_to[slot] = NULL;
</code></pre><p>如果 slot 中没有 key，并且处于 <strong>migrating</strong> 状态（也就说这是针对源节点的操作），那么把迁出状态取消。<br> 接下来，对于 <strong>importing</strong> 状态的目标节点，发布最新的路由，代码如下，</p><pre><code class="language-c">if (n == myself &amp;&amp; server.cluster-&gt;importing_slots_from[slot]){if (clusterBumpConfigEpochWithoutConsensus() == C_OK) {serverLog(LL_WARNING, &quot;configEpoch updated after importing slot %d&quot;, slot);
    }
    server.cluster-&gt;importing_slots_from[slot] = NULL;
}
</code></pre><p>使用 <code>clusterBumpConfigEpochWithoutConsensus</code> 函数，<strong>自行增加自己的 config epoch 值</strong>。</p><p>本函数违反了 config epochs 应经过集群达成共识后产生，且在整个 cluster 内是唯一的。<br> 然而 Redis Cluster 在以下两种情况下使用自动生成的新 config epochs：</p><ul><li><p>当 slots 在 importing 后关闭。否则，resharding 的代价太昂贵。</p></li><li><p>当 CLUSTER FAILOVER 强制一个 slave failover 的选项调用时，即使没有大多数 master 同意也要产生一个新的 epoch。</p></li></ul><p>如果本节点的 config epoch 值不是集群中最大的，那么会取到最大的，然后 +1，作为现在的 config epoch 和 current epoch。<br> 最后变更路由，代码如下，</p><pre><code class="language-c">clusterDelSlot(slot);
clusterAddSlot(n,slot);
</code></pre><p><strong>至此，就把完成了一个完整的迁移流程</strong>。</p><h2 id="附录">附录</h2><h3 id="migrateGetSocket- 函数分析">migrateGetSocket 函数分析</h3><p>主要代码如下，</p><pre><code class="language-c">migrateCachedSocket* migrateGetSocket(client *c, robj *host, robj *port, long timeout) {
    ...
    cs = dictFetchValue(server.migrate_cached_sockets,name);
    if (cs) {sdsfree(name);
        cs-&gt;last_use_time = server.unixtime;
        return cs;
    }
    /* No cached socket, create one. */
    if (dictSize(server.migrate_cached_sockets) == MIGRATE_SOCKET_CACHE_ITEMS) {
        /* Too many items, drop one at random. */
        dictEntry *de = dictGetRandomKey(server.migrate_cached_sockets);
        cs = dictGetVal(de);
        close(cs-&gt;fd);
        zfree(cs);
        dictDelete(server.migrate_cached_sockets,dictGetKey(de));
    }
    fd = anetTcpNonBlockConnect(server.neterr, c-&gt;argv[1]-&gt;ptr, atoi(c-&gt;argv[2]-&gt;ptr));
    ...
    anetEnableTcpNoDelay(server.neterr,fd);
   /* Check if it connects within the specified timeout. */
    if ((aeWait(fd,AE_WRITABLE,timeout) &amp; AE_WRITABLE) == 0) {sdsfree(name);
        addReplySds(c,
            sdsnew(&quot;-IOERR error or timeout connecting to the client\r\n&quot;));
        close(fd);
        return NULL;
    }

    /* Add to the cache and return it to the caller. */
    cs = zmalloc(sizeof(*cs));
    cs-&gt;fd = fd;
    cs-&gt;last_dbid = -1;
    cs-&gt;last_use_time = server.unixtime;
    dictAdd(server.migrate_cached_sockets,name,cs);
 }
</code></pre><p>通过以上代码可以看到，对于连接过程中的 socket fd 封装到结构体 <code>migrateCachedSocket</code>，存入 <code>server.migrate_cached_sockets</code> 这个 dict 中。</p><pre><code class="language-c">typedef struct migrateCachedSocket {
   int fd;
   long last_dbid;
   time_t last_use_time;
} migrateCachedSocket;
</code></pre><p><code>migrateCachedSocket</code> 结构体包含 socket fd，上一次迁移数据用到的 db，以及连接上一次使用的时间 <code>last_use_time</code>。<br> 将 socket 缓存下来的目的是，当要迁移的 key 很多时，一次 migrate 命令是迁不完的，缓存下来 socket 可以减少创建成本。</p><p><code>last_use_time</code> 变量存在的意义是，为了节省资源，缓存的连接需要做定期清理，该逻辑在函数 <code>migrateCloseTimedoutSockets</code> 中，如果一个连接 <strong>10 s</strong> 未使用，就把它 close 掉。</p><p><code>last_dbid</code> 的作用是，强制发送 <code>SELECT</code> 命令，以切换数据库。</p><p>当缓存的连接数量足够多时，会随机剔除一个，以容纳新的连接。</p><p>然后，设置 fd 为非阻塞式的，在给定时间内，看一下是否连接成功了。成功后返回一个 <code>migrateCachedSocket</code> 类型的变量，并放到 <code>migrate_cached_sockets</code> 中缓存起来。</p></div><hr><div><p><span><i class="iconfont icon-inbox"></i> <a class="hover-with-bg" href="/categories/%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/">源码系列</a> &nbsp;</span> &nbsp;&nbsp;<span><i class="iconfont icon-tag"></i> <a class="hover-with-bg" href="/tags/redis/">redis</a></span></p><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p><div class="post-prevnext row"><div class="post-prev col-6"><a href="/badab03c.html"><i class="fa fa-chevron-left"></i> <span class="hidden-mobile">Redis 源码分析之数据迁移 (2)</span> <span class="visible-mobile">上一篇</span></a></div><div class="post-next col-6"> <a href="/9025979a.html"><span class="hidden-mobile">Redis 源码之主从复制 (4)</span> <span class="visible-mobile">下一篇</span><i class="fa fa-chevron-right"></i></a></div></div></div><div class="comments" id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC8zNjg1MS8xMzM4Nw"><script type="text/javascript">!function(e,t){var r,n=e.getElementsByTagName(t)[0];"function"!=typeof LivereTower&&((r=e.createElement(t)).src="https://cdn-city.livere.com/js/embed.dist.js",r.defer=!0,n.parentNode.insertBefore(r,n))}(document,"script")</script><noscript> 为正常使用来必力评论功能请激活JavaScript</noscript></div></div></div></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc-start"></div><div id="toc"><p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div><div class="col-lg-7 mx-auto nopadding-md"><div class="container custom post-content mx-auto"> <img src="https://octodex.github.com/images/jetpacktocat.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-5" style="width:150px;height:150px"></div></div></main><a class="z-depth-1" id="scroll-top-button" href="#" role="button"><i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4> <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"> <span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"> <input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><footer class="mt-5"><div class="text-center py-3"><div> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a><i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><b>Fluid</b></a></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js"></script><script>$(document).ready(function(){var s=$("#navbar").height(),c=$("#toc"),t=$("#board-ctn"),o=t.offset().top,i=2*o+t.height();$(window).scroll(function(){var t=$("#toc-start").offset().top-s,o=document.body.scrollTop+document.documentElement.scrollTop;t<=o&&o<=i?c.css({display:"block",position:"fixed",top:s}):o<=t?c.css({position:"",top:""}):i<o&&c.css("display","none")}),tocbot.init({tocSelector:"#tocbot",contentSelector:".post-content",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,headingsOffset:-o}),0<$(".toc-list-item").length&&$("#toc > p").css("visibility","visible");var l=t.css("margin-right");$("#toc-ctn").css({right:l})})</script><script defer="defer" src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer="defer" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script defer="defer">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?882b48640075e00a238ae94a7eec0d40";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script defer="defer">var _mtac={};!function(){var t=document.createElement("script");t.src="//pingjs.qq.com/h5/stats.js?v2.0.4",t.setAttribute("name","MTAH5"),t.setAttribute("sid","");var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js"></script><script>$(document).ready(function(){$("pre").addClass("prettyprint  "),prettyPrint()})</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","Redis 源码分析之数据迁移 (1)&nbsp;"],cursorChar:"_",typeSpeed:75,loop:!1});typed.stop(),$(document).ready(function(){$(".typed-cursor").addClass("h2"),typed.start()})</script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){getSearchFile(path),this.onclick=null}</script><script defer="defer" src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><script>$("#post img:not(.no-zoom img, img[no-zoom])").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script></body></html>