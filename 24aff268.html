<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="Scrapy Demo"><meta name="keywords" content="爬虫"><meta name="author" content="Happen"><meta name="copyright" content="Happen"><title>Scrapy Demo | Happen's Memo</title><link rel="shortcut icon" href="/images/dolphin.png"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?882b48640075e00a238ae94a7eec0d40";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>!function(e,a,t,n,c,g,o){e.GoogleAnalyticsObject=c,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,g=a.createElement(t),o=a.getElementsByTagName(t)[0],g.async=1,g.src="https://www.google-analytics.com/analytics.js",o.parentNode.insertBefore(g,o)}(window,document,"script",0,"ga"),ga("create","RRBput3V2WYVZd2lq058Z4IwJEhViOwuMElqkWh6bcA","auto"),ga("send","pageview")</script><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容:${query}"}},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"}}</script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy-是什么"><span class="toc-number">1.</span> <span class="toc-text">Scrapy 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy-架构"><span class="toc-number">2.</span> <span class="toc-text">Scrapy 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下载安装"><span class="toc-number">3.</span> <span class="toc-text">下载安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hello-World"><span class="toc-number">4.</span> <span class="toc-text">Hello World</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#创建工程"><span class="toc-number">4.1.</span> <span class="toc-text">创建工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#定义-Item"><span class="toc-number">4.2.</span> <span class="toc-text">定义 Item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写爬虫"><span class="toc-number">4.3.</span> <span class="toc-text">编写爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬取"><span class="toc-number">4.4.</span> <span class="toc-text">爬取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#保存"><span class="toc-number">4.5.</span> <span class="toc-text">保存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用的命令行工具"><span class="toc-number">5.</span> <span class="toc-text">常用的命令行工具</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/images/avatar.png"></div><div class="author-info__name text-center">Happen</div><div class="author-info__description text-center">浮生若梦，为欢几何</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">37</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">14</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">7</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="http://renrenlove.me/" target="_blank" rel="noopener">Galway</a><a class="author-info-links__name text-center" href="http://kvguru.com/" target="_blank" rel="noopener">Wangbin</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image:url(https://s2.ax1x.com/2019/11/17/Mr5txK.jpg)"><div id="page-header"> <span class="pull-left"><a id="site-name" href="/">Happen's Memo</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i> <span>搜索</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Scrapy Demo</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-04-20</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/python/">python</a><div class="post-meta-wordcount"><span>字数总计:</span> <span class="word-count">1.5k</span><span class="post-meta__separator">|</span><span>阅读时长: 5 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Scrapy-是什么"><a href="#Scrapy-是什么" class="headerlink" title="Scrapy 是什么"></a>Scrapy 是什么</h2><blockquote><p>Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取 API 所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy 用途广泛，可以用于数据挖掘、监测和自动化测试。<br>现在最新版本为 1.0，同时支持 2.7.x 和 3.x。</p></blockquote><a id="more"></a><ul><li><a href="http://scrapy.org/" target="_blank" rel="noopener">官方网站</a></li><li><a href="http://scrapy-chs.readthedocs.org/zh_CN/1.0/intro/tutorial.html" target="_blank" rel="noopener">中文版document</a></li></ul><h2 id="Scrapy-架构"><a href="#Scrapy-架构" class="headerlink" title="Scrapy 架构"></a>Scrapy 架构</h2><p>Scrapy 使用了 Twisted 异步网络库来处理网络通讯, 整体架构大致如下：</p><center><img src="https://s1.ax1x.com/2018/10/28/icwTq1.jpg" width="700"></center><p>Scrapy 主要包括了以下组件：</p><ul><li>Scrapy Engine：用来处理整个系统的数据流处理，触发事务。</li><li>Scheduler：用来接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。</li><li>Downloader：用于下载网页内容，并将网页内容返回给 Spiders。</li><li>Spiders：Spiders 是主要干活的，用它来制订特定域名或网页的解析规则。</li><li>Item Pipeline：负责处理由 Spiders 从网页中抽取的项目，它的主要任务是清晰、验证和存储数据。当页面被 Spiders 解析后，将被发送到 Item Pipeline，并经过几个特定的次序处理数据。</li><li>Downloader 中间件：位于Scrapy引擎和下载器之间的钩子框架，主要是处理 Scrapy 引擎与下载器之间的请求及响应。</li><li>Spider 中间件：介于 Scrapy引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。</li><li>Scheduler 中间件：介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。</li></ul><p>使用Scrapy可以很方便的完成网上数据的采集工作，它为我们完成了大量的工作，而不需要自己费大力气去开发。</p><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><h3 id="创建工程"><a href="#创建工程" class="headerlink" title="创建工程"></a>创建工程</h3><p>在 cmd 下切换到想创建 scrapy 项目的地方，然后使用命名</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy startproject tutorial</span><br></pre></td></tr></table></figure><p><strong>注</strong>：tutorial 为工程名<br>然后就会发现在当前位置会多出一个文件夹，名字是 tutorial。它的目录结构是这样的：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tutorial/</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    tutorial/</span><br><span class="line">        spiders/</span><br><span class="line">            __init__.py</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br></pre></td></tr></table></figure><p><strong>注</strong>：<br>scrapy.cfg 是该项目的全局配置文件<br>tutorial/: 该项目的python模块。<br>tutorial/items.py: 项目中的item文件.<br>tutorial/pipelines.py: 项目中的pipelines文件.<br>tutorial/settings.py: 项目的设置文件.<br>tutorial/spiders/: 放置spider代码的目录.</p><h3 id="定义-Item"><a href="#定义-Item" class="headerlink" title="定义 Item"></a>定义 Item</h3><p>Item 是保存爬取到的数据的容器；其使用方法和python字典类似。虽然您也可以在 Scrapy 中直接使用dict，但是 Item 提供了额外保护机制来避免拼写错误导致的未定义字段错误。<br>这里这样写</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    link = scrapy.Field()</span><br><span class="line">    desc = scrapy.Field()</span><br></pre></td></tr></table></figure><p>DmozItem 为该 Item 的名字， 该类是一个 scrapy.Item 类。<br>我这里想获取到的信息是 title、link 和 desc 这三个字段，它们都是 scrapy.Field 类型的。</p><h3 id="编写爬虫"><a href="#编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h3><p>在 <code>tutorial/spiders/</code>下创建一个 py 文件 <code>dmoz_spider.py</code>，它是这样定义的：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> tutorial.items <span class="keyword">import</span> DmozItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'dmoz'</span></span><br><span class="line">    allowed_domains = [<span class="string">'dmoz.org'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span>,</span><br><span class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        sel = Selector(response)</span><br><span class="line">        sites = sel.xpath(<span class="string">'//ul[@class="directory-url"]/li'</span>)</span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> sites:</span><br><span class="line">            item = DmozItem() <span class="comment"># 实例化一个 DmozItem 类</span></span><br><span class="line">            item[<span class="string">'title'</span>] = sel.xpath(<span class="string">'a/text()'</span>).extract()</span><br><span class="line">            item[<span class="string">'link'</span>] = sel.xpath(<span class="string">'a/@href'</span>).extract()</span><br><span class="line">            item[<span class="string">'desc'</span>] = sel.xpath(<span class="string">'text()'</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><p>爬虫类必须继承自<code>scrapy.Spider</code> 类， 且定义一些属性:</p><p><strong>name</strong>: 用于区别 Spider。 该名字必须是唯一的，不可以为不同的 Spider 设定相同的名字。<br><strong>start_urls</strong>: 包含了 Spider 在启动时进行爬取的 url 列表。 因此，第一个被获取到的页面将是其中之一， 后续的URL则从初始的URL获取到的数据中提取。<br><code>parse()</code> 是 spider 的一个方法。 被调用时，每个初始 URL 完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成 item )以及生成需要进一步处理的 URL 的 Request 对象。scrapy 为 Spider 的 start_urls 属性中的每个URL创建了 scrapy.Request 对象，并将 parse 方法作为回调函数(callback)赋值给了 Request。Request 对象经过调度，执行生成 scrapy.http.Response 对象并送回给 spider parse() 方法, 一般返回 Item 实例。</p><h3 id="爬取"><a href="#爬取" class="headerlink" title="爬取"></a>爬取</h3><p>进入该工程目录，本例中就是 tutorial/, 在命令行执行</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy crawl dmoz</span><br></pre></td></tr></table></figure><h3 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h3><p>可以使用如下命令</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy crawl dmoz -o items.json</span><br></pre></td></tr></table></figure><p>该命令是说将结果保存在 items.json 文件中。</p><h2 id="常用的命令行工具"><a href="#常用的命令行工具" class="headerlink" title="常用的命令行工具"></a>常用的命令行工具</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建项目</span><br><span class="line">scrapy startproject myproject</span><br><span class="line"># 帮助信息</span><br><span class="line">scrapy &lt;command&gt; -h</span><br><span class="line"># 帮助信息</span><br><span class="line">scrapy -h</span><br><span class="line"># 使用下载器下载指定的url，并将获取到的内容送到标准输出</span><br><span class="line">scrapy fetch &lt;url&gt;</span><br><span class="line"># 在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现</span><br><span class="line">scrapy view &lt;url&gt;</span><br><span class="line"># 以给定的URL(如果给出)或者空(没有给出URL)启动Scrapy shell</span><br><span class="line">scrapy shell [url]</span><br><span class="line">#在未创建项目的情况下，运行一个编写在Python文件中的spider</span><br><span class="line">scrapy runspider &lt;spider_file.py&gt;</span><br><span class="line"># 获取Scrapy的设定</span><br><span class="line">scrapy settings [options]</span><br><span class="line">-------------------------以上不需要项目，以下需要在项目中----------------------------------------</span><br><span class="line"># 使用 template 模版来信创建一个 spider， name 值为&lt;name&gt;, allowed_domains 值为 &lt;domain&gt;</span><br><span class="line">scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;</span><br><span class="line"># 查看可用的模版，默认有 basic、crawl、csvfeed 和 xmlfeed 4个</span><br><span class="line">scrapy genspider -l</span><br><span class="line"># 查看 TEMPLATE 信息</span><br><span class="line">scrapy genspider -d TEMPLATE</span><br><span class="line"># 使用&lt;spider&gt;进行爬取数据</span><br><span class="line">scrapy crawl &lt;spider&gt;</span><br><span class="line"># 列出当前项目中所有可用的 spider</span><br><span class="line">scrapy list</span><br><span class="line"># 运行contract检查。</span><br><span class="line">scrapy check [-l] &lt;spider&gt;</span><br><span class="line"># 获取给定的URL并使用相应的spider分析处理，可以解析成自己写的 item</span><br><span class="line">scrapy parse &lt;url&gt; [options]</span><br></pre></td></tr></table></figure></div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="social-share" data-disabled="google,facebook,qzone,twitter,diandian,linkedin,qzone,tencent"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/f49a9b8a.html"><i class="fa fa-chevron-left"></i><span>sublime text3 配置[ python 篇]</span></a></div><div class="next-post pull-right"><a href="/5e988508.html"><span>hexo + gitpages 搭建博客</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="lv-container" data-id="city" data-uid="MTAyMC8zNjg1MS8xMzM4Nw"><script>!function(e,t){var n,c=e.getElementsByTagName(t)[0];"function"!=typeof LivereTower&&((n=e.createElement(t)).src="https://cdn-city.livere.com/js/embed.dist.js",n.async=!0,c.parentNode.insertBefore(n,c))}(document,"script")</script></div></div></div><footer class="footer-bg" style="background-image:url(https://s2.ax1x.com/2019/11/17/Mr5txK.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;&nbsp;2016 - 2019 By Happen</div><div class="framework-info"><span>Powered by</span> <a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme -</span> <a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/local-search.js"></script><script>/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)&&($("#nav").addClass("is-mobile"),$("footer").addClass("is-mobile"))</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49b1f5">hexo-generator-search</a> <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>