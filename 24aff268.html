<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/images/dolphin.png"><link rel="icon" type="image/png" href="/images/dolphin.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#433d3c"><meta name="description" content=""><meta name="author" content="Happen"><meta name="keywords" content=""><title>Scrapy Demo - HappenのMemo</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/monokai.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.1.1"></head><body><header style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>HappenのMemo</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/links/"><i class="iconfont icon-link-fill"></i> 友链</a></li><li class="nav-item" id="search-btn"><a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" href="javascript:">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner intro-2" id="background" parallax="true" style="background:url(/images/about-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="container page-header text-center fade-in-up"><span class="h2" id="subtitle"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> Happen </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2016-04-20 00:05" pubdate>2016-04-20 00:05</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 1.5k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 19 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto" id="post"><h1 style="display:none">Scrapy Demo</h1><p class="note note-info">本文最后更新于：2016-04-20 00:05</p><div class="markdown-body" id="post-body"><h2 id="Scrapy- 是什么"><a href="#Scrapy- 是什么" class="headerlink" title="Scrapy 是什么"></a>Scrapy 是什么</h2><blockquote><p>Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了页面抓取 (更确切来说, 网络抓取)所设计的， 也可以应用在获取 API 所返回的数据 (例如 Amazon Associates Web Services) 或者通用的网络爬虫。Scrapy 用途广泛，可以用于数据挖掘、监测和自动化测试。<br>现在最新版本为 1.0，同时支持 2.7.x 和 3.x。</p></blockquote><a id="more"></a><ul><li><a target="_blank" rel="noopener" href="http://scrapy.org/">官方网站</a></li><li><a target="_blank" rel="noopener" href="http://scrapy-chs.readthedocs.org/zh_CN/1.0/intro/tutorial.html">中文版 document</a></li></ul><h2 id="Scrapy- 架构"><a href="#Scrapy- 架构" class="headerlink" title="Scrapy 架构"></a>Scrapy 架构</h2><p>Scrapy 使用了 Twisted 异步网络库来处理网络通讯, 整体架构大致如下：</p><center><img src="https://s1.ax1x.com/2018/10/28/icwTq1.jpg" srcset="/img/loading.gif" width="700"></center><p>Scrapy 主要包括了以下组件：</p><ul><li>Scrapy Engine：用来处理整个系统的数据流处理，触发事务。</li><li>Scheduler：用来接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。</li><li>Downloader：用于下载网页内容，并将网页内容返回给 Spiders。</li><li>Spiders：Spiders 是主要干活的，用它来制订特定域名或网页的解析规则。</li><li>Item Pipeline：负责处理由 Spiders 从网页中抽取的项目，它的主要任务是清晰、验证和存储数据。当页面被 Spiders 解析后，将被发送到 Item Pipeline，并经过几个特定的次序处理数据。</li><li>Downloader 中间件：位于 Scrapy 引擎和下载器之间的钩子框架，主要是处理 Scrapy 引擎与下载器之间的请求及响应。</li><li>Spider 中间件：介于 Scrapy 引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。</li><li>Scheduler 中间件：介于 Scrapy 引擎和调度之间的中间件，从 Scrapy 引擎发送到调度的请求和响应。</li></ul><p>使用 Scrapy 可以很方便的完成网上数据的采集工作，它为我们完成了大量的工作，而不需要自己费大力气去开发。</p><h2 id="下载安装"><a href="# 下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><div class="hljs"><pre><code class="hljs python">pip install scrapy</code></pre></div><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><h3 id="创建工程"><a href="# 创建工程" class="headerlink" title="创建工程"></a>创建工程</h3><p>在 cmd 下切换到想创建 scrapy 项目的地方，然后使用命名</p><div class="hljs"><pre><code class="hljs python">scrapy startproject tutorial</code></pre></div><p><strong>注 </strong>：tutorial 为工程名<br>然后就会发现在当前位置会多出一个文件夹，名字是 tutorial。它的目录结构是这样的：</p><div class="hljs"><pre><code class="hljs python">tutorial/
    scrapy.cfg
    tutorial/
        spiders/
            __init__.py
        __init__.py
        items.py
        pipelines.py
        settings.py</code></pre></div><p><strong>注</strong>：<br>scrapy.cfg 是该项目的全局配置文件<br>tutorial/: 该项目的 python 模块。<br>tutorial/items.py: 项目中的 item 文件.<br>tutorial/pipelines.py: 项目中的 pipelines 文件.<br>tutorial/settings.py: 项目的设置文件.<br>tutorial/spiders/: 放置 spider 代码的目录.</p><h3 id="定义 -Item"><a href="# 定义 -Item" class="headerlink" title="定义 Item"></a>定义 Item</h3><p>Item 是保存爬取到的数据的容器；其使用方法和 python 字典类似。虽然您也可以在 Scrapy 中直接使用 dict，但是 Item 提供了额外保护机制来避免拼写错误导致的未定义字段错误。<br>这里这样写</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DmozItem</span>(<span class="hljs-params">scrapy.Item</span>):</span>
    title = scrapy.Field()
    link = scrapy.Field()
    desc = scrapy.Field()</code></pre></div><p>DmozItem 为该 Item 的名字， 该类是一个 scrapy.Item 类。<br>我这里想获取到的信息是 title、link 和 desc 这三个字段，它们都是 scrapy.Field 类型的。</p><h3 id="编写爬虫"><a href="# 编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h3><p>在 <code>tutorial/spiders/</code>下创建一个 py 文件 <code>dmoz_spider.py</code>，它是这样定义的：</p><div class="hljs"><pre><code class="hljs python">
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> tutorial.items <span class="hljs-keyword">import</span> DmozItem

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DmozSpider</span>(<span class="hljs-params">scrapy.Spider</span>):</span>
    name = <span class="hljs-string">&#x27;dmoz&#x27;</span>
    allowed_domains = [<span class="hljs-string">&#x27;dmoz.org&#x27;</span>]
    start_urls = [<span class="hljs-string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;</span>,
        <span class="hljs-string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</span>
    ]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span>
        sel = Selector(response)
        sites = sel.xpath(<span class="hljs-string">&#x27;//ul[@class=&quot;directory-url&quot;]/li&#x27;</span>)
        <span class="hljs-keyword">for</span> sel <span class="hljs-keyword">in</span> sites:
            item = DmozItem() <span class="hljs-comment"># 实例化一个 DmozItem 类</span>
            item[<span class="hljs-string">&#x27;title&#x27;</span>] = sel.xpath(<span class="hljs-string">&#x27;a/text()&#x27;</span>).extract()
            item[<span class="hljs-string">&#x27;link&#x27;</span>] = sel.xpath(<span class="hljs-string">&#x27;a/@href&#x27;</span>).extract()
            item[<span class="hljs-string">&#x27;desc&#x27;</span>] = sel.xpath(<span class="hljs-string">&#x27;text()&#x27;</span>).extract()
            <span class="hljs-keyword">yield</span> item</code></pre></div><p>爬虫类必须继承自<code>scrapy.Spider</code> 类， 且定义一些属性:</p><p><strong>name</strong>: 用于区别 Spider。 该名字必须是唯一的，不可以为不同的 Spider 设定相同的名字。<br><strong>start_urls</strong>: 包含了 Spider 在启动时进行爬取的 url 列表。 因此，第一个被获取到的页面将是其中之一， 后续的 URL 则从初始的 URL 获取到的数据中提取。<br><code>parse()</code> 是 spider 的一个方法。 被调用时，每个初始 URL 完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据 (response data)，提取数据(生成 item) 以及生成需要进一步处理的 URL 的 Request 对象。scrapy 为 Spider 的 start_urls 属性中的每个 URL 创建了 scrapy.Request 对象，并将 parse 方法作为回调函数 (callback) 赋值给了 Request。Request 对象经过调度，执行生成 scrapy.http.Response 对象并送回给 spider parse() 方法, 一般返回 Item 实例。</p><h3 id="爬取"><a href="# 爬取" class="headerlink" title="爬取"></a>爬取</h3><p>进入该工程目录，本例中就是 tutorial/, 在命令行执行</p><div class="hljs"><pre><code class="hljs python">scrapy crawl dmoz</code></pre></div><h3 id="保存"><a href="# 保存" class="headerlink" title="保存"></a>保存</h3><p>可以使用如下命令</p><div class="hljs"><pre><code class="hljs python">scrapy crawl dmoz -o items.json</code></pre></div><p>该命令是说将结果保存在 items.json 文件中。</p><h2 id="常用的命令行工具"><a href="# 常用的命令行工具" class="headerlink" title="常用的命令行工具"></a>常用的命令行工具</h2><div class="hljs"><pre><code class="hljs other"># 创建项目
scrapy startproject myproject
# 帮助信息
scrapy &lt;command&gt; -h
# 帮助信息
scrapy -h
# 使用下载器下载指定的 url，并将获取到的内容送到标准输出
scrapy fetch &lt;url&gt;
# 在浏览器中打开给定的 URL，并以 Scrapy spider 获取到的形式展现
scrapy view &lt;url&gt;
# 以给定的 URL(如果给出)或者空 (没有给出 URL) 启动 Scrapy shell
scrapy shell [url]
#在未创建项目的情况下，运行一个编写在 Python 文件中的 spider
scrapy runspider &lt;spider_file.py&gt;
# 获取 Scrapy 的设定
scrapy settings [options]
------------------------- 以上不需要项目，以下需要在项目中 ----------------------------------------
# 使用 template 模版来信创建一个 spider， name 值为 &lt;name&gt;, allowed_domains 值为 &lt;domain&gt;
scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;
# 查看可用的模版，默认有 basic、crawl、csvfeed 和 xmlfeed 4 个
scrapy genspider -l
# 查看 TEMPLATE 信息
scrapy genspider -d TEMPLATE
# 使用 &lt;spider&gt; 进行爬取数据
scrapy crawl &lt;spider&gt;
# 列出当前项目中所有可用的 spider
scrapy list
# 运行 contract 检查。
scrapy check [-l] &lt;spider&gt;
# 获取给定的 URL 并使用相应的 spider 分析处理，可以解析成自己写的 item
scrapy parse &lt;url&gt; [options]
</code></pre></div></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/python/">python</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p><div class="post-prevnext row"><article class="post-prev col-6"><a href="/f49a9b8a.html"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">sublime text3 配置 [python 篇]</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/5e988508.html"><span class="hidden-mobile">hexo + gitpages 搭建博客</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC8zNjg1MS8xMzM4Nw"><script type="text/javascript">function loadLivere(){addScript("https://cdn-city.livere.com/js/embed.dist.js")}waitElementVisible("lv-container",loadLivere)</script><noscript>为正常使用来必力评论功能请允许 JavaScript 运行</noscript></div></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div></main><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><footer class="mt-5"><div class="text-center py-3"><div><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/debouncer.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script>$(document).ready(function(){var t=$("#board-ctn").offset().top;tocbot.init({tocSelector:"#tocbot",contentSelector:"#post-body",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:3,scrollSmooth:!0,headingsOffset:-t}),0<$(".toc-list-item").length&&$("#toc").css("visibility","visible")})</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","Scrapy Demo&nbsp;"],cursorChar:"|",typeSpeed:72,loop:!1});typed.stop(),$(document).ready(function(){$(".typed-cursor").addClass("h2"),typed.start()})</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>anchors.options = {
      placement: "right",
      visible: "hover",
      
      icon: "§"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))</script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){searchFunc(path,"local-search-input","local-search-result"),this.onclick=null}</script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script>$("#post img:not(.no-zoom img, img[no-zoom]), img[zoom]").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script></body></html>