<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Redis 源码分析之 key 过期</title>
    <link href="/5a077de9.html"/>
    <url>/5a077de9.html</url>
    
    <content type="html"><![CDATA[<p>redis 支持 key 级别的过期设置，可以使用 <code>EXPIRE</code> 相关的命令对此进行设置，同时支持相对时间和绝对时间两种方式。</p><a id="more"></a><h2 id="设置过期时间命令">设置过期时间命令</h2><p>redis 中设置 key 相对过期时间的命令 <code>EXPIRE</code>/ <code>PEXPIRE</code>，设置 key 绝对过期时间的命令 <code>EXPIREAT</code>/<code>PEXPIREAT</code>，最终都是调用 <code>expireGenericCommand</code> 函数实现的。</p><p>代码分析大致如下，</p><pre><code class="language-c">void expireGenericCommand(client *c, long long basetime, int unit) {robj *key = c-&gt;argv[1], *param = c-&gt;argv[2];   long long when; /* unix time in milliseconds when the key will expire. */   if (getLongLongFromObjectOrReply(c, param, &amp;when, NULL) != C_OK)       return;   if (unit == UNIT_SECONDS) when *= 1000;   when += basetime;   /* No key, return zero. */   if (lookupKeyWrite(c-&gt;db,key) == NULL) {addReply(c,shared.czero);       return;   }   if (when &lt;= mstime() &amp;&amp; !server.loading &amp;&amp; !server.masterhost) {       robj *aux;       serverAssertWithInfo(c,key,dbDelete(c-&gt;db,key));       server.dirty++;       /* Replicate/AOF this as an explicit DEL. */       aux = createStringObject(&quot;DEL&quot;,3);       rewriteClientCommandVector(c,2,aux,key);       decrRefCount(aux);       signalModifiedKey(c-&gt;db,key);       notifyKeyspaceEvent(NOTIFY_GENERIC,&quot;del&quot;,key,c-&gt;db-&gt;id);       addReply(c, shared.cone);       return;   } else {setExpire(c-&gt;db,key,when);       addReply(c,shared.cone);       signalModifiedKey(c-&gt;db,key);       notifyKeyspaceEvent(NOTIFY_GENERIC,&quot;expire&quot;,key,c-&gt;db-&gt;id);       server.dirty++;       return;   }}</code></pre><p>首先是解析参数，相对时间会被转换成绝对时间 <code>when</code>。</p><p>找一个下这个 key 是否存在，如果不存在，那么直接返回。</p><p>如果 <code>when</code> 比当前时间还要小，没有做数据的 loading，且当前节点是 master（slave 节点等着 master 传过去的 DEL 就好），这时把 expire 命令转换成 <strong>DEL</strong>。<br>否则，调用 <code>setExpire</code> 函数为 key 设置过期时间，</p><p>代码分析如下，</p><pre><code class="language-c">void setExpire(redisDb *db, robj *key, long long when) {   dictEntry *kde, *de;   /* Reuse the sds from the main dict in the expire dict */   kde = dictFind(db-&gt;dict,key-&gt;ptr);   serverAssertWithInfo(NULL,key,kde != NULL);   // 在 expires 中寻找 key，找不到就新建一个   de = dictReplaceRaw(db-&gt;expires,dictGetKey(kde));   dictSetSignedIntegerVal(de,when);}</code></pre><p>通过以上代码可以发现，含有过期时间的 key 都会放到 <code>db-&gt;expires</code> 变量中（在数据库结构体 <code>redisDb</code> 中，使用 <code>expires</code> 字典存放这些 key）。</p><pre><code class="language-c">typedef struct redisDb {    dict *dict; // 存放所有 key    dict *expires; // 存放过期 key    int id; // 数据库 id    ....} redisDb;</code></pre><p>过期时间通过 <code>dictSetSignedIntegerVal</code> 函数，存放到 key 所在的 <code>dictEntry</code> 结构，如下，</p><pre><code class="language-c">typedef struct dictEntry {    void *key;    union {        void *val;        uint64_t u64;        int64_t s64; // 存放过期时间        double d;    } v;    struct dictEntry *next;} dictEntry;</code></pre><h2 id="查询过期时间命令">查询过期时间命令</h2><p>查询某个 key 的过期时间，redis 提供了 <code>TTL</code> 这个命令，有三种返回值，</p><ul><li>返回 <strong>-2</strong>，表示查询的 key 不存在。</li><li>返回 <strong>-1</strong>，表示查询的 key 没有设置过期。</li><li>返回正常的过期时间。</li></ul><p>上面已经知道，key 过期时间存放位置了，那么直接取出来就好了。</p><pre><code class="language-c">long long getExpire(redisDb *db, robj *key) {    dictEntry *de;    /* No expire? return ASAP */    if (dictSize(db-&gt;expires) == 0 ||       (de = dictFind(db-&gt;expires,key-&gt;ptr)) == NULL) return -1;    serverAssertWithInfo(NULL,key,dictFind(db-&gt;dict,key-&gt;ptr) != NULL);    return dictGetSignedIntegerVal(de);}</code></pre><p>通过 <code>dictGetSignedIntegerVal</code> 函数取到过期时间。</p><h2 id="删除过期时间">删除过期时间</h2><p>如果一个 key 设置了过期时间后想删除怎么办？redis 提供了 <code>PERSIST</code> 命令，或者直接用 <code>SET</code> 命令去覆盖，它们都涉及到函数 <code>removeExpire</code>。</p><p>具体代码如下，</p><pre><code class="language-c">int removeExpire(redisDb *db, robj *key) {    /* An expire may only be removed if there is a corresponding entry in the     * main dict. Otherwise, the key will never be freed. */    serverAssertWithInfo(NULL,key,dictFind(db-&gt;dict,key-&gt;ptr) != NULL);    return dictDelete(db-&gt;expires,key-&gt;ptr) == DICT_OK;}</code></pre><p>从 <code>db-&gt;expires</code> 中删掉这个 key，但是 <code>dictEntry</code> 结构体中的 <strong> 过期时间并不会重置</strong>。</p><h2 id="删除过期 -key">删除过期 key</h2><p>redis 3.x 中，过期 key 的删除方式有两种，<strong>惰性删除 </strong> 和<strong>周期删除</strong>。</p><h3 id="惰性删除">惰性删除</h3><p>当 key 过期后，并不会立刻删除，即，它们占用的内存不能够得到及时释放。</p><p>redis 在对每个 key 进行读写时，都会去检查这个 key 是否过期需要删除了，这样就 <strong> 把清理过期 key 的工作分摊到每一次访问中</strong>。类似的思路还有，redis 中的 dict 的扩容，称为渐进式 rehash。</p><p class="note note-warning">这样会导致一个问题，当检查到一个大 key 要删除时，会占用比较长的时间，导致此次访问的响应时间变长。</p><p>检查 key 的 expire 的逻辑在 <code>expireIfNeeded</code> 函数中实现，代码如下，</p><pre><code class="language-c">int expireIfNeeded(redisDb *db, robj *key) {    // 获得 key 的过期时间    mstime_t when = getExpire(db,key);    mstime_t now;    // key 没有设置过期时间    if (when &lt; 0) return 0;    // 在 load 数据时，暂时先不要处理过期的 key    if (server.loading) return 0;    // 有 lua 脚本调用时，now 取 lua 脚本开始的时间，否则取当前时间    now = server.lua_caller ? server.lua_time_start : mstime();    // 如果本节点是 slave，等着 master 同步 DEL 命令    if (server.masterhost != NULL) return now &gt; when;    // 如果没过期，返回 0    if (now &lt;= when) return 0;    // 过期 key 的统计    server.stat_expiredkeys++;    // 同步 DEL 命令给 slave 和 aof 文件    propagateExpire(db,key);    notifyKeyspaceEvent(NOTIFY_EXPIRED,        &quot;expired&quot;,key,db-&gt;id);    // 删 key    return dbDelete(db,key);}</code></pre><p>经过一些前置校验，在 <code>propagateExpire</code> 函数中，将 <code>DEL</code> 命令分发给所有的 slave，以及写入 aof。</p><pre><code class="language-c">void propagateExpire(redisDb *db, robj *key) {robj *argv[2];    argv[0] = shared.del;    argv[1] = key;    incrRefCount(argv[0]);    incrRefCount(argv[1]);    if (server.aof_state != AOF_OFF)        feedAppendOnlyFile(server.delCommand,db-&gt;id,argv,2);    replicationFeedSlaves(server.slaves,db-&gt;id,argv,2);    decrRefCount(argv[0]);    decrRefCount(argv[1]);}</code></pre><p>当一个 key 在 master 上过期后，将会给所有的 slave 发送相应的 DEL 命令，如果 aof 打开了，也会写入 aof。</p><p class="note note-primary">这种在一个地方集中化管理 key 的方式，并且在 aof 和主从链接里保证操作顺序，即使有对于过期 key 的写操作也是允许的。</p><p>而删 key 的操作，在函数 <code>dbDelete</code> 中完成，代码如下，</p><pre><code class="language-c">int dbDelete(redisDb *db, robj *key) {if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);    if (dictDelete(db-&gt;dict,key-&gt;ptr) == DICT_OK) {if (server.cluster_enabled) slotToKeyDel(key);        return 1;    } else {return 0;}}</code></pre><p>如上代码可以看到，分别从 <code>db-&gt;expires</code> 和 <code>db-&gt;dict</code> 这两个 dict 里删除相应的 key。如果开启了 <strong>cluster 模式</strong>，还有在相应的 slot 里删掉。</p><h3 id="周期删除">周期删除</h3><p>上面的惰性删除，只有在访问到 key 时才会触发，这使得过期 key 的清理时间拉的很长，所以只有惰性删除一种方式是不行的，因此增加周期删除这个方式作为补充。</p><p>周期删除使用的函数是 <code>activeExpireCycle</code>。这个函数在调用时，入参分情况有 2 种过期循环类型，两者的主要区别是执行时间的差异。</p><ul><li>常量 <code>ACTIVE_EXPIRE_CYCLE_FAST</code> ，执行时间限制是 1000 us。在 <code>beforeSleep</code> 函数中调用的，即，每次 redis 要进入事件循环之前调用，因此需要比较快的返回</li><li>常量 <code>ACTIVE_EXPIRE_CYCLE_SLOW</code>，执行时间限制有一个复杂公式计算，后面会说到。在周期性任务 <code>databasesCron</code> 中调用的，执行时间可以稍微长一点。</li></ul><p>在 <code>activeExpireCycle</code> 函数里，会尝试删除一些过期的 key。使用到的算法是 <strong> 自适应的</strong>，如果几乎没有过期 key，仅使用少量的 CPU 周期，否则，为了避免过期 key 过多占用内存，将会更积极地从数据库删除它们。每轮检查的数据库个数不超过常量 <strong>CRON_DBS_PER_CALL</strong> (16) 个。</p><p>代码大概如下，</p><pre><code class="language-c">if (type == ACTIVE_EXPIRE_CYCLE_FAST) {if (!timelimit_exit) return;      if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;      last_fast_cycle = start;  }</code></pre><p>如果上一次循环不是因为 timeout 而结束的，那么这一次没必要跑 fast 循环，也就是说，时间够用了，可以跑 slow 多清理一些过期 key。<br>另外，不要在上一次跑过 fast 之后的 2 倍 <strong>ACTIVE_EXPIRE_CYCLE_FAST_DURATION</strong> (1000) us 时间内再跑一次 fast 循环。</p><p><code>dbs_per_call</code> 变量保存的是，本轮循环需要遍历的 db 数量，默认值是 16，在以下 2 种情况下需要修改，</p><ul><li>检查的 db 数超过现有的。</li><li>上一次以为 timelimit 离开了。此时需要尽快的把已有的 db 里的过期 key 给清理掉，减少内存占用，留出更多空间供正常使用。</li></ul><p>判断代码如下，</p><pre><code class="language-c">  if (dbs_per_call &gt; server.dbnum || timelimit_exit)      dbs_per_call = server.dbnum;</code></pre><p>下面是循环时间 limit 的计算，</p><pre><code class="language-c">  timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;  timelimit_exit = 0;  if (timelimit &lt;= 0) timelimit = 1;  if (type == ACTIVE_EXPIRE_CYCLE_FAST)      timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. 1000 us */</code></pre><p>然后开启遍历每个 db 了，如下逻辑均在此循环中实现，</p><pre><code class="language-c">for (j = 0; j &lt; dbs_per_call; j++) {}</code></pre><p>代码里有一个记录上一次遍历到那个 db 的静态变量 <code>current_db</code>，每次都加 1。</p><pre><code class="language-c">static unsigned int current_db = 0; /* Last DB tested. */current_db++;</code></pre><p>选择一个 db 进行数据清理，</p><pre><code class="language-c">redisDb *db = server.db+(current_db % server.dbnum);</code></pre><p>下面就是在选择的 db 里对 key 进行抽样检查的过程，</p><pre><code class="language-c">// 如果没有过期的 key，那么这个 db 的检查结束if ((num = dictSize(db-&gt;expires)) == 0) {            db-&gt;avg_ttl = 0;            break;}slots = dictSlots(db-&gt;expires);if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp; (num*100/slots &lt; 1))        break;</code></pre><p>如果 expires 字典不为空，存储的数据可能已经很少了，但是字典还是大字典 (<strong> 数据不足 1%</strong>)，这样遍历数据有效命中率会很低，处理起来会浪费时间，后面的访问会很快触发字典的缩容，缩容后再进行处理效率更高, 暂时结束这个 db 的检查。</p><p>每一次抽样最多 20 个 key。</p><pre><code class="language-c">if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)      num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;while (num--) {    dictEntry *de;    long long ttl;    if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;    ttl = dictGetSignedIntegerVal(de)-now;    if (activeExpireCycleTryExpire(db,de,now)) expired++; // 过期的 key 删掉    if (ttl &gt; 0) {        /* We want the average TTL of keys yet not expired. */        ttl_sum += ttl;        ttl_samples++;    }}</code></pre><p>随机选取 key，调用 <code>activeExpireCycleTryExpire</code> 函数进行过期 key 的删除，该函数逻辑见附录。</p><p>这里还有个统计平均 ttl 的逻辑，</p><pre><code class="language-c">if (ttl_samples) {    // 抽样 key 的平均 ttl 时间    long long avg_ttl = ttl_sum/ttl_samples;    // 本轮 avg_ttl 占比 2%，历史值占比 98%    if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;    db-&gt;avg_ttl = (db-&gt;avg_ttl/50)*49 + (avg_ttl/50);}</code></pre><p>每个 db 的检查什么时候退出呢？有 2 个时刻。</p><ol><li>通过超时时间 <code>timelimit</code>。<br>每 16 轮循环检查一次是否超时，到时间后 ，<code>timelimit_exit</code> 变量置 1，接着就退出了。</li></ol><pre><code class="language-c">iteration++;if ((iteration &amp; 0xf) == 0) { /* check once every 16 iterations. */    long long elapsed = ustime()-start;    latencyAddSampleIfNeeded(&quot;expire-cycle&quot;,elapsed/1000);    if (elapsed &gt; timelimit) timelimit_exit = 1;}if (timelimit_exit) return;</code></pre><ol start="2"><li>在每个 db 的检查循环外，是有条件的。<br>每检查到一个过期的 key，就把 <code>expired</code> 变量加 1，所以，这个循环的条件时，如果一轮抽样到的 key 中过期的比例小于 25%，那么这个 db 就不必再抽样了。</li></ol><pre><code class="language-c">#define ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 20do {...} while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);</code></pre><p class="note note-warning">在一个时间范围内，过期 key 最好不要太密集，因为系统发现到期数据很多，会迫切希望尽快处理掉这些过期数据，所以每次检查都要耗尽分配的时间片，直到到期数据到达一个可接受的密度比例。</p><p class="note note-primary">由上总结，redis 主逻辑在单进程主线程中实现，要保证不能影响主业务前提下，检查过期数据，不能太影响系统性能。主要三方面进行限制：(1) 检查时间限制。(2) 过期数据检查数量限制。(3) 过期数据是否达到可接受比例。</p><p>至此，redis 中 key 的过期逻辑就讲完了。顺便说一下，为了解决删大 key 带来的阻塞风险，在更高版本的 redis 中，将删 key 放到了 bio 后台线程中。</p><h2 id="附录">附录</h2><p><code>activeExpireCycleTryExpire</code> 函数将试着将存储的过期 key 从全局 key 的 dict 和 expire 的 dict 中删掉。如果发现 key 过期了，操作后返回 1，否则什么也不做，返回 0。代码逻辑如下，</p><pre><code class="language-c">int activeExpireCycleTryExpire(redisDb *db, dictEntry *de, long long now) {long long t = dictGetSignedIntegerVal(de);    if (now &gt; t) {sds key = dictGetKey(de);        robj *keyobj = createStringObject(key,sdslen(key));        // 广播到 slave 和 aof        propagateExpire(db,keyobj);        // 删 key        dbDelete(db,keyobj);        notifyKeyspaceEvent(NOTIFY_EXPIRED,            &quot;expired&quot;,keyobj,db-&gt;id);        decrRefCount(keyobj);        // 更新统计        server.stat_expiredkeys++;        return 1;    } else {return 0;}}</code></pre>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码分析之数据迁移 (2)</title>
    <link href="/badab03c.html"/>
    <url>/badab03c.html</url>
    
    <content type="html"><![CDATA[<p>上一篇文章中，详细讲解了 redis  cluster 中说数据迁移的流程，那在迁移过程中，节点对正常用户访问是如何处理的呢？<br>本篇文章将探讨一下。</p><a id="more"></a><h3 id="processCommand- 函数处理">processCommand 函数处理</h3><p>众所周知，<code>processCommand</code> 函数负责处理具体的命令处理过程，</p><p>在 cluster 模式下，此函数中会进行 cluster 重定向，但 2 种情况除外：</p><ul><li>发送命令的是我的 master</li><li>发送的命令没有 key 参数</li></ul><p>具体代码，如下，</p><pre><code class="language-c">if (server.cluster_enabled &amp;&amp;    !(c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp;    !(c-&gt;flags &amp; CLIENT_LUA &amp;&amp;    server.lua_caller-&gt;flags &amp; CLIENT_MASTER) &amp;&amp;    !(c-&gt;cmd-&gt;getkeys_proc == NULL &amp;&amp; c-&gt;cmd-&gt;firstkey == 0 &amp;&amp;    c-&gt;cmd-&gt;proc != execCommand)){    int hashslot;    int error_code;    clusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc,                                        &amp;hashslot,&amp;error_code);    if (n == NULL || n != server.cluster-&gt;myself) {if (c-&gt;cmd-&gt;proc == execCommand) {discardTransaction(c);        } else {flagTransaction(c);        }        clusterRedirectClient(c,n,hashslot,error_code);        return C_OK;    }}</code></pre><p>由上可以看出，代码中使用 <code>getNodeByQuery</code> 函数负责处理 hashslot 的节点 n。<br>如果 n 是空的，或者不是我自己，那么就需要做一个 cluster 的 redirection，使用 <code>clusterRedirectClient</code> 函数，该函数主要是针对 <code>getNodeByQuery</code> 函数返回的不同错误码，给 client 不同的返回信息，具体代码如下，</p><pre><code class="language-c">void clusterRedirectClient(client *c, clusterNode *n, int hashslot, int error_code) {if (error_code == CLUSTER_REDIR_CROSS_SLOT) {addReplySds(c,sdsnew(&quot;-CROSSSLOT Keys in request don't hash to the same slot\r\n&quot;));    } else if (error_code == CLUSTER_REDIR_UNSTABLE) {addReplySds(c,sdsnew(&quot;-TRYAGAIN Multiple keys request during rehashing of slot\r\n&quot;));    } else if (error_code == CLUSTER_REDIR_DOWN_STATE) {addReplySds(c,sdsnew(&quot;-CLUSTERDOWN The cluster is down\r\n&quot;));    } else if (error_code == CLUSTER_REDIR_DOWN_UNBOUND) {addReplySds(c,sdsnew(&quot;-CLUSTERDOWN Hash slot not served\r\n&quot;));    } else if (error_code == CLUSTER_REDIR_MOVED || error_code == CLUSTER_REDIR_ASK)    {addReplySds(c,sdscatprintf(sdsempty(),            &quot;-%s %d %s:%d\r\n&quot;,            (error_code == CLUSTER_REDIR_ASK) ? &quot;ASK&quot; : &quot;MOVED&quot;,            hashslot,n-&gt;ip,n-&gt;port));    } else {serverPanic(&quot;getNodeByQuery() unknown error.&quot;);    }}</code></pre><p>最后返回 <code>C_OK</code>，结束命令处理流程，因为涉及到的 slot 不是本节点负责！</p><h3 id="getNodeByQuery- 函数处理">getNodeByQuery 函数处理</h3><p>下面来看下比较重要的 <code>getNodeByQuery</code> 函数的处理逻辑，它用来返回负责访问 slot 的真实节点。</p><pre><code class="language-c">multiState *ms, _ms;multiCmd mc;int i, slot = 0, migrating_slot = 0, importing_slot = 0, missing_keys = 0;/* Set error code optimistically for the base case. */if (error_code) *error_code = CLUSTER_REDIR_NONE;if (cmd-&gt;proc == execCommand) {    /* If CLIENT_MULTI flag is not set EXEC is just going to return an     * error. */    if (!(c-&gt;flags &amp; CLIENT_MULTI)) return myself;        ms = &amp;c-&gt;mstate;    } else {        /* In order to have a single codepath create a fake Multi State         * structure if the client is not in MULTI/EXEC state, this way         * we have a single codepath below. */        ms = &amp;_ms;        _ms.commands = &amp;mc;        _ms.count = 1;        mc.argv = argv;        mc.argc = argc;        mc.cmd = cmd;}</code></pre><p>当没有错误时，该函数返回的错误码是 <strong>CLUSTER_REDIR_NONE</strong>。</p><p><strong>注意</strong>：<br>如果当前处于事务模式下，则事务中的所有命令中的所有 key，需要一起进行判断。<br>对于非事务模式下的命令，也按照事务的方式进行处理，只不过本事务只包含当前一条命令。</p><p>如果当前执行的命令是 <code>EXEC</code>，并且 client 没有 <strong>CLIENT_MULTI</strong> 标记，那么直接返回 myself，表示自己能处理这个命令，但是实际上这种情况下，在命令处理函数 <code>execCommand</code> 中，会直接反馈给客户端 <strong>EXEC without MULTI</strong> 错误。<br>否则，构造伪事务数据结构变量 <code>ms</code>，其中只包含当前命令这一条。</p><p>接下来，针对每一条命令，即所有逻辑包裹在如下循环里，</p><pre><code class="language-c">for (i = 0; i &lt; ms-&gt;count; i++) {}</code></pre><pre><code class="language-c">// 每一个命令的相关参数mcmd = ms-&gt;commands[i].cmd;margc = ms-&gt;commands[i].argc;margv = ms-&gt;commands[i].argv;keyindex = getKeysFromCommand(mcmd,margv,margc,&amp;numkeys);</code></pre><p><code>getKeysFromCommand</code> 函数的返回值 <code>keyindex</code> 为本条命令中所有 key 的 index 数组，<code>numkeys</code> 则为 key 的个数。<br>接下来就循环处理本条命令中的所有 key。</p><pre><code class="language-c">// 循环处理每个 keyfor (j = 0; j &lt; numkeys; j++) {}</code></pre><pre><code class="language-c">// 拿到 keyrobj *thiskey = margv[keyindex[j]];// 拿到对应的 slotint thisslot = keyHashSlot((char*)thiskey-&gt;ptr, sdslen(thiskey-&gt;ptr));</code></pre><pre><code class="language-c">if (firstkey == NULL) {    // 如果是该命令中的一个 key，记录到 firstkey 里    firstkey = thiskey;    slot = thisslot;    n = server.cluster-&gt;slots[slot];    // 找不到负责该 slot 的节点，报错 &quot;-CLUSTERDOWN, unbound slot.&quot;    if (n == NULL) {getKeysFreeResult(keyindex);        if (error_code)            *error_code = CLUSTER_REDIR_DOWN_UNBOUND;        return NULL;     }     // 是我负责的 slot，并且该 slot 正在迁出 key     if (n == myself         &amp;&amp; server.cluster-&gt;migrating_slots_to[slot] != NULL) {migrating_slot = 1;} else if (server.cluster-&gt;importing_slots_from[slot] != NULL) {importing_slot = 1;}}</code></pre><p>这里有个重要的逻辑。<br>当要操作的 key 对应的 slot 是我负责的，并且该 slot 正在迁出 key，那么标记 <code>migrating_slot = 1</code>。<br>如果这个 slot 不是我负责的，那么标记 <code>importing_slot = 1</code>。</p><p>如果不是第一个 key，就要看下 <strong> 是不是所有的 key 都在一个 slot 上</strong>，否则，会报错 <strong>CROSSSLOT Keys in request don’t hash to the same slot</strong>。代码如下，</p><pre><code class="language-c">if (!equalStringObjects(firstkey,thiskey)) {if (slot != thisslot) {       /* Error: multiple keys from different slots. */        getKeysFreeResult(keyindex);        if (error_code)            *error_code = CLUSTER_REDIR_CROSS_SLOT;        return NULL;     } else {        /* Flag this request as one with multiple different keys. */         multiple_keys = 1;     }}</code></pre><p>所以，对于多 key 操作，涉及到的 key 需要在一个 slot 上，否则会报错。</p><p>同时，遇到正在迁入迁出 key 的 slot 还要统计 missing_keys（本地找不到的 key，可能已经迁移到目的地了）。如下，</p><pre><code class="language-c">if ((migrating_slot || importing_slot) &amp;&amp;    lookupKeyRead(&amp;server.db[0],thiskey) == NULL) {missing_keys++;}</code></pre><p>结束了每个命令的处理，接着往下走，对于有迁入迁出 slot 的情况是如何处理的呢？</p><pre><code class="language-c">// 命令里没有 key，本节点就可以处理，返回 myselfif (n == NULL) return myself;// 集群状态不正常，返回错误 -CLUSTERDOWNif (server.cluster-&gt;state != CLUSTER_OK) {if (error_code) *error_code = CLUSTER_REDIR_DOWN_STATE;        return NULL; }// 如果有正在迁入或者迁出的 slot，且正执行的命令是 MIGRATE，返回 myself// MIGRATE 命令总是在本地上下文环境中运行的if ((migrating_slot || importing_slot) &amp;&amp; cmd-&gt;proc == migrateCommand)    return myself;</code></pre><p>对于访问到迁入迁出 slot 中的 key 的处理，如下</p><pre><code class="language-c">if (migrating_slot &amp;&amp; missing_keys) {if (error_code) *error_code = CLUSTER_REDIR_ASK;    return server.cluster-&gt;migrating_slots_to[slot];}if (importing_slot &amp;&amp; (c-&gt;flags &amp; CLIENT_ASKING || cmd-&gt;flags &amp; CMD_ASKING)) {if (multiple_keys &amp;&amp; missing_keys) {if (error_code) *error_code = CLUSTER_REDIR_UNSTABLE;             return NULL;     } else {         // 否则返回 myself         return myself;     }}</code></pre><p>若访问的 slot 正在做迁出，且存在正常访问的 key 在本地查不到，那么报错 <strong>-ASK</strong>，并返回该 key 迁移到的目的节点（可能是迁到目的节点了）。<br>若访问的 slot 正在做迁入，且 client 带有 <strong>CLIENT_ASKING</strong> 标记，或者 cmd 带有 <strong>CMD_ASKING</strong> 的标记。此时，如果涉及到多 key 操作，且有的 key 不在当前节点中，报错  <strong>-TRYAGAIN</strong>（后面重试），返回 NULL。否则，返回 myself（因为所有的 key 我都有嘛）。</p><hr><p>经过上面两条分析，<strong>下面总结一下</strong>：<br>当要访问的 slot 恰好在做迁移，那么 redis 有如下逻辑。<br><code>multiple_keys</code> 变量表示这是否是个多 key 操作。<br><code>missing_keys</code> 变量表示，要访问的 key，是否都在本节点。</p><p>对于单 key 操作，</p><ul><li><p>写 key 时，因为本地没有这个 key，所以通过 ASK 错误重定向到目标节点进行写入操作。</p></li><li><p>读 key 时，如果本地节点有，那么在本地节点访问，否则通过 ASK 错误，重定向到目标节点进行读取。</p></li></ul><p>对于多 key 操作，</p><ul><li><p>写 key 时，因为本地没有这些 key，所以通过 ASK 错误重定向到目标节点，而在目标节点中也没有这些 key，而且又是个多 key 操作，那么报错 <strong>-TRYAGAIN</strong>，只能等到后面这个 slot 迁移完成后才能做多 key 写入。</p></li><li><p>多 key 时，如果本地有所有的 key，那么正常返回。如果本地只有部分 key，那么通过 ASK 错误重定向到目标节点。到了目标节点，如果有全部的 key，那么正常返回，否则报错 <strong>-TRYAGAIN</strong>。（待会再来访问吧，等到所有的 key 都迁过来）</p></li></ul><hr><h3 id="MOVED- 与 -ASK- 重定向">MOVED 与 ASK 重定向</h3><p>如果访问到的 slot 不是我负责的，那么报错 <strong>-MOVED</strong>，且返回正确的负责节点。</p><pre><code class="language-c">if (n != myself &amp;&amp; error_code) *error_code = CLUSTER_REDIR_MOVED;    return n;</code></pre><p>当然，这样也可以很清楚的看到 <strong>MOVED</strong> 和 <strong>ASK</strong> 错误的区别。</p><ul><li><p><strong>ASK</strong> 表示，要访问的 key 所在的 slot 当前正在做迁移，去 ASK 迁入节点处理请求。</p></li><li><p><strong>MOVED</strong> 表示，要访问的 key 所在的 slot 不由本节点负责，MOVED 到正确的节点去访问吧。</p></li></ul><p>接收到 ASK 错误后，client 应该先发送 <code>ASKING</code> 命令到迁入节点，使得 client 带上 <code>CLIENT_ASKING</code> 标记，然后再发送正常命令。</p><pre><code class="language-c">void askingCommand(client *c) {if (server.cluster_enabled == 0) {addReplyError(c,&quot;This instance has cluster support disabled&quot;);        return;    }    c-&gt;flags |= CLIENT_ASKING;    addReply(c,shared.ok);}</code></pre>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码分析之数据迁移 (1)</title>
    <link href="/91f7e3ff.html"/>
    <url>/91f7e3ff.html</url>
    
    <content type="html"><![CDATA[<p>redis 中的数据迁移是以 key 为单位的，整个迁移过程由一系列命令组成，在官方提供的 ruby 实现的 trib 工具中对整个过程进行了包装串联，在更新的版本的 redis 中，已经将这些逻辑移植到了 redis-cli 中，使用 C 进行了重写。下面进行分步详细讲解。</p><a id="more"></a><h2 id="标记 -importing">标记 importing</h2><p>在 <strong> 目的节点</strong> B 执行命令 <code>SETSLOT 10 IMPORTING &lt;A 的 nodeID&gt;</code>，标记有一个 slot (10) 将要从源节点 A 迁入到本节点 B。<br>此时，在 B 上使用  <code>cluster nodes</code> 命令查看集群路由现状，可以发现，在 B 负责的 slot 信息里有这样的标记<code>[10-&lt;-A nodeid]</code>。（其他节点不知道这件事）</p><p>具体代码执行逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {    .....    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;setslot&quot;) &amp;&amp; c-&gt;argc &gt;= 4) {        .....        else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;importing&quot;) &amp;&amp; c-&gt;argc == 5) {if (server.cluster-&gt;slots[slot] == myself) {addReplyErrorFormat(c, &quot;I'm already the owner of hash slot %u&quot;,slot);                return;            }            if ((n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr)) == NULL) {addReplyErrorFormat(c,&quot;I don't know about node %s&quot;, (char*)c-&gt;argv[3]-&gt;ptr);                return;            }            server.cluster-&gt;importing_slots_from[slot] = n;        }        .....    }    .....}</code></pre><p>当接收到 <code>setslot</code> 命令时，匹配到关于设置 slot  importing 状态的逻辑。</p><p>首先是一些参数的校验。</p><ul><li>检查 slot x 是不是已经属于我了，如果是，那么报错 <strong>I’m already the owner of hash slot x</strong>。（slot x 已经是我的了，不需要再迁给我）</li><li>检查源节点我是否认识，如果不认识的话，报错  <strong>I don’t know about node</strong>。（不认识源节点，我从哪儿迁入呢？）</li></ul><p>然后，修改 <code>server.cluster</code> 结构体的相应变量，表示已经记下了。</p><p>在每个 cluster 节点中，都有一个 <code>clusterState</code> 结构体，用来保存集群信息，其中 <code>importing_slots_from</code> 变量表示要迁入本节点的 slot 信息，而 <code>migrating_slots_to</code> 变量表示要迁出本节点的 slot 信息，它们都是 16384 长度的数组。</p><h2 id="标记 -migrating">标记 migrating</h2><p>在源节点 A  执行命令 <code>SETSLOT 10 MIGRATING &lt;B 的 nodeID&gt;</code>，标记有一个 slot (10) 将要从本节点 A 迁出到目标节点 B。<br>此时，在 A 上使用 <code>cluster nodes</code> 命令查看集群路由现状，可以发现，在 A 负责的 slot 信息里有这样的标记<code>[10-&gt;-B nodeid]</code>。（其他节点不知道这件事）</p><p>具体代码执行逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {    ....    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;setslot&quot;) &amp;&amp; c-&gt;argc &gt;= 4) {        ....          if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;migrating&quot;) &amp;&amp; c-&gt;argc == 5) {addReplyErrorFormat(c,&quot;I'm not the owner of hash slot %u&quot;,slot);                return;            }            if ((n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr)) == NULL) {addReplyErrorFormat(c,&quot;I don't know about node %s&quot;, (char*)c-&gt;argv[4]-&gt;ptr);                return;            }            server.cluster-&gt;migrating_slots_to[slot] = n; // 标记 slot 的目的地        }        ....    }    .....}</code></pre><p>当接收到 <code>setslot</code> 命令时，匹配到关于设置 slot  migrating 状态的逻辑。<br>首先是一些参数的校验。</p><ul><li>检查 slot x 是不是我负责的，如果不是，报错 <strong>I’m not the owner of hash slot x</strong>。（不是我负责的 slot，我无权迁出）</li><li>检查目的节点我是否认识，如果不认识的话，报错 <strong>I don’t know about node</strong>。（不认识目的节点，我怎么迁出？）</li></ul><p>然后，修改 <code>server.cluster</code> 结构体相应变量，表示已经记下了。</p><p class="note note-warning">应该先在迁入节点标记 slot 的 importing 状态，后在迁出节点标记 slot 的 migrating 状态。若颠倒顺序的话，会有一些问题。<br><br>假设这样的场景，在迁出节点设置了 slot 的 migrating 状态。之后访问迁出节点 slot 的写命令，会被重定向到迁入节点（没有 key 就会重定向），但是此时迁入节点 slot 还没有做标记，所以又会产出一个 MOVED 错误，如此循环往复。说到底还是因为这些命令的执行是分开的，而非原子的。</p><h2 id="源节点从 -slot- 中取 -key">源节点从 slot 中取 key</h2><p>经过前面两步，将要迁移的 slot 在源节点和目的节点都进行的标记。 现有的 redis cluster 中数据迁移的基本单位是 key，因此要先取出要迁移的一部分 key，有 <code>GETKEYSINSLOT</code> 命令可以使用，全格式为 <code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>。</p><p>具体代码逻辑如下，</p><pre><code class="language-c">void clusterCommand(client *c) {    ......    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;getkeysinslot&quot;) &amp;&amp; c-&gt;argc == 4) {        /* CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt; */        long long maxkeys, slot;        unsigned int numkeys, j;        robj **keys;        if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;slot,NULL) != C_OK)            return;        if (getLongLongFromObjectOrReply(c,c-&gt;argv[3],&amp;maxkeys,NULL)            != C_OK)            return;        if (slot &lt; 0 || slot &gt;= CLUSTER_SLOTS || maxkeys &lt; 0) {addReplyError(c,&quot;Invalid slot or number of keys&quot;);            return;        }        keys = zmalloc(sizeof(robj*)*maxkeys);        numkeys = getKeysInSlot(slot, keys, maxkeys);        addReplyMultiBulkLen(c,numkeys);        for (j = 0; j &lt; numkeys; j++) addReplyBulk(c,keys[j]);        zfree(keys);    }    .....}</code></pre><p>首先，解析参数，</p><ul><li><p>从哪个 slot 取数据？存到变量 slot 中。</p></li><li><p>这一次取多少个 key？存到变量 maxkeys 中。</p></li></ul><p>然后，分配内存，使用 <code>getKeysInSlot</code> 函数从跳表 <code>server.cluster-&gt;slots_to_keys</code> 中取出 slot x 里最多 maxkeys 个 key，存入数组 keys 中，<code>getKeysInSlot</code> 函数返回实际取得的 key 的数量。<br>最后，响应客户端 OK，并释放内存。</p><h2 id="migrate-keys- 过程">migrate keys 过程</h2><h3 id="源节点处理">源节点处理</h3><p>使用上一步取出来的 key，使用 <code>MIGRATE</code> 命令进行 key 的搬迁。</p><pre><code class="language-c">MIGRATE host port &quot;&quot; dbid timeout [COPY | REPLACE] KEYS key1 key2 ... keyN</code></pre><p>正常流程中，将 key 搬迁到目标节点以后，会其从源节点删除掉，但是命令中的 <strong>COPY</strong> 和 <strong>REPLACE</strong> 选项会使得此过程有不同的表现。</p><ul><li><p>COPY ：目的节点如果已经存在要搬迁的 key，会报错。且 key 搬迁完成后，源节点也不会删掉这个 key。</p></li><li><p>REPLACE：不管目的节点是否存在要迁移的 key，都覆盖它。</p></li><li><p>两个选项都不要。目的节点如果已经存在要搬迁的 key，会报错。</p></li></ul><h4 id="一些初始化">一些初始化</h4><p><code>MIGRATE</code> 命令使用函数 <code>migrateCommand</code> 进行处理。</p><p>首先，进行一些参数校验以及变量的初始化。<br>如果 timeout 选项解析出来 &lt;=0，那么设置为默认值 1s。timeout 值用来做建链接接超时，以及后面的读写超时。<br>将要迁移的 key 保存到数组 kv 中，相应的 value 保存到数组 ov 中 ，代码如下，</p><pre><code class="language-c">ov = zrealloc(ov,sizeof(robj*)*num_keys);kv = zrealloc(kv,sizeof(robj*)*num_keys);int oi = 0;for (j = 0; j &lt; num_keys; j++) {if ((ov[oi] = lookupKeyRead(c-&gt;db,c-&gt;argv[first_key+j])) != NULL) {kv[oi] = c-&gt;argv[first_key+j];        oi++;    }}num_keys = oi;if (num_keys == 0) {zfree(ov); zfree(kv);    addReplySds(c,sdsnew(&quot;+NOKEY\r\n&quot;));    return;}</code></pre><p class="note note-warning">由于 key 的过期或者主从删除等原因，这里的 oi 的值很可能跟 num_keys 是不一致的，如果 key 都没有了，也就是不用再迁移了，那么返回信息 +NOKEY。</p><h4 id="建立连接">建立连接</h4><p>然后，跟要迁入 key 的目的节点建立连接。代码如下，</p><pre><code class="language-c">/* Connect */cs = migrateGetSocket(c,c-&gt;argv[1],c-&gt;argv[2],timeout);if (cs == NULL) {zfree(ov); zfree(kv);    return; /* error sent to the client by migrateGetSocket() */}</code></pre><p>可以看到，代码中根据命令参数 host 和 port 使用 <code>migrateGetSocket</code> 函数可拿到一个可用的连接，该函数逻辑可以参考附录。</p><h4 id="填充 -cmd- 信息">填充 cmd 信息</h4><p>拿到可用的连接后，接着就需要将要搬迁的 key 以 <strong>redis 协议的格式 </strong> 发送到目的节点，具体格式如下，</p><pre><code class="language-c">*4\r\n (或 *5\r\n)$14\r\nRESTORE-ASKING\r\n (或 $7\r\nRESTORE\r\n)$&lt;count&gt;\r\n&lt;payload&gt;\r\n (key 信息)$&lt;count&gt;\r\n&lt;payload&gt;\r\n (ttl 信息)$&lt;count&gt;\r\n&lt;payload&gt;\r\n (value dump 信息)$7\r\nREPLACE\r\n (根据情况决定是否有这个参数)</code></pre><p>可以看到使用的是 <code>RESTORE-ASKING</code> 或者 <code>RESTORE</code> 的命令。</p><p>下面看填充 cmd 的具体代码分析。</p><pre><code class="language-c">rio cmd, payload;rioInitWithBuffer(&amp;cmd,sdsempty());</code></pre><p>首先，使用 <code>rio</code> 类型的变量 cmd 存放要发给目的节点的 redis 协议格式的命令，下面就开始使用要迁移的 key/value 组装数据。<br>看下是否需要切换数据库，有必要的话，强制发 <code>SELECT &lt;dbid&gt;</code> 。</p><pre><code class="language-c">int select = cs-&gt;last_dbid != dbid; /* Should we emit SELECT? */if (select) {serverAssertWithInfo(c,NULL,rioWriteBulkCount(&amp;cmd,'*',2));    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;SELECT&quot;,6));    serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,dbid));}</code></pre><p>下面是针对每一个 key 进行的处理，具体代码如下，</p><pre><code class="language-c">long long ttl = 0;long long expireat = getExpire(c-&gt;db,kv[j]);if (expireat != -1) {ttl = expireat-mstime();    if (ttl &lt; 1) ttl = 1;}</code></pre><p>首先将 key 的过期时间从绝对时间转成相对时间，记录在 ttl 中。<br>根据前面命令传入的选项是 replace 还是 copy，决定发送命令的参数个数。</p><pre><code class="language-c">serverAssertWithInfo(c,NULL,rioWriteBulkCount(&amp;cmd,'*',replace ? 5 : 4));</code></pre><pre><code class="language-c">if (server.cluster_enabled)    serverAssertWithInfo(c,NULL,                rioWriteBulkString(&amp;cmd,&quot;RESTORE-ASKING&quot;,14));else    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;RESTORE&quot;,7));</code></pre><p>如果当前处于集群模式下，则向 cmd 中填充 <code>RESTORE-ASKING</code> 命令，否则填充 <code>RESTORE</code> 命令。<br>然后，对每个 key 的信息进行填充，</p><pre><code class="language-c">// 填充 key 的信息serverAssertWithInfo(c,NULL,sdsEncodedObject(kv[j]));serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,kv[j]-&gt;ptr,                sdslen(kv[j]-&gt;ptr)));// 填充 ttl 信息serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,ttl));// 填充 value 的信息createDumpPayload(&amp;payload,ov[j]);serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,payload.io.buffer.ptr,    sdslen(payload.io.buffer.ptr)));sdsfree(payload.io.buffer.ptr);</code></pre><p>value 的值，要使用 <code>createDumpPayload</code> 函数进行 rdb 序列化，具体格式如下，</p><pre><code class="language-c">/* Write the footer, this is how it looks like: * ----------------+---------------------+---------------+ * ... RDB payload | 2 bytes RDB version | 8 bytes CRC64 | * ----------------+---------------------+---------------+ * RDB version and CRC are both in little endian. */</code></pre><p>序列化过程在函数 <code>createDumpPayload</code> 中，在此就不做分析了。<br>最后根据 replace 变量，决定是否要填充 <strong>REPLACE</strong>，即，</p><pre><code class="language-c">if (replace)    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;REPLACE&quot;,7));</code></pre><p>这样，所有要迁移的 key 也就序列化到 cmd 这个 <code>rio</code> 变量里了。下面就要发给目的节点了。</p><h4 id="发送到目的节点">发送到目的节点</h4><p>组装完 cmd，就要把它们发送到对端，代码逻辑如下，</p><pre><code class="language-c">sds buf = cmd.io.buffer.ptr;size_t pos = 0, towrite;int nwritten = 0;while ((towrite = sdslen(buf)-pos) &gt; 0) {towrite = (towrite &gt; (64*1024) ? (64*1024) : towrite);    nwritten = syncWrite(cs-&gt;fd,buf+pos,towrite,timeout);    if (nwritten != (signed)towrite) {        write_error = 1;        goto socket_err;     }     pos += nwritten;}</code></pre><p>循环调用 <code>syncWrite</code> 函数，向远端 Redis <strong>同步 </strong> 发送 cmd 中的内容，每次最多发送 <strong>64k</strong> 个字节。</p><h4 id="对目的节点回复的处理">对目的节点回复的处理</h4><p>定义两个变量，接收对端的回复。</p><pre><code class="language-c">char buf1[1024]; /* Select reply. */char buf2[1024]; /* Restore reply. */</code></pre><pre><code class="language-c">// 如果前面发送了 select 命令，那么需要先读取此命令的回复if (select &amp;&amp; syncReadLine(cs-&gt;fd, buf1, sizeof(buf1), timeout) &lt;= 0)    goto socket_err;</code></pre><p>下面同步读取每一个 restore key 的返回值，具体逻辑如下，</p><pre><code class="language-c">if (syncReadLine(cs-&gt;fd, buf2, sizeof(buf2), timeout) &lt;= 0) {     socket_error = 1;     break;}if ((select &amp;&amp; buf1[0] == '-') || buf2[0] == '-') {    /* On error assume that last_dbid is no longer valid. */   if (!error_from_target) {       cs-&gt;last_dbid = -1;       addReplyErrorFormat(c,&quot;Target instance replied with error: %s&quot;,           (select &amp;&amp; buf1[0] == '-') ? buf1+1 : buf2+1);       error_from_target = 1;   }} else {if (!copy) {        /* No COPY option: remove the local key, signal the change. */        dbDelete(c-&gt;db,kv[j]);        signalModifiedKey(c-&gt;db,kv[j]);        server.dirty++;        /* Populate the argument vector to replace the old one. */         newargv[del_idx++] = kv[j];         incrRefCount(kv[j]);    }}</code></pre><p>首先将对端回复读取变量 <strong>buf2</strong> 里。<br>如果 <strong>buf1</strong> 或者 <strong>buf2</strong> 首字母是字符 <code>-</code>，说明遇到了错误，那么将连接中的  <code>last_dbid</code> 置为 -1，这样下次再使用时，会强制发送 <code>SELECT</code> 命令。<br>如果 <code>MIGRATE</code> 命令中没有使用 <strong>COPY</strong>  选项，那么需要将搬迁到目标节点的 key 从本地删除掉。同时记录在数组 <code>newargv</code> 中，<strong>以方便后面修改命令，传播到副本中</strong>。</p><p>具体逻辑如下，</p><pre><code class="language-c">if (!copy) {if (del_idx &gt; 1) {newargv[0] = createStringObject(&quot;DEL&quot;,3);        replaceClientCommandVector(c,del_idx,newargv);        argv_rewritten = 1;    } else {zfree(newargv);    }   newargv = NULL;}</code></pre><p>将 <code>MIGRATE</code> 命令改成 <code>DEL</code> 命令。</p><h4 id="回复 -client- 与错误处理">回复 client 与错误处理</h4><pre><code class="language-c">if (socket_error) migrateCloseSocket(c-&gt;argv[1],c-&gt;argv[2]);if (!copy) {....}</code></pre><p><code>socket_error</code> 在同步读取对端回复时，有可能遇到。当发生这个错误时，直接关掉这个 socket。</p><p class="note note-warning">这里并没有返回，这是因为，对于已经迁移成功的 key，后面还是要做命令转换的，因此不能直接返回。</p><p>如果没有发生错误，就可以给 client 正确的回复了。</p><pre><code class="language-c">if (!error_from_target) {    cs-&gt;last_dbid = dbid;    addReply(c,shared.ok);} else {}</code></pre><p>成功了，更改连接中的 <code>last_dbid</code> 为本次使用的 dbid，留着下一次用，避免下次再发送 <code>SELECT</code> 命令。<br>如果写命令或者读回复发生错误，而且若 <strong> 不是超时错误 </strong> 的话，那么可以重试一次。</p><pre><code class="language-c">if (errno != ETIMEDOUT &amp;&amp; may_retry) {    may_retry = 0;    goto try_again;}</code></pre><p><strong>try_again</strong> 会跳到前面重新填 cmd，再来一遍，否则会回复 client 错误。</p><pre><code class="language-c">addReplySds(c, sdscatprintf(sdsempty(),    &quot;-IOERR error or timeout %s to target instance\r\n&quot;,    write_error ? &quot;writing&quot; : &quot;reading&quot;));</code></pre><p class="note note-danger">从上面的分析，<br><br>为了避免同一个 key 出现在两个节点中，在源节点上，涉及到向目标节点建链、发送命令和等待回复的过程，都是同步的。如果遇到大 key，那么搬迁时间会比较长，此时会堵塞住进来请求的 client，甚至有可能触发 failover。<br><br>所以，不建议一次性搬移过多的 key，而且要提前解决掉 大 key 的问题。<br><br>目前业界已经有以主从复制的思路，以 slot 为单位进行数据搬迁了，能很好解决大 key 问题。</p><h3 id="目的节点的处理">目的节点的处理</h3><p>对端接收到 <code>RESTORE-ASKING</code> 或 <code>RESTORE</code> 命令后，使用函数 <code>restoreCommand</code> 进行逻辑处理。<br>首先检查第 4 个参数是否为 replace。</p><pre><code class="language-c">for (j = 4; j &lt; c-&gt;argc; j++) {if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;replace&quot;)) {replace = 1;} else {addReply(c,shared.syntaxerr);         return;    }}</code></pre><p><strong>如果有 </strong> 第 4 个参数，那么一定是  replace ，否则就报语法错误 <strong>-ERR syntax error</strong>。当然也有可能没有，这时 replace = 0。<br>如果 replace = 0，且当前数据库中已经有个这个 key，报错 <strong>-BUSYKEY Target key name already exists</strong><br>取出 ttl 信息，且它一定是个 &gt; 0 的数值。</p><pre><code class="language-c">if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;ttl,NULL) != C_OK) {return;} else if (ttl &lt; 0) {addReplyError(c,&quot;Invalid TTL value, must be &gt;= 0&quot;);    return;}</code></pre><p>接着解析第 3 个参数，应该是 value 的 dump 信息了。</p><pre><code class="language-c">/* Verify RDB version and data checksum. */if (verifyDumpPayload(c-&gt;argv[3]-&gt;ptr,sdslen(c-&gt;argv[3]-&gt;ptr)) == C_ERR) {addReplyError(c,&quot;DUMP payload version or checksum are wrong&quot;);    return;}rioInitWithBuffer(&amp;payload,c-&gt;argv[3]-&gt;ptr);if (((type = rdbLoadObjectType(&amp;payload)) == -1) ||    ((obj = rdbLoadObject(type,&amp;payload)) == NULL)) {addReplyError(c,&quot;Bad data format&quot;);    return;}</code></pre><p>先校验一下这个 dump 信息是否符合规范，然后分别使用 <code>rdbLoadObjectType</code> 函数和 <code>rdbLoadObject</code> 函数，将 type 和 obj 还原。<br>接着对本地数据库进行处理，代码如下，</p><pre><code class="language-c">if (replace) dbDelete(c-&gt;db,c-&gt;argv[1]);/* Create the key and set the TTL if any */dbAdd(c-&gt;db,c-&gt;argv[1],obj);if (ttl) setExpire(c-&gt;db,c-&gt;argv[1],mstime()+ttl);signalModifiedKey(c-&gt;db,c-&gt;argv[1]);addReply(c,shared.ok);server.dirty++;</code></pre><p>如果有 replace，就要从本地删除原来的 key，使用从源节点传过来的值进行覆盖。<br>有 ttl 的话，再设置一下过期时间。<br>最后，回复客户端 &quot;OK&quot; 信息；</p><p><strong>以上，就完成了一个 key 的迁移过程。</strong></p><h2 id="设置 -slot- 最终归属">设置 slot 最终归属</h2><p>当 slot 中的 key 全部搬迁完之后，<br>使用 <code>CLUSTER SETSLOT &lt;SLOT&gt; NODE &lt;NODE ID&gt;</code> 命令设置 slot。</p><p>先在目标节点设置，消除 importing 标记。<br>再在源节点设置， 消除 migrating 标记。</p><p>为了让整个集群都感知到新的 slot 归属，可以给集群其他节点都发一遍，当然了，也可以等着 gossip 消息，但是在大集群中扩散过程就比较慢了。</p><p class="note note-warning">注意上面的顺序!!<br><br>如果先取消到 migrating 标记，且还没有取消 importing 标记，那么迁出节点会认为这个 slot 属于迁入节点了，所以读写访问时，会 MOVED 到迁入节点，但是在迁入节点来看这个节点不属于自己，且没有 ASK 重定向，所以会重新 MOVED 到迁出节点。所以产生一个 pingpong 的过程。<br><br>而按照上面的顺序的话，如果有访问到正在迁出的 slot，那么会 ASK 重定向到迁入节点，在迁入节点看来，这个 slot 是属于自己的，正常处理，不会发生错误。</p><p class="note note-primary">这个顺序跟开始迁移时是一致的，先处理迁入节点，再处理迁出节点。</p><p>下面看这个命令的实际处理过程，部分代码如下，</p><pre><code class="language-c">else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,&quot;node&quot;) &amp;&amp; c-&gt;argc == 5) {clusterNode *n = clusterLookupNode(c-&gt;argv[4]-&gt;ptr);    if (!n) {addReplyErrorFormat(c,&quot;Unknown node %s&quot;, (char*)c-&gt;argv[4]-&gt;ptr);        return;    }    ...}</code></pre><pre><code class="language-c">if (server.cluster-&gt;slots[slot] == myself &amp;&amp; n != myself) {if (countKeysInSlot(slot) != 0) {        addReplyErrorFormat(c,            &quot;Can't assign hashslot %d to a different node &quot;             &quot;while I still hold keys for this hash slot.&quot;, slot);        return;     }}</code></pre><p>首先还是一些参数校验。</p><ul><li><p>参数传入的 node 我是否认识，不认识的话，报错退出。</p></li><li><p>参数传入的 slot 是我负责的，且 node 是别人。这时就要看下，这个 slot 里的 key 是否已经全部搬迁完了，如果不是，那么报错。（key 都没有迁完，怎么能把 slot 给别人呢？会丢数据的）。如果 slot 不是我的，那么我就抱着看热闹的心态，跳过这个检查就好了。</p></li></ul><p>下面就是 slot 状态的消除了，主要代码如下，</p><pre><code class="language-c"> if (countKeysInSlot(slot) == 0 &amp;&amp;     server.cluster-&gt;migrating_slots_to[slot])     server.cluster-&gt;migrating_slots_to[slot] = NULL;</code></pre><p>如果 slot 中没有 key，并且处于 <strong>migrating</strong> 状态（也就说这是针对源节点的操作），那么把迁出状态取消。<br>接下来，对于 <strong>importing</strong> 状态的目标节点，发布最新的路由，代码如下，</p><pre><code class="language-c">if (n == myself &amp;&amp; server.cluster-&gt;importing_slots_from[slot]){if (clusterBumpConfigEpochWithoutConsensus() == C_OK) {serverLog(LL_WARNING, &quot;configEpoch updated after importing slot %d&quot;, slot);    }    server.cluster-&gt;importing_slots_from[slot] = NULL;}</code></pre><p>使用 <code>clusterBumpConfigEpochWithoutConsensus</code> 函数，<strong>自行增加自己的 config epoch 值</strong>。</p><p>本函数违反了 config epochs 应经过集群达成共识后产生，且在整个 cluster 内是唯一的。<br>然而 Redis Cluster 在以下两种情况下使用自动生成的新 config epochs：</p><ul><li><p>当 slots 在 importing 后关闭。否则，resharding 的代价太昂贵。</p></li><li><p>当 CLUSTER FAILOVER 强制一个 slave failover 的选项调用时，即使没有大多数 master 同意也要产生一个新的 epoch。</p></li></ul><p>如果本节点的 config epoch 值不是集群中最大的，那么会取到最大的，然后 +1，作为现在的 config epoch 和 current epoch。<br>最后变更路由，代码如下，</p><pre><code class="language-c">clusterDelSlot(slot);clusterAddSlot(n,slot);</code></pre><p><strong>至此，就把完成了一个完整的迁移流程</strong>。</p><h2 id="附录">附录</h2><h3 id="migrateGetSocket- 函数分析">migrateGetSocket 函数分析</h3><p>主要代码如下，</p><pre><code class="language-c">migrateCachedSocket* migrateGetSocket(client *c, robj *host, robj *port, long timeout) {    ...    cs = dictFetchValue(server.migrate_cached_sockets,name);    if (cs) {sdsfree(name);        cs-&gt;last_use_time = server.unixtime;        return cs;    }    /* No cached socket, create one. */    if (dictSize(server.migrate_cached_sockets) == MIGRATE_SOCKET_CACHE_ITEMS) {        /* Too many items, drop one at random. */        dictEntry *de = dictGetRandomKey(server.migrate_cached_sockets);        cs = dictGetVal(de);        close(cs-&gt;fd);        zfree(cs);        dictDelete(server.migrate_cached_sockets,dictGetKey(de));    }    fd = anetTcpNonBlockConnect(server.neterr, c-&gt;argv[1]-&gt;ptr, atoi(c-&gt;argv[2]-&gt;ptr));    ...    anetEnableTcpNoDelay(server.neterr,fd);   /* Check if it connects within the specified timeout. */    if ((aeWait(fd,AE_WRITABLE,timeout) &amp; AE_WRITABLE) == 0) {sdsfree(name);        addReplySds(c,            sdsnew(&quot;-IOERR error or timeout connecting to the client\r\n&quot;));        close(fd);        return NULL;    }    /* Add to the cache and return it to the caller. */    cs = zmalloc(sizeof(*cs));    cs-&gt;fd = fd;    cs-&gt;last_dbid = -1;    cs-&gt;last_use_time = server.unixtime;    dictAdd(server.migrate_cached_sockets,name,cs); }</code></pre><p>通过以上代码可以看到，对于连接过程中的 socket fd 封装到结构体 <code>migrateCachedSocket</code>，存入 <code>server.migrate_cached_sockets</code> 这个 dict 中。</p><pre><code class="language-c">typedef struct migrateCachedSocket {   int fd;   long last_dbid;   time_t last_use_time;} migrateCachedSocket;</code></pre><p><code>migrateCachedSocket</code> 结构体包含 socket fd，上一次迁移数据用到的 db，以及连接上一次使用的时间 <code>last_use_time</code>。<br>将 socket 缓存下来的目的是，当要迁移的 key 很多时，一次 migrate 命令是迁不完的，缓存下来 socket 可以减少创建成本。</p><p><code>last_use_time</code> 变量存在的意义是，为了节省资源，缓存的连接需要做定期清理，该逻辑在函数 <code>migrateCloseTimedoutSockets</code> 中，如果一个连接 <strong>10 s</strong> 未使用，就把它 close 掉。</p><p><code>last_dbid</code> 的作用是，强制发送 <code>SELECT</code> 命令，以切换数据库。</p><p>当缓存的连接数量足够多时，会随机剔除一个，以容纳新的连接。</p><p>然后，设置 fd 为非阻塞式的，在给定时间内，看一下是否连接成功了。成功后返回一个 <code>migrateCachedSocket</code> 类型的变量，并放到 <code>migrate_cached_sockets</code> 中缓存起来。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之主从复制 (4)</title>
    <link href="/9025979a.html"/>
    <url>/9025979a.html</url>
    
    <content type="html"><![CDATA[<p>在上一篇文章，主要介绍了主从复制流程中 slave 的状态机流转，本篇文章中，将做相应的 master 逻辑的相关分析。</p><a id="more"></a><h2 id="主从建链与握手阶段">主从建链与握手阶段</h2><blockquote><p>slave 在向 master 发起 TCP 建链，以及复制握手过程中，master 一直把 slave 当成一个普通的 client 来处理。也就是说，不为 slave 保存状态，只是收到 slave 发来的命令进而处理并回复而已。</p></blockquote><h3 id="PING- 命令处理">PING 命令处理</h3><p>握手过程中，首先 slave 会发过来一个 PING 命令，master 使用 <strong>pingCommand</strong> 函数来进行处理。回复字符串 <strong>+PONG</strong>，还是权限错误，视情况而定。</p><h3 id="AUTH- 命令处理">AUTH 命令处理</h3><p>可能会有一个鉴权过程，master 收到 slave 发来 AUTH 命令，使用 <strong>authCommand</strong> 函数进行处理，代码大概如下，</p><pre><code class="language-c">void authCommand(client *c) {if (!server.requirepass) { // 未设置 auth passwd        addReplyError(c,&quot;Client sent AUTH, but no password is set&quot;);    } else if (!time_independent_strcmp(c-&gt;argv[1]-&gt;ptr, server.requirepass)) {      c-&gt;authenticated = 1;      addReply(c,shared.ok);    } else {      c-&gt;authenticated = 0;      addReplyError(c,&quot;invalid password&quot;);    }}</code></pre><p>client 的 <strong>authenticated</strong> 属性表明 server 是否设置了鉴权。</p><h3 id="REPLCONF- 命令处理">REPLCONF 命令处理</h3><p>接下来就是 REPLCONF 命令，相应处理函数为 <strong>replconfCommand</strong>，用于保存 slave 告知的端口号、地址和能力等。该函数代码逻辑基本如下，</p><p>首先进行必要的参数校验，命令格式为 <code>REPLCONF &lt;option&gt; &lt;value&gt; &lt;option&gt; &lt;value&gt; ...</code>，可以看出，后面的参数值是成对出现的，加上 REPLCONF 本身，参数个数肯定是奇数个，那么偶数个就肯定是有问题的。</p><pre><code class="language-c">if ((c-&gt;argc % 2) == 0) {    /* Number of arguments must be odd to make sure that every     * option has a corresponding value. */    addReply(c,shared.syntaxerr);    return;}</code></pre><p>接着，匹配到各选项分别处理，目前支持的选项有 listening-port、ip-address、capa、ack 和 getack，不支持的选项在报错后会返回，代码处理如下，</p><pre><code class="language-c">for (j = 1; j &lt; c-&gt;argc; j+=2) {if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;listening-port&quot;)) {        long port;        if ((getLongFromObjectOrReply(c,c-&gt;argv[j+1],                &amp;port,NULL) != C_OK))            return;        c-&gt;slave_listening_port = port;    } else if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;ip-address&quot;)) {sds ip = c-&gt;argv[j+1]-&gt;ptr;        if (sdslen(ip) &lt; sizeof(c-&gt;slave_ip)) {memcpy(c-&gt;slave_ip,ip,sdslen(ip)+1);        } else {            addReplyErrorFormat(c,&quot;REPLCONF ip-address provided by &quot;                &quot;slave instance is too long: %zd bytes&quot;, sdslen(ip));            return;        }    } else if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;capa&quot;)) {        /* Ignore capabilities not understood by this master. */        if (!strcasecmp(c-&gt;argv[j+1]-&gt;ptr,&quot;eof&quot;))            c-&gt;slave_capa |= SLAVE_CAPA_EOF;    } else if {.....}    } else {        addReplyErrorFormat(c,&quot;Unrecognized REPLCONF option: %s&quot;,            (char*)c-&gt;argv[j]-&gt;ptr);        return;    }}</code></pre><h2 id="主从复制阶段">主从复制阶段</h2><p>接下来，slave 会向 master 发送 SYNC/PSYNC 命令，请求进行完全重同步或者部分重同步。master 为 slave 保存的状态记录在 client 的 <strong>replstate</strong> 属性中。</p><p>从 master 的角度看，slave 需要经历的如下状态：<strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> → <strong>SLAVE_REPL_WAIT_BGSAVE_END</strong> → <strong>SLAVE_REPL_SEND_BULK</strong> → <strong>SLAVE_REPL_ONLINE</strong>。状态转换图在前一篇文章开头画过，这里不做赘述。</p><h3 id="SYNC-PSYNC- 命令处理">SYNC/PSYNC 命令处理</h3><p>SYNC/PSYNC 命令的处理函数为 <strong>syncCommand</strong>。</p><h4 id="前置 -check">前置 check</h4><p>首先，需要做一些必要的 check。</p><pre><code class="language-c">/* ignore SYNC if already slave or in monitor mode */if (c-&gt;flags &amp; CLIENT_SLAVE) return;// 本节点是其他节点的 slave，但是还没有同步好数据，// 此时不能为本节点的 slave 进行数据同步(因为数据不全)if (server.masterhost &amp;&amp; server.repl_state != REPL_STATE_CONNECTED) {addReplyError(c,&quot;Can't SYNC while not connected with my master&quot;);    return;}/* 因为 master 接下来需要为该 slave 进行后台 RDB 数据转储了， * 同时需要将前台接收到的其他 client 命令请求缓存到该 slave client 的输出缓存中， * 这就需要一个完全清空的输出缓存，才能为该 slave 保存从执行 BGSAVE 开始的命令流。 * * 在 master 收到 slave 发来的 SYNC(PSYNC)命令之前，两者之间的交互信息都是比较短的， * 因此，在网络正常的情况下，slave client 中的输出缓存应该是很容易就发送给该 slave，并清空的。 * 所以，如果不为空，说明可能有问题 */if (clientHasPendingReplies(c)) {addReplyError(c,&quot;SYNC and PSYNC are invalid with pending output&quot;);    return;}</code></pre><h4 id="完全重同步 -or- 部分重同步">完全重同步 or 部分重同步</h4><p>下面就开始进入正题，SYNC/PSYNC 命令进行了区别对待。</p><pre><code class="language-c">// slave 发来 psync 命令if (!strcasecmp(c-&gt;argv[0]-&gt;ptr,&quot;psync&quot;)) {if (masterTryPartialResynchronization(c) == C_OK) {        server.stat_sync_partial_ok++;        return; /* No full resync needed, return. */    } else {char *master_runid = c-&gt;argv[1]-&gt;ptr;        /* Increment stats for failed PSYNCs, but only if the         * runid is not &quot;?&quot;, as this is used by slaves to force a full         * resync on purpose when they are not albe to partially         * resync. */        if (master_runid[0] != '?') server.stat_sync_partial_err++;    }// slave 发来 sync 命令} else {    /* If a slave uses SYNC, we are dealing with an old implementation     * of the replication protocol (like redis-cli --slave). Flag the client     * so that we don't expect to receive REPLCONF ACK feedbacks. */    c-&gt;flags |= CLIENT_PRE_PSYNC; // 老版本实例}</code></pre><p>从上面代码可以看出，当需要进行 <strong> 部分重同步 </strong> 时，函数会直接返回，否则，开始着手处理 <strong> 完全重同步 </strong> 的情况，此时 master 要执行一次 rdb 。</p><p>处理 PSYNC 命令的函数是 <strong>masterTryPartialResynchronization</strong>，该函数通过返回值来进行区分是否进行部分重同步，<code>C_OK</code> 表示部分重同步，<code>C_ERR</code> 表示完全重同步，下面进行具体分析。</p><p>首先，把自己的 runid 与 slave 发来的 <strong>master_runid</strong> 相匹配，如果不匹配，说明是一个新的 slave，此时需要进行 <strong> 完全重同步</strong>，代码如下。</p><pre><code class="language-c">char *master_runid = c-&gt;argv[1]-&gt;ptr;... ...if (strcasecmp(master_runid, server.runid)) {    // slave 通过发送 runid 为 `？` 来触发一次完全重同步。    if (master_runid[0] != '?') {        serverLog(LL_NOTICE,&quot;Partial resynchronization not accepted: &quot;            &quot;Runid mismatch (Client asked for runid '%s', my runid is '%s')&quot;,            master_runid, server.runid);    } else {        serverLog(LL_NOTICE,&quot;Full resync requested by slave %s&quot;,            replicationGetSlaveName(c));    }    goto need_full_resync;}</code></pre><p>然后，取出 slave 的复制偏移量 <strong>psync_offset</strong>，master 据此来判断是否可以进行完全重同步，关于复制偏移量的问题，前面的文章已经提过。</p><pre><code class="language-c">if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;psync_offset,NULL) !=    C_OK) goto need_full_resync;if (!server.repl_backlog ||    psync_offset &lt; server.repl_backlog_off ||    psync_offset &gt; (server.repl_backlog_off + server.repl_backlog_histlen)){    serverLog(LL_NOTICE,        &quot;Unable to partial resync with slave %s for lack of backlog (Slave request was: %lld).&quot;, replicationGetSlaveName(c), psync_offset);    if (psync_offset &gt; server.master_repl_offset) {        serverLog(LL_WARNING,            &quot;Warning: slave %s tried to PSYNC with an offset that is greater than the master replication offset.&quot;, replicationGetSlaveName(c));    }    goto need_full_resync;}</code></pre><p>以上出现的两种需要进行完全重同步的情况，都会进入 <strong>need_full_resync</strong> 的逻辑，最后返回 <code>C_ERR</code>。</p><pre><code class="language-c">need_full_resync:    /* We need a full resync for some reason... Note that we can't     * reply to PSYNC right now if a full SYNC is needed. The reply     * must include the master offset at the time the RDB file we transfer     * is generated, so we need to delay the reply to that moment. */    return C_ERR;</code></pre><p>否则，表示需要进行部分重同步，进行相应变量的初始化，返回<code>C_OK</code>。</p><pre><code class="language-c">c-&gt;flags |= CLIENT_SLAVE;c-&gt;replstate = SLAVE_STATE_ONLINE;c-&gt;repl_ack_time = server.unixtime;c-&gt;repl_put_online_on_ack = 0;listAddNodeTail(server.slaves,c);// 这里不能用输出缓存，因为输出缓存只能用于累积命令流。// 之前 master 向 slave 发送的信息很少，因此内核的输出缓存中应该会有空间，// 所以，这里直接的 write 操作一般不会出错。// 回复 slave +CONTINUEbuflen = snprintf(buf,sizeof(buf),&quot;+CONTINUE\r\n&quot;);if (write(c-&gt;fd,buf,buflen) != buflen) {freeClientAsync(c);    return C_OK;}// 将积压队列中 psync_offset 之后的数据复制到客户端输出缓存中psync_len = addReplyReplicationBacklog(c,psync_offset);/* Note that we don't need to set the selected DB at server.slaveseldb * to -1 to force the master to emit SELECT, since the slave already * has this state from the previous connection with the master. */// 更新当前状态正常的 slave 数量refreshGoodSlavesCount();return C_OK; /* The caller can return, no full resync needed. */</code></pre><p><strong>addReplyReplicationBacklog</strong> 函数的逻辑也已经在前面讲过。</p><h4 id="完全重同步过程">完全重同步过程</h4><p>首先，一些变量的更新，将 <strong>replstate</strong> 更新为 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> 状态。</p><pre><code class="language-c">server.stat_sync_full++;/* Setup the slave as one waiting for BGSAVE to start. The following code    * paths will change the state if we handle the slave differently. */c-&gt;replstate = SLAVE_STATE_WAIT_BGSAVE_START;if (server.repl_disable_tcp_nodelay)    anetDisableTcpNoDelay(NULL, c-&gt;fd); /* Non critical if it fails. */c-&gt;repldbfd = -1;c-&gt;flags |= CLIENT_SLAVE;listAddNodeTail(server.slaves,c);</code></pre><p>完全重同步时，master 需要做一次 rdb。后台 rdb 数据生成时需要做 <code>fork</code>，这对性能是有所牺牲的，所以要先看下是否有现成的 rdb 数据可以复用。分以下 3 种清理，</p><p>【1】如果后台有 rdb 任务在执行，并且使用的是 <strong> 有硬盘复制 </strong> 的方式（将 rdb 数据保存在本地临时文件），然后发送给 slave。</p><pre><code class="language-c">/* CASE 1: BGSAVE is in progress, with disk target. */if (server.rdb_child_pid != -1 &amp;&amp;    server.rdb_child_type == RDB_CHILD_TYPE_DISK){    /* Ok a background save is in progress. Let's check if it is a good     * one for replication, i.e. if there is another slave that is     * registering differences since the server forked to save. */    client *slave;    listNode *ln;    listIter li;    listRewind(server.slaves,&amp;li);    while((ln = listNext(&amp;li))) {        slave = ln-&gt;value;        if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_END) break;    }    /* To attach this slave, we check that it has at least all the     * capabilities of the slave that triggered the current BGSAVE. */    if (ln &amp;&amp; ((c-&gt;slave_capa &amp; slave-&gt;slave_capa) == slave-&gt;slave_capa)) {        /* Perfect, the server is already registering differences for         * another slave. Set the right state, and copy the buffer. */        copyClientOutputBuffer(c,slave);        replicationSetupSlaveForFullResync(c,slave-&gt;psync_initial_offset);        serverLog(LL_NOTICE,&quot;Waiting for end of BGSAVE for SYNC&quot;);    } else {        /* No way, we need to wait for the next BGSAVE in order to         * register differences. */        serverLog(LL_NOTICE,&quot;Can't attach the slave to the current BGSAVE. Waiting for next BGSAVE for SYNC&quot;);    }}</code></pre><p>代码中，在 master 所有 slave 中找到一个处于 <strong>SLAVE_STATE_WAIT_BGSAVE_END</strong> 状态的 slaveX。<br>将 slaveX 输出缓存内容 copy 一份给当前的 client，然后调用函数 <strong>replicationSetupSlaveForFullResync</strong>，将 client 状态设置为 <strong>SLAVE_STATE_WAIT_BGSAVE_END</strong>，并发送 <strong>+FULLRESYNC</strong> 回复，代码如下，</p><pre><code class="language-c">int replicationSetupSlaveForFullResync(client *slave, long long offset) {char buf[128];    int buflen;    slave-&gt;psync_initial_offset = offset;    slave-&gt;replstate = SLAVE_STATE_WAIT_BGSAVE_END;    /* We are going to accumulate the incremental changes for this     * slave as well. Set slaveseldb to -1 in order to force to re-emit     * a SELECT statement in the replication stream. */    server.slaveseldb = -1;    /* Don't send this reply to slaves that approached us with     * the old SYNC command. */    if (!(slave-&gt;flags &amp; CLIENT_PRE_PSYNC)) {buflen = snprintf(buf,sizeof(buf),&quot;+FULLRESYNC %s %lld\r\n&quot;,                          server.runid,offset);        if (write(slave-&gt;fd,buf,buflen) != buflen) {return C_ERR;}    }    return C_OK;}</code></pre><p>这个函数主要做了以下 4 件事：</p><ul><li>设置 slave 的 <strong>psync_initial_offset</strong> 属性，方便后面再进来的 slave，可以最大限度的复用。</li><li>设置 slave 的当前状态为 <strong>WAIT_BGSAVE_END</strong>，表明 slave 可以从这个点来累积前台发过来的命令流，并等待 rdb 转储完成。</li><li>设置 slave 的 <strong>slaveseldb</strong> 属性为 -1，这样可以在开始累积命令流时，强制增加一条 SELECT 命令到客户端输出缓存中，以免第一条命令没有选择数据库。</li><li>给 slave 一个 <strong>+FULLRESYNC</strong> 的回复。</li></ul><p>该函数应当在以下 2 个时刻立即被调用：</p><ul><li>由复制而发起的一次成功的 bgsave 之后；</li><li>找到了一个可以复用的 slave 之后。</li></ul><p>如果找不到一个可以复用的 slave，那么 master 需要在当前的 bgsave 操作完成之后，再执行一次。</p><p>【2】如果后台有 rdb 任务在执行，并且使用的是 <strong> 无硬盘复制 </strong> 的方式。</p><p>此时，当前 slave 无法重用 rdb 数据，必须在当前的 bgsave 操作完成之后，再执行一次。代码如下，</p><pre><code class="language-c">/* CASE 2: BGSAVE is in progress, with socket target. */else if (server.rdb_child_pid != -1 &amp;&amp;            server.rdb_child_type == RDB_CHILD_TYPE_SOCKET){    /* There is an RDB child process but it is writing directly to     * children sockets. We need to wait for the next BGSAVE     * in order to synchronize. */    serverLog(LL_NOTICE,&quot;Current BGSAVE has socket target. Waiting for next BGSAVE for SYNC&quot;);}</code></pre><p>【3】如果后台没有 rdb 任务在执行。</p><p>若当前 slave 使用的是 <strong> 无磁盘化复制 </strong>，那么暂时先不进行 bgsave，把它推迟到 <strong>replicationCron</strong> 函数，这是<strong> 为了等待更多的 slave，以减少执行 bgsave 的次数</strong>，因为使用 diskless 的方式进行主从复制，后来的 slave 不能 attach 到已有 slave 上，只能重新做 bgsave。</p><p>若当前 slave 使用的是 <strong> 有磁盘化复制</strong>，调用 <strong>startBgsaveForReplication</strong> 函数开始一次新的 bgsave，需要注意的是这里要避开后台的 aofrewite。代码如下，</p><pre><code class="language-c">/* CASE 3: There is no BGSAVE is progress. */else {if (server.repl_diskless_sync &amp;&amp; (c-&gt;slave_capa &amp; SLAVE_CAPA_EOF)) {        /* Diskless replication RDB child is created inside         * replicationCron() since we want to delay its start a         * few seconds to wait for more slaves to arrive. */        if (server.repl_diskless_sync_delay)            serverLog(LL_NOTICE,&quot;Delay next BGSAVE for diskless SYNC&quot;);    } else {        /* Target is disk (or the slave is not capable of supporting         * diskless replication) and we don't have a BGSAVE in progress,         * let's start one. */        if (server.aof_child_pid == -1) {startBgsaveForReplication(c-&gt;slave_capa); // 直接进行 bgsave        } else {            serverLog(LL_NOTICE,                &quot;No BGSAVE in progress, but an AOF rewrite is active. &quot;                &quot;BGSAVE for replication delayed&quot;);        }    }}</code></pre><p>最后，如果有必要的话，创建 backlog。</p><pre><code class="language-c">if (listLength(server.slaves) == 1 &amp;&amp; server.repl_backlog == NULL)    createReplicationBacklog();</code></pre><pre><code class="language-c">void createReplicationBacklog(void) {serverAssert(server.repl_backlog == NULL);    server.repl_backlog = zmalloc(server.repl_backlog_size);    server.repl_backlog_histlen = 0;    server.repl_backlog_idx = 0;    // 避免之前使用过 backlog 的 slave 引发错误的 PSYNC 操作    server.master_repl_offset++;    // 尽管没有数据，但事实上，第一个字节的逻辑位置是 master_repl_offset 的下一个字节    server.repl_backlog_off = server.master_repl_offset+1;}</code></pre><h4 id="执行 -bgsave- 操作">执行 bgsave 操作</h4><p>接上一小节，bgsave 操作的处理函数为 <strong>startBgsaveForReplication</strong>。<br>首先根据传入的参数，针对有无磁盘化复制调用不同的处理函数，即，</p><pre><code class="language-c">int retval;int socket_target = server.repl_diskless_sync &amp;&amp; (mincapa &amp; SLAVE_CAPA_EOF);listIter li;listNode *ln;serverLog(LL_NOTICE,&quot;Starting BGSAVE for SYNC with target: %s&quot;,    socket_target ? &quot;slaves sockets&quot; : &quot;disk&quot;);if (socket_target)    retval = rdbSaveToSlavesSockets();else    retval = rdbSaveBackground(server.rdb_filename);</code></pre><p>参数 <strong>mincapa</strong>，表示 slave 的 &quot; 能力 &quot;，即是否能接受无硬盘复制的 rdb 数据。<br>如果选项<code>server.repl_diskless_sync</code> 为真，且 <strong>mincapa</strong> 中包含 <strong>SLAVE_CAPA_EOF</strong>，说明可以为该 slave 直接发送无硬盘复制的 rdb 数据，调用 <strong>rdbSaveToSlavesSockets</strong> 函数，在后台将 rdb 数据通过 socket 发送给所有状态为 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> 的 slave。<br>否则，调用<strong>rdbSaveBackground</strong> 函数，在后台将 rdb 数据转储到本地文件。</p><p>如果以上的 rdb 处理函数调用失败，从 slave 列表中删除处于 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> 状态的 slave，并在 slave 中加入 <strong>CLIENT_CLOSE_AFTER_REPLY</strong> 标识，以便在回复错误消息后关闭连接。代码逻辑如下，</p><pre><code class="language-c">if (retval == C_ERR) {serverLog(LL_WARNING,&quot;BGSAVE for replication failed&quot;);    listRewind(server.slaves,&amp;li);    while((ln = listNext(&amp;li))) {        client *slave = ln-&gt;value;        if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) {            slave-&gt;flags &amp;= ~CLIENT_SLAVE;            listDelNode(server.slaves,ln);            addReplyError(slave,                &quot;BGSAVE failed, replication can't continue&quot;);            slave-&gt;flags |= CLIENT_CLOSE_AFTER_REPLY;        }    }    return retval;}</code></pre><p>如果使用的是有磁盘复制，那么从 slave 列表中找到处于 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> 状态的 slave，调用 <strong>replicationSetupSlaveForFullResync</strong> 函数，把 slave 状态置为 <strong>SLAVE_STATE_WAIT_BGSAVE_END</strong>，并回复 <strong>+FULLRESYNC</strong>，这个前面说过。代码如下，</p><pre><code class="language-c">/* If the target is socket, rdbSaveToSlavesSockets() already setup * the salves for a full resync. Otherwise for disk target do it now.*/if (!socket_target) {listRewind(server.slaves,&amp;li);    while((ln = listNext(&amp;li))) {        client *slave = ln-&gt;value;        if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) {                replicationSetupSlaveForFullResync(slave,                        getPsyncInitialOffset());        }    }}</code></pre><p>最后调用函数 <strong>replicationScriptCacheFlush</strong> 清空 lua 脚本缓存。</p><h3 id="累积命令流过程">累积命令流过程</h3><p>当 master 收到 client 发来的命令后，会调用 <strong>call</strong> 函数执行相应的命令处理函数。在代码中 <strong>PROPAGATE_REPL</strong> 标识表示需要将命令同步给 slave，有如下逻辑，</p><pre><code class="language-c">void call(client *c, int flags) {    ......   /* Propagate the command into the AOF and replication link */    if (flags &amp; CMD_CALL_PROPAGATE &amp;&amp;        (c-&gt;flags &amp; CLIENT_PREVENT_PROP) != CLIENT_PREVENT_PROP)    {        ......        /* Check if the command operated changes in the data set. If so         * set for replication / AOF propagation. */        if (dirty) propagate_flags |= (PROPAGATE_AOF|PROPAGATE_REPL);        ......        /* If the client forced AOF / replication of the command, set         * the flags regardless of the command effects on the data set. */        if (c-&gt;flags &amp; CLIENT_FORCE_REPL) propagate_flags |= PROPAGATE_REPL;        ......        /* Call propagate() only if at least one of AOF / replication         * propagation is needed. */        if (propagate_flags != PROPAGATE_NONE)            propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);    }}void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc,               int flags){if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF)        feedAppendOnlyFile(cmd,dbid,argv,argc);    if (flags &amp; PROPAGATE_REPL)        replicationFeedSlaves(server.slaves,dbid,argv,argc);}</code></pre><p>现在来看重点处理函数 <strong>replicationFeedSlaves</strong>，现在分析如下。</p><p>首先，必要的 check。</p><pre><code class="language-c">// 如果 backlog 为空，且本节点没有 slave，那么下面的逻辑就没必要走了if (server.repl_backlog == NULL &amp;&amp; listLength(slaves) == 0) return;</code></pre><p>如果有必要的话，将 SELECT 命令添加到 backlog 和所有状态不是 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong> 的 slave 输出缓存中，其他命令也是如此，代码大概如下，</p><pre><code class="language-c">/* Write the command to the replication backlog if any. */if (server.repl_backlog) {char aux[LONG_STR_SIZE+3];    /* Add the multi bulk reply length. */    // *..CRLF    aux[0] = '*';    len = ll2string(aux+1,sizeof(aux)-1,argc);    aux[len+1] = '\r';    aux[len+2] = '\n';    feedReplicationBacklog(aux,len+3);// argc 转换成字符串的长度 + 3，即 * 以及 CRLF    for (j = 0; j &lt; argc; j++) {long objlen = stringObjectLen(argv[j]);        /* We need to feed the buffer with the object as a bulk reply         * not just as a plain string, so create the $..CRLF payload len         * and add the final CRLF */        aux[0] = '$';        len = ll2string(aux+1,sizeof(aux)-1,objlen);        aux[len+1] = '\r';        aux[len+2] = '\n';        feedReplicationBacklog(aux,len+3);        feedReplicationBacklogWithObject(argv[j]);        feedReplicationBacklog(aux+len+1,2); // CRLF    }}/* Write the command to every slave. */listRewind(server.slaves,&amp;li);while((ln = listNext(&amp;li))) {    client *slave = ln-&gt;value;    /* Don't feed slaves that are still waiting for BGSAVE to start */    if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue;    /* Feed slaves that are waiting for the initial SYNC (so these commands        * are queued in the output buffer until the initial SYNC completes),        * or are already in sync with the master. */    /* Add the multi bulk length. */    addReplyMultiBulkLen(slave,argc);    /* Finally any additional argument that was not stored inside the        * static buffer if any (from j to argc). */    for (j = 0; j &lt; argc; j++)        addReplyBulk(slave,argv[j]);}</code></pre><p>向 slave 输出缓存追加命令流时，调用的是 addReply 类的函数。</p><h2 id="bgsave- 收尾阶段">bgsave 收尾阶段</h2><p>当完成 bgsave 后，无论是有无磁盘复制，都要调用 <strong>updateSlavesWaitingBgsave</strong> 函数进行最后的处理，主要是为了前面说过的 <strong> 被推迟的 bgsave</strong>。</p><pre><code class="language-c">void updateSlavesWaitingBgsave(int bgsaveerr, int type) {.....}</code></pre><p>遍历 slave 列表，如果 slave 的复制状态处于 <strong>SLAVE_STATE_WAIT_BGSAVE_START</strong>，那么调用 <strong>startBgsaveForReplication</strong> 函数，开始一次新的 bgsave。</p><pre><code class="language-c">if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) {    startbgsave = 1;    mincapa = (mincapa == -1) ? slave-&gt;slave_capa :                                (mincapa &amp; slave-&gt;slave_capa);</code></pre><p>如果 slave 的复制状态处于 <strong>SLAVE_STATE_WAIT_BGSAVE_END</strong>，说明该 slave 正在等待 rdb 数据处理完成，此时需要根据有无磁盘化复制，区别对待处理。</p><h3 id="无磁盘复制">无磁盘复制</h3><pre><code class="language-c">if (type == RDB_CHILD_TYPE_SOCKET) {    serverLog(LL_NOTICE,        &quot;Streamed RDB transfer with slave %s succeeded (socket). Waiting for REPLCONF ACK from slave to enable streaming&quot;,            replicationGetSlaveName(slave));    /* Note: we wait for a REPLCONF ACK message from slave in     * order to really put it online (install the write handler     * so that the accumulated data can be transfered). However     * we change the replication state ASAP, since our slave     * is technically online now. */    slave-&gt;replstate = SLAVE_STATE_ONLINE;    slave-&gt;repl_put_online_on_ack = 1;    slave-&gt;repl_ack_time = server.unixtime; /* Timeout otherwise. */}</code></pre><p>将 slave 的复制状态置为 <strong>SLAVE_STATE_ONLINE</strong>，属性 <strong>repl_put_online_on_ack</strong> 置为 1。<br>⚠ <strong>注意</strong>，在收到该 slave 第一个 <code>replconf ack &lt;offset&gt;</code> 命令之后，master 才真正调用 <strong>putSlaveOnline</strong> 函数将该 slave 置为 <strong>REDIS_REPL_ONLINE</strong> 状态，并且开始发送缓存的命令流。</p><pre><code class="language-c">void replconfCommand(client *c) {    .....    else if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,&quot;ack&quot;)) {        /* REPLCONF ACK is used by slave to inform the master the amount         * of replication stream that it processed so far. It is an         * internal only command that normal clients should never use. */        long long offset;        if (!(c-&gt;flags &amp; CLIENT_SLAVE)) return;        if ((getLongLongFromObject(c-&gt;argv[j+1], &amp;offset) != C_OK))            return;        if (offset &gt; c-&gt;repl_ack_off)            c-&gt;repl_ack_off = offset;        c-&gt;repl_ack_time = server.unixtime;        /* If this was a diskless replication, we need to really put         * the slave online when the first ACK is received (which         * confirms slave is online and ready to get more data). */        if (c-&gt;repl_put_online_on_ack &amp;&amp; c-&gt;replstate == SLAVE_STATE_ONLINE)            putSlaveOnline(c);        /* Note: this command does not reply anything! */        return;    }    ......}</code></pre><p>之所以这样设计，与这两种复制方式有关。</p><p>当使用 <strong> 有磁盘复制 </strong> 方式时，master 会先把 rdb 数据的长度以 <code>$&lt;len&gt;/r/n</code> 的格式发送给 slave，slave 在解析到 len 后，从 socket 中读取到特定长度的 rdb 数据。<br>当使用 <strong> 无磁盘复制 </strong> 方式时，master 预先无法获知 rdb 数据的长度，那 slave 如何判断 rdb 数据是否读完了呢？在发送 rdb 数据之前，master 会先以 <code>$EOF:&lt;40 bytes delimiter&gt;</code> 的格式发送一个 40 字节的魔数，当 rdb 数据发送完后，再次发送这个魔数，这样 slave 就可以检测到 rdb 数据发送结束了。</p><p>如果 master 发送完 rdb 数据后，直接将 slave 状态置为 <strong>SLAVE_STATE_ONLINE</strong> ，接着发送缓存的命令流。<br>当采用 <strong> 无磁盘复制 </strong> 方式时，slave 最后读到的数据很有可能包含了命令流数据。因此，需要等到 slave 发送的第一个 <code>replconf ack &lt;offset&gt;</code> 命令之后，master 再把 slave 状态置为 <strong>SLAVE_STATE_ONLINE</strong>。</p><p>可以参考作者的解释 <a href="https://github.com/antirez/redis/commit/bb7fea0d5ca7b3a53532338e8654e409014c1194" target="_blank" rel="noopener">https://github.com/antirez/redis/commit/bb7fea0d5ca7b3a53532338e8654e409014c1194</a>。</p><h3 id="有磁盘复制">有磁盘复制</h3><pre><code class="language-c">if (bgsaveerr != C_OK) {freeClient(slave);        serverLog(LL_WARNING,&quot;SYNC failed. BGSAVE child returned an error&quot;);        continue;}if ((slave-&gt;repldbfd = open(server.rdb_filename,O_RDONLY)) == -1 ||    redis_fstat(slave-&gt;repldbfd,&amp;buf) == -1) {freeClient(slave);    serverLog(LL_WARNING,&quot;SYNC failed. Can't open/stat DB after BGSAVE: %s&quot;, strerror(errno));    continue;}slave-&gt;repldboff = 0;slave-&gt;repldbsize = buf.st_size;slave-&gt;replstate = SLAVE_STATE_SEND_BULK;slave-&gt;replpreamble = sdscatprintf(sdsempty(),&quot;$%lld\r\n&quot;,    (unsigned long long) slave-&gt;repldbsize);aeDeleteFileEvent(server.el,slave-&gt;fd,AE_WRITABLE);if (aeCreateFileEvent(server.el, slave-&gt;fd, AE_WRITABLE, sendBulkToSlave, slave) == AE_ERR) {freeClient(slave);    continue;}</code></pre><p>如果前面做 bgsave 出错了，那么这里会释放掉 client。<br>否则，打开生成的 rdb 文件，将 fd 保存到 <strong>repldbfd</strong> 属性中，状态置为 <strong>SLAVE_STATE_SEND_BULK</strong>，这表示要把 rdb 数据发送给 slave 了，将 rdb 大小写入 <strong>replpreamble</strong> 属性。<br>重新注册 slave 上的写事件，回调函数为 <strong>sendBulkToSlave</strong>，该函数做以下分析，</p><pre><code class="language-c">/* Before sending the RDB file, we send the preamble as configured by the * replication process. Currently the preamble is just the bulk count of * the file in the form &quot;$&lt;length&gt;\r\n&quot;. */if (slave-&gt;replpreamble) {nwritten = write(fd,slave-&gt;replpreamble,sdslen(slave-&gt;replpreamble));    if (nwritten == -1) {        serverLog(LL_VERBOSE,&quot;Write error sending RDB preamble to slave: %s&quot;,            strerror(errno));        freeClient(slave);        return;    }    server.stat_net_output_bytes += nwritten;    sdsrange(slave-&gt;replpreamble,nwritten,-1);    if (sdslen(slave-&gt;replpreamble) == 0) {sdsfree(slave-&gt;replpreamble);        slave-&gt;replpreamble = NULL;        /* fall through sending data. */    } else {return;}}</code></pre><p>如果 <strong>replpreamble</strong> 属性不为空，说明是第一次触发该回调，那么先把这个 rdb 数据的长度信息发送给 slave。<br>否则，进入发送实际 rdb 数据阶段。从 rdb 文件中读取数据，然后发送给 slave，代码中使用 repldboff 属性记录累积发送过多少数据。<br>默认一次发送的数据量为 <strong>PROTO_IOBUF_LEN</strong>，大小为 16K。</p><pre><code class="language-c">/* If the preamble was already transfered, send the RDB bulk data. */lseek(slave-&gt;repldbfd,slave-&gt;repldboff,SEEK_SET);buflen = read(slave-&gt;repldbfd,buf,PROTO_IOBUF_LEN); // 读 16k 数据if (buflen &lt;= 0) {    serverLog(LL_WARNING,&quot;Read error sending DB to slave: %s&quot;,        (buflen == 0) ? &quot;premature EOF&quot; : strerror(errno));    freeClient(slave);    return;}if ((nwritten = write(fd,buf,buflen)) == -1) {if (errno != EAGAIN) {        serverLog(LL_WARNING,&quot;Write error sending DB to slave: %s&quot;,            strerror(errno));        freeClient(slave);    }    return;}slave-&gt;repldboff += nwritten;server.stat_net_output_bytes += nwritten;</code></pre><p>当 rdb 数据完全发送完以后，关闭 rdb 文件 fd，删除 fd 的写事件，重置 repldbfd。</p><pre><code class="language-c">if (slave-&gt;repldboff == slave-&gt;repldbsize) { // 发送完 rdb 文件，删除可读事件    close(slave-&gt;repldbfd);    slave-&gt;repldbfd = -1;    aeDeleteFileEvent(server.el,slave-&gt;fd,AE_WRITABLE);    putSlaveOnline(slave);}</code></pre><p>最后调用 <strong>putSlaveOnline</strong> 函数，将 slave 的复制状态置为 <strong>SLAVE_STATE_ONLINE</strong>，重新注册 fd 的写事件，回调函数为 <strong>sendReplyToClient</strong>，向 slave 发送累积的命令流。</p><pre><code class="language-c">void putSlaveOnline(client *slave) {    slave-&gt;replstate = SLAVE_STATE_ONLINE;    slave-&gt;repl_put_online_on_ack = 0;    slave-&gt;repl_ack_time = server.unixtime; /* Prevent false timeout. */    if (aeCreateFileEvent(server.el, slave-&gt;fd, AE_WRITABLE,        sendReplyToClient, slave) == AE_ERR) {serverLog(LL_WARNING,&quot;Unable to register writable event for slave bulk transfer: %s&quot;, strerror(errno));        freeClient(slave);        return;    }    refreshGoodSlavesCount();    serverLog(LL_NOTICE,&quot;Synchronization with slave %s succeeded&quot;,        replicationGetSlaveName(slave));}</code></pre><p>设置 slave 属性 **repl_put_online_on_ack ** 为 0，表示该 <strong>slave 已完成初始同步，接下来进入命令传播阶段</strong>。<br>最后，调用 <strong>refreshGoodSlavesCount</strong> 函数，更新当前状态正常的 slave 数量。</p><hr><p>到此，主从复制过程中 master 的逻辑就已经讲完了。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之主从复制 (3)</title>
    <link href="/968a029a.html"/>
    <url>/968a029a.html</url>
    
    <content type="html"><![CDATA[<p>redis 代码中主从复制流程的核心部分在于 <strong> 状态机的流转</strong>。</p><a id="more"></a><p>单机模式下以  <strong>SLAVEOF</strong> 命令触发；<br>cluster 模式下以 <strong>REPLICATE</strong> 命令触发，且 cluster 模式下不支持 <strong>SLAVEOF</strong> 命令。</p><p>在该过程中，master 与 slave 各有不同的流转逻辑，交互频繁，本文以下内容试图介绍 slave 的处理逻辑, 以下流程图可以辅助理解。<br><img src="https://s2.ax1x.com/2019/09/09/nGjlXd.png" srcset="/img/loading.gif" alt="nGjlXd.png"></p><p>代码中在 <code>redisServer</code> 结构体里定义的很多 <strong>repl</strong> 前缀的变量都用于此过程，如<code>repl_transfer_fd</code>。<br>各变量的作用在源码注释里已经写得非常详细了，不做赘述。</p><h2 id="单机模式下的主从复制">单机模式下的主从复制</h2><p>redis 实例以单机模式启动，即在 <span id="inline-blue"> redis.conf </span> 中配置 <strong>cluster-enabled no</strong>。</p><h3 id="触发方式">触发方式</h3><p>有以下三种方式可触发主从复制流程。<br>① <span id="inline-blue">redis.conf </span> 中配置 <code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code>；<br>② redis-server 命令启动服务时指定参数 <code>--slaveof [masterip] [masterport]</code>；<br>③ 对一个实例执行 <code>slaveof [masterip] [masterport]</code> 命令。</p><p>①② 逻辑相似，直接标记 <code>server.repl_state</code> 为 <strong>REPL_STATE_CONNECT</strong> 状态，以 ① 为例简要说明，加载配置文件时有如下逻辑，</p><pre><code class="language-c">void loadServerConfigFromString(char *config) {    ....    else if (!strcasecmp(argv[0],&quot;slaveof&quot;) &amp;&amp; argc == 3) {        slaveof_linenum = linenum;        server.masterhost = sdsnew(argv[1]);        server.masterport = atoi(argv[2]);        server.repl_state = REPL_STATE_CONNECT;    }....}</code></pre><p>而 ③ 在标记 <code>REPL_STATE_CONNECT</code> 状态前需要做一些检查。<br>首先，检查实例是否开启了 cluster 模式，如果开启了，那么直接返回，不支持这个命令。<br>接着，通过检查 <code>slaveof</code> 命令后面的参数来判断使用的是哪个命令，代码如下，</p><pre><code class="language-c">void slaveofCommand(client *c) {    /* cluster 模式开启后，禁用 slaveof 命令 */    if (server.cluster_enabled) {addReplyError(c,&quot;SLAVEOF not allowed in cluster mode.&quot;);        return;    }   // SLAVEOF NO ONE    if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;no&quot;) &amp;&amp;        !strcasecmp(c-&gt;argv[2]-&gt;ptr,&quot;one&quot;)) {if (server.masterhost) { // 如果之前有 master            replicationUnsetMaster();            sds client = catClientInfoString(sdsempty(),c);            serverLog(LL_NOTICE,&quot;MASTER MODE enabled (user request from '%s')&quot;, client);            sdsfree(client);        }    } else {        long port;        // 从参数中获得 port        if ((getLongFromObjectOrReply(c, c-&gt;argv[2], &amp;port, NULL) != C_OK))            return;        // 如果现在的 master 已经是要设置的，那么就不必再做操作了，直接返回吧        if (server.masterhost &amp;&amp; !strcasecmp(server.masterhost,c-&gt;argv[1]-&gt;ptr)            &amp;&amp; server.masterport == port) {serverLog(LL_NOTICE,&quot;SLAVE OF would result into synchronization with the master we are already connected with. No operation performed.&quot;);            addReplySds(c,sdsnew(&quot;+OK Already connected to specified master\r\n&quot;));            return;        }        replicationSetMaster(c-&gt;argv[1]-&gt;ptr, port);        sds client = catClientInfoString(sdsempty(),c);        serverLog(LL_NOTICE,&quot;SLAVE OF %s:%d enabled (user request from '%s')&quot;,            server.masterhost, server.masterport, client);        sdsfree(client);    }    addReply(c,shared.ok);}</code></pre><h4 id="SLAVEOF-NO-ONE- 命令">SLAVEOF NO ONE 命令</h4><p>该命令会取消现有的主从关系，使 slave 变为 master，主要函数如下，</p><pre><code class="language-c">void replicationUnsetMaster(void) {    // 已经是 master 了，无需继续操作    if (server.masterhost == NULL) return;    sdsfree(server.masterhost);    server.masterhost = NULL;    if (server.master) {if (listLength(server.slaves) == 0) {            // 继承 master 的 repl offset            server.master_repl_offset = server.master-&gt;reploff;            freeReplicationBacklog();}        freeClient(server.master);    }    replicationDiscardCachedMaster();    cancelReplicationHandshake();    server.repl_state = REPL_STATE_NONE;}</code></pre><p>这里主要涉及到一些与 master 相关的变量的内存释放。<br>如果该实例有 master，且不是其他实例的 master，即 <code>listLength(server.slaves) == 0</code>，也就是说未形成链式结构，那么记录下原 master 的  replication offset。在某些特定条件下，副本的数据新鲜度可以通过 replication offset 来比较，有时由于网络等原因暂时断开了，隔了一段时间又重新连上原 master，有了这个偏移量可以减少做完全重同步的可能性(我是这么理解的)。<br><strong>freeClient</strong> 函数会释放掉原来的 master，做一些内存释放，一些标志位重置等。</p><p>接下来的 <code>replicationDiscardCachedMaster</code> 函数中会释放掉 <code>server.cached_master</code>，因为这里缓存以前的 mater 已经没用了，不知道下次要连的是哪个 master，或者自己以后成为一个 master，避免不必要的内存浪费。</p><p><code>cancelReplicationHandshake</code> 函数则会取消一个正在进行尝试 handshake 的主从复制过程。<br>最后重置状态机为 <strong>REPL_STATE_NONE</strong>。</p><h4 id="SLAVEOF-host-port- 命令">SLAVEOF host port 命令</h4><p>通过执行该命令，可以将当前实例变成某个实例的 slave。<br>如果指定的主从关系已经存在，那本次命令没必要继续执行了，直接返回；否则，通过 <code>replicationSetMaster</code> 函数设置新的主从关系，代码如下，</p><pre><code class="language-c">void replicationSetMaster(char *ip, int port) {sdsfree(server.masterhost);    server.masterhost = sdsnew(ip);    server.masterport = port;    // 如果原来有 master 了，需要释放掉    if (server.master) freeClient(server.master);    disconnectAllBlockedClients();    // 释放掉所有的 slave，让它们重新连    disconnectSlaves();    replicationDiscardCachedMaster();    freeReplicationBacklog();    cancelReplicationHandshake();    server.repl_state = REPL_STATE_CONNECT;    server.master_repl_offset = 0;    server.repl_down_since = 0;}</code></pre><p>在以上函数中，<br>先保存下要连接的 ip 和 port，方便后面进行建立网络连接。<br>如果，该节点之前有 master 了，那么需要释放掉原来的 master，跟上面一节的逻辑类似，前面详细说过了。<br><strong>disconnectAllBlockedClients</strong> 函数会 unlock 已经 lock 在这个实例上的 client，并返回 <strong>-UNBLOCKED</strong> 开头的错误。这是因为该实例已经改变了角色，block 已经没什么意义。比如当一个实例从 master 变为 slave，那么由于 list 选项而阻塞在该实例上的 client 就不安全了，<strong>因为数据随着从新的 slave 同步数据，该实例的数据集可能会发生变化</strong>。<br><strong>disconnectSlaves</strong> 函数释放掉所有的 slave，重新同步新的数据。<br>释放掉 <code>server.cached_master</code>，同样因为数据集变化了，cache 的数据并不能用了。<br>释放掉 <code>server.repl_backlog</code>，理由同上。<br><code>cancelReplicationHandshake</code> 函数在上面讲过了。<br>将 <code>server.repl_state</code> 置为 <strong>REPL_STATE_CONNECT</strong> 状态，复制偏离量归零等。<br>最后返回 OK，也就是这个命令的返回值<code>+OK\r\n</code>。</p><h3 id="主从建立连接">主从建立连接</h3><p>redis 中有很多 cron 任务，其中就有一个负责 replication 的，即每秒执行一次的 <strong>replicationCron</strong> 函数。</p><pre><code class="language-c"> run_with_period(1000) replicationCron();</code></pre><p>在上一步中，状态机已经流转到 <strong>REPL_STATE_CONNECT</strong> 状态，这里直接就进入到主从建连的逻辑。</p><pre><code class="language-c">void replicationCron(void) {......    // 开始一段新的主从关系    if (server.repl_state == REPL_STATE_CONNECT) {        serverLog(LL_NOTICE,&quot;Connecting to MASTER %s:%d&quot;,            server.masterhost, server.masterport);        if (connectWithMaster() == C_OK) {serverLog(LL_NOTICE,&quot;MASTER &lt;-&gt; SLAVE sync started&quot;);        }    }  ......}</code></pre><p>使用 <code>server.masterhost</code> 和 <code>server.masterport</code> 向 master 发起 connect 请求， fd 设置为<strong> 非阻塞</strong>。成功后，为 fd 的读写事件注册 <code>syncWithMaster</code> 回调函数，用于处理 master 与 slave 之间的 handshake 过程。这部分逻辑在 <strong>connectWithMaster</strong> 函数中实现，代码如下，</p><pre><code class="language-c">int connectWithMaster(void) {    int fd;    // 连接 master，获得 fd    fd = anetTcpNonBlockBestEffortBindConnect(NULL, server.masterhost,server.masterport,NET_FIRST_BIND_ADDR);    if (fd == -1) {        serverLog(LL_WARNING,&quot;Unable to connect to MASTER: %s&quot;,            strerror(errno));        return C_ERR;    }    // 为 fd 设置读写事件回调 syncWithMaster    if (aeCreateFileEvent(server.el,fd,AE_READABLE|AE_WRITABLE,syncWithMaster,NULL) == AE_ERR)    {close(fd);        serverLog(LL_WARNING,&quot;Can't create readable event for SYNC&quot;);        return C_ERR;    }    server.repl_transfer_lastio = server.unixtime;    server.repl_transfer_s = fd;    // 状态机更新    server.repl_state = REPL_STATE_CONNECTING;    return C_OK;}</code></pre><p><code>server.repl_transfer_lastio</code> 用于记录上一次 fd 读事件的时刻，<code>server.repl_transfer_s</code> 记录主从复制使用到的 socket fd。</p><p>更新状态机为 <strong>REPL_STATE_CONNECTING</strong>。</p><h3 id="主从 -handshake- 过程">主从 handshake 过程</h3><h4 id="发送 -ping">发送 ping</h4><p>主从建连成功后，通过 fd 的读写事件触发  <code>syncWithMaster</code> 回调函数。</p><p>如果该事件在用户把本实例用 <strong>SLAVEOF NO ONE</strong> 变成 master 后出触发，那么没有执行下去的必要，判断逻辑如下，</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_NONE) {close(fd);    return;}</code></pre><p>下面是同步发送 PING 的代码逻辑，更新状态机为 <strong>REPL_STATE_RECEIVE_PONG</strong>。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_CONNECTING) {serverLog(LL_NOTICE,&quot;Non blocking connect for SYNC fired the event.&quot;);    /* 为了等待 pong 的返回，删除 fd 上的可写事件，但保留可读事件 */    aeDeleteFileEvent(server.el,fd,AE_WRITABLE);    server.repl_state = REPL_STATE_RECEIVE_PONG;    /* 同步发送 ping，这里不检查是否 err，因为已经有超时限制做保证 */    err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;PING&quot;,NULL);    if (err) goto write_error;    return;}</code></pre><p><code>sendSynchronousCommand</code> 函数通过 flag 标识读写命令，此处写命令标识为 <strong>SYNC_CMD_WRITE</strong>。</p><h4 id="验证 -AUTH">验证 AUTH</h4><p>使用 <strong>sendSynchronousCommand</strong> 函数同步读取 master 对 PING 的回复。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_RECEIVE_PONG) {    /* 读取上面发送的 ping 命令的 response */    err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);    if (err[0] != '+' &amp;&amp; strncmp(err,&quot;-NOAUTH&quot;,7) != 0 &amp;&amp;        strncmp(err,&quot;-ERR operation not permitted&quot;,28) != 0)    {serverLog(LL_WARNING,&quot;Error reply to PING from master: '%s'&quot;,err);        sdsfree(err);        goto error;    } else {        serverLog(LL_NOTICE,          &quot;Master replied to PING, replication can continue...&quot;);    }    sdsfree(err);    server.repl_state = REPL_STATE_SEND_AUTH;}</code></pre><p>回复只可能有 3 种情况：<strong>+PONG</strong>，<strong>-NOAUTH</strong> 和 <strong>-ERR operation not permitted</strong>（老版本的 redis 主节点）。如果不是，直接进入错误处理代码流程。</p><p><strong>注意</strong>：这里的读操作会更新变量 <code>server.repl_transfer_lastio</code>。</p><p>调整状态机为 <strong>REDIS_REPL_SEND_AUTH</strong>。这里没有 <code>return</code>，直接往下执行，进入鉴权的逻辑，</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_SEND_AUTH) {if (server.masterauth) {err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;AUTH&quot;,server.masterauth,NULL);        if (err) goto write_error;        server.repl_state = REPL_STATE_RECEIVE_AUTH;        return;    } else {server.repl_state = REPL_STATE_SEND_PORT;}}</code></pre><p>如果配置文件中没有设置 <strong>masterauth</strong> 选项，那么状态机置为 <strong>REPL_STATE_SEND_PORT</strong>。<br>否则，需要发送 <code>AUTH</code> 命令鉴权。状态机置为 <strong>REPL_STATE_RECEIVE_AUTH</strong>。</p><pre><code class="language-c">/* Receive AUTH reply. */if (server.repl_state == REPL_STATE_RECEIVE_AUTH) {err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);    if (err[0] == '-') {serverLog(LL_WARNING,&quot;Unable to AUTH to MASTER: %s&quot;,err);        sdsfree(err);        goto error;    }    sdsfree(err);    server.repl_state = REPL_STATE_SEND_PORT;}</code></pre><p>验证 auth 通过后，状态机置为 <strong>REPL_STATE_SEND_PORT</strong>，否则，直接跳到的 err 处理流程。</p><h4 id="发送 -REPLCONF- 命令">发送 REPLCONF 命令</h4><p>slave 将发送一连串的 <code>REPLCONF</code> 命令，以告知 master 自己的一些信息。<br><code>slave-announce-ip</code> 和 <code>slave-announce-port</code> 主要是针对转发或者 NAT 场景下，master 无法通过 socket 连接获得对端信息时使用。</p><p>首先发送自己的 port 信息，<code>REPLCONF listening-port &lt;port&gt;</code>，状态机置为 <strong>REPL_STATE_RECEIVE_PORT</strong>，返回，等下一次事件触发。<br>接着，同步读取 master 的回复，即使返回错误也没有关系，状态机置为 <strong>REPL_STATE_SEND_IP</strong>。<br>代码如下，</p><pre><code class="language-c">/* Set the slave port, so that Master's INFO command can list the * slave listening port correctly. */if (server.repl_state == REPL_STATE_SEND_PORT) {    sds port = sdsfromlonglong(server.slave_announce_port ?                               server.slave_announce_port : server.port);    err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;REPLCONF&quot;,                                 &quot;listening-port&quot;,port, NULL);    sdsfree(port);    if (err) goto write_error;    sdsfree(err);    server.repl_state = REPL_STATE_RECEIVE_PORT;    return;}if (server.repl_state == REPL_STATE_RECEIVE_PORT) {err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);    if (err[0] == '-') {serverLog(LL_NOTICE,&quot;(Non critical) Master does not understand &quot;                &quot;REPLCONF listening-port: %s&quot;, err);    }    sdsfree(err);    server.repl_state = REPL_STATE_SEND_IP;</code></pre><p>如果没有配置 <code>slave-announce-ip</code> 时，直接将状态机调跳转到 <strong>REPL_STATE_SEND_CAPA</strong>，跳过发送 REPLCONF ip-address 的步骤。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_SEND_IP &amp;&amp;    server.slave_announce_ip == NULL){server.repl_state = REPL_STATE_SEND_CAPA;}</code></pre><p>发送 REPLCONF ip-address，接收回复，将状态机置为 <strong>REPL_STATE_SEND_CAPA</strong>。</p><pre><code class="language-c">/* REPLCONF ip-address &lt;ip&gt;  */if (server.repl_state == REPL_STATE_SEND_IP) {    err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;REPLCONF&quot;,                                 &quot;ip-address&quot;,server.slave_announce_ip, NULL);    if (err) goto write_error;    sdsfree(err);    server.repl_state = REPL_STATE_RECEIVE_IP;    return;}/* Receive REPLCONF ip-address reply. */if (server.repl_state == REPL_STATE_RECEIVE_IP) {err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);    if (err[0] == '-') {serverLog(LL_NOTICE,&quot;(Non critical) Master does not understand &quot;                &quot;REPLCONF ip-address: %s&quot;, err);    }    sdsfree(err);    server.repl_state = REPL_STATE_SEND_CAPA;}</code></pre><p>状态机置为  <strong>REPL_STATE_SEND_CAPA</strong>，告知 master 自己的能力，现在只有 eof，表示支持无磁盘化主从复制，以后可能会有更多，格式为 <code> REPLCONF capa X capa Y capa Z ...</code>。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_SEND_CAPA) {    err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;REPLCONF&quot;,                                 &quot;capa&quot;,&quot;eof&quot;,NULL);    if (err) goto write_error;    sdsfree(err);    server.repl_state = REPL_STATE_RECEIVE_CAPA;    return;}if (server.repl_state == REPL_STATE_RECEIVE_CAPA) {err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);    /* Ignore the error if any, not all the Redis versions support           * REPLCONF capa. */    if (err[0] == '-') {serverLog(LL_NOTICE,&quot;(Non critical) Master does not understand &quot;                &quot;REPLCONF capa: %s&quot;, err);    }    sdsfree(err);    server.repl_state = REPL_STATE_SEND_PSYNC;}</code></pre><p>状态机置为 <strong>REPL_STATE_SEND_PSYNC</strong>。</p><h4 id="尝试做部分重同步">尝试做部分重同步</h4><p>为解决旧版本 redis 在处理断线情况下完全复制的低效问题， 从 2.8 版本开始，使用 PSYNC 命令代替 SYNC 命令来执行复制时的同步操作，这个点在前面的博客讲过了。</p><p>为高效起见，首先尝试做部分重同步，试探逻辑在函数 <strong>slaveTryPartialResynchronization</strong> 中。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_SEND_PSYNC) {if (slaveTryPartialResynchronization(fd,0) == PSYNC_WRITE_ERROR) {err = sdsnew(&quot;Write error sending the PSYNC command.&quot;);        goto write_error;    }    server.repl_state = REPL_STATE_RECEIVE_PSYNC;    return;}</code></pre><p><strong>slaveTryPartialResynchronization</strong> 里包含了读写两部分，其中写的部分在上半部，当第二个参数为 0 时，发送 PSYNC 命令，命令格式为 <code>PSYNC &lt;runid&gt; &lt;offset&gt;</code>。<br>发送 PSYNC 时，分两种情况，首次连接或非首次连接。首次连接时，runid 未知，用 <code>?</code> 代替，offset 置为初始值 -1。<br>代码逻辑如下，</p><pre><code class="language-c">if (!read_reply) {server.repl_master_initial_offset = -1;    if (server.cached_master) { // 重连        psync_runid = server.cached_master-&gt;replrunid;        snprintf(psync_offset,sizeof(psync_offset),&quot;%lld&quot;, server.cached_master-&gt;reploff+1);        serverLog(LL_NOTICE,&quot;Trying a partial resynchronization (request %s:%s).&quot;, psync_runid, psync_offset);    } else { // 首次连接 master        serverLog(LL_NOTICE,&quot;Partial resynchronization not possible (no cached master)&quot;);        psync_runid = &quot;?&quot;;        memcpy(psync_offset,&quot;-1&quot;,3); /* psync ? -1 */    }    reply = sendSynchronousCommand(SYNC_CMD_WRITE,fd,&quot;PSYNC&quot;,psync_runid,psync_offset,NULL);    if (reply != NULL) {serverLog(LL_WARNING,&quot;Unable to send PSYNC to master: %s&quot;,reply);        sdsfree(reply);        /* 发送出错了，需要删掉 fd 上的可读事件 */        aeDeleteFileEvent(server.el,fd,AE_READABLE);        return PSYNC_WRITE_ERROR;    }    return PSYNC_WAIT_REPLY;}</code></pre><p>发送出错后，需要删掉 fd 上的可读事件。<br>回到 <strong>syncWithMaster</strong> 函数中，状态机置为 <strong>REPL_STATE_RECEIVE_PSYNC</strong>。</p><p>代码逻辑走到这一步，如果状态机的状态不是 <strong>REPL_STATE_RECEIVE_PSYNC</strong>，一定是哪里出错了，进入错误处理流程，即，</p><pre><code class="language-c">/* If reached this point, we should be in REPL_STATE_RECEIVE_PSYNC. */if (server.repl_state != REPL_STATE_RECEIVE_PSYNC) {serverLog(LL_WARNING,&quot;syncWithMaster(): state machine error, &quot;        &quot;state should be RECEIVE_PSYNC but is %d&quot;, server.repl_state);    goto error;}</code></pre><p>接着去读取 master 的给的回复信息，</p><pre><code class="language-c">psync_result = slaveTryPartialResynchronization(fd,1);</code></pre><p>可能会读到三种，<code>+FULLRESYNC</code>、<code>+CONTINUE</code>以及<code>-ERR</code>。</p><pre><code class="language-c">reply = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);if (sdslen(reply) == 0) {  // 为了保活，master 可能在收到 PSYNC 后且回复前发送空行  sdsfree(reply);  return PSYNC_WAIT_REPLY;}/* 删除 fd 可读事件，方便后面为 f'd 重新注册新的回调 */aeDeleteFileEvent(server.el,fd,AE_READABLE);</code></pre><p>【1】<code>+FULLRESYNC</code> 回复表示不能进行部分重同步，slave 告诉给 master 的 offset 不在 master 的复制积压缓冲区范围内，只能进行完全重同步，返回给上层函数 <strong>PSYNC_FULLRESYNC</strong>，代码如下，</p><pre><code class="language-c">/* 完全重同步得到 response 为 +FULLRESYNC &lt;master_runid&gt; &lt;offset&gt; */if (!strncmp(reply,&quot;+FULLRESYNC&quot;,11)) {    char *runid = NULL, *offset = NULL;    runid = strchr(reply,' ');    if (runid) {        runid++;        offset = strchr(runid,' ');        if (offset) offset++;    }    /* 有可能是 master 发送格式有问题，先把 repl_master_runid 置空 */    if (!runid || !offset || (offset-runid-1) != CONFIG_RUN_ID_SIZE) {        serverLog(LL_WARNING,                  &quot;Master replied with wrong +FULLRESYNC syntax.&quot;);        memset(server.repl_master_runid,0,CONFIG_RUN_ID_SIZE+1);    } else {memcpy(server.repl_master_runid, runid, offset-runid-1);        server.repl_master_runid[CONFIG_RUN_ID_SIZE] = '\0';        server.repl_master_initial_offset = strtoll(offset,NULL,10);        serverLog(LL_NOTICE,&quot;Full resync from master: %s:%lld&quot;,                  server.repl_master_runid,                  server.repl_master_initial_offset);    }    /* We are going to full resync, discard the cached master structure. */    replicationDiscardCachedMaster();    sdsfree(reply);    return PSYNC_FULLRESYNC;}</code></pre><p>以上代码解析出 master 的 runid，以及 offset，分别赋值给 <code>repl_master_runid</code> 和 <code>repl_master_initial_offset</code>。因为要进行全同步，<code>cached_master</code> 保存的信息就失效了，需要重置，即函数 <code>replicationDiscardCachedMaster</code> 的调用。</p><p>【2】<code>+CONTINUE</code> 表示可以进行部分重同步，返回给上层函数 <strong>PSYNC_CONTINUE</strong>。</p><pre><code class="language-c">if (!strncmp(reply,&quot;+CONTINUE&quot;,9)) {    serverLog(LL_NOTICE,              &quot;Successful partial resynchronization with master.&quot;);    sdsfree(reply);    replicationResurrectCachedMaster(fd);    return PSYNC_CONTINUE;}</code></pre><pre><code class="language-c">void replicationResurrectCachedMaster(int newfd) {    server.master = server.cached_master;    server.cached_master = NULL;    server.master-&gt;fd = newfd;    server.master-&gt;flags &amp;= ~(CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP);    server.master-&gt;authenticated = 1;    server.master-&gt;lastinteraction = server.unixtime;    server.repl_state = REPL_STATE_CONNECTED;    /* Re-add to the list of clients. */    listAddNodeTail(server.clients,server.master);    if (aeCreateFileEvent(server.el, newfd, AE_READABLE,                          readQueryFromClient, server.master)) {serverLog(LL_WARNING,&quot;Error resurrecting the cached master, impossible to add the readable handler: %s&quot;, strerror(errno));        freeClientAsync(server.master); /* Close ASAP. */    }    if (clientHasPendingReplies(server.master)) {        if (aeCreateFileEvent(server.el, newfd, AE_WRITABLE,                          sendReplyToClient, server.master)) {serverLog(LL_WARNING,&quot;Error resurrecting the cached master, impossible to add the writable handler: %s&quot;, strerror(errno));            freeClientAsync(server.master); /* Close ASAP. */        }    }}</code></pre><p>可以看出，从 <code>cached_master</code> 恢复 master，将状态机置为 <strong>REPL_STATE_CONNECTED</strong>。<br>为 fd 的读事件注册新的回调函数 readQueryFromClient。<br>如果在<code> server.master</code> 上仍然有 reply，或者是在写 buffer 里有数据，那么需要为写事件注册回调函数 <code>sendReplyToClient</code>。</p><p>【3】<code>-ERR</code> 的情况。需要清理现有的 <code>cached_master</code>，返回给上层函数 <strong>PSYNC_NOT_SUPPORTED</strong> 。</p><p>回到 <strong>syncWithMaster</strong> 函数里，处理 PSYNC 命令的返回值。<br>当返回的是 <strong>PSYNC_CONTINUE</strong> 时，表示进行的是部分重同步，该函数结束。</p><pre><code class="language-c">if (psync_result == PSYNC_CONTINUE) { /* 部分重同步 ，不会走到下面接收 rdb 的流程 */  serverLog(LL_NOTICE, &quot;MASTER &lt;-&gt; SLAVE sync: Master accepted a Partial Resynchronization.&quot;);  return;}</code></pre><p>否则，有两种可能，进行完全重同步，或者 master 不支持 PSYNC 命令(老版本的 master)，但是无论如何都需要断开现有的所有 slave，因为新 master 可能会传过来一份不同的数据。<br>同时清空复制积压缓冲区，即 repl_backlog，不允许我的 slave 做 psync 了（<strong>毕竟数据不同了嘛</strong>）。</p><p>如果新 master 不支持 PSYNC 命令，那么同步发送 SYNC 命令。</p><pre><code class="language-c">if (psync_result == PSYNC_NOT_SUPPORTED) {serverLog(LL_NOTICE,&quot;Retrying with SYNC...&quot;);    if (syncWrite(fd,&quot;SYNC\r\n&quot;,6,server.repl_syncio_timeout*1000) == -1) {        serverLog(LL_WARNING,&quot;I/O error writing to MASTER: %s&quot;,                  strerror(errno));        goto error;    }}</code></pre><p>如果没有出错，接下来准备完全重同步阶段 master 发过来的 rdb 数据。创建一个名字以 tmp 为前缀的临时 rdb 接收文件，打开，并记录 fd，最多 5 次，要是还不能成功创建一个临时文件，那么就走错误处理的流程了。代码如下，</p><pre><code class="language-c">while(maxtries--) {    snprintf(tmpfile,256,             &quot;temp-%d.%ld.rdb&quot;,(int)server.unixtime,(long int)getpid());    dfd = open(tmpfile,O_CREAT|O_WRONLY|O_EXCL,0644);    if (dfd != -1) break;    sleep(1);}if (dfd == -1) {serverLog(LL_WARNING,&quot;Opening the temp file needed for MASTER &lt;-&gt; SLAVE synchronization: %s&quot;,strerror(errno));    goto error;}</code></pre><p>接着为 fd 的读事件注册回调函数 <code>readSyncBulkPayload</code>，用来处理从 master 读到的数据 rdb 文件。</p><pre><code class="language-c">/* 为 fd 的可读事件注册新的函数 readSyncBulkPayload */if (aeCreateFileEvent(server.el,fd, AE_READABLE,readSyncBulkPayload,NULL) == AE_ERR){    serverLog(LL_WARNING,              &quot;Can't create readable event for SYNC: %s (fd=%d)&quot;,              strerror(errno),fd);    goto error;}</code></pre><p>最后是一些 server 变量的赋值。</p><pre><code class="language-c">server.repl_state = REPL_STATE_TRANSFER;/* 初始化 RDB 文件大小 */server.repl_transfer_size = -1;/* 已读数据大小 */server.repl_transfer_read = 0;/* 最近一次执行的 fsync 偏移量 */server.repl_transfer_last_fsync_off = 0;/* 本地临时 rdb 文件的 fd */server.repl_transfer_fd = dfd;/* 最近一次读数据的时间 */server.repl_transfer_lastio = server.unixtime;/* 本地临时 rdb 文件的名字 */server.repl_transfer_tmpfile = zstrdup(tmpfile);</code></pre><p>状态机置为 <strong>REPL_STATE_TRANSFER</strong>，<code>repl_transfer_fd</code> 记录 rdb 临时文件的 fd。</p><h4 id="几个超时保证">几个超时保证</h4><p>在 <strong>replicationCron</strong> 函数中的开始部分，有一些超时保证。</p><p>与 master 建立连接后，一直没能发 PING，说明连接可能有问题。<br>在鉴权和确认 capa 的流程中，花了过多的时间。</p><pre><code class="language-c">if (server.masterhost &amp;&amp;    (server.repl_state == REPL_STATE_CONNECTING ||  slaveIsInHandshakeState()) &amp;&amp;        (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout) // 默认 60s 超时{serverLog(LL_WARNING,&quot;Timeout connecting to the MASTER...&quot;);    cancelReplicationHandshake();}int slaveIsInHandshakeState(void) {    return server.repl_state &gt;= REPL_STATE_RECEIVE_PONG &amp;&amp;        server.repl_state &lt;= REPL_STATE_RECEIVE_PSYNC;}</code></pre><p>接收 rdb 文件的时长做限制。</p><pre><code class="language-c">/* Bulk transfer I/O timeout? */if (server.masterhost &amp;&amp; server.repl_state == REPL_STATE_TRANSFER &amp;&amp;    (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout) // 默认 60s 超时{serverLog(LL_WARNING,&quot;Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value.&quot;);    cancelReplicationHandshake();}</code></pre><p>成为 slave 以后，没有数据发过来。</p><pre><code class="language-c"> /* Timed out master when we are an already connected slave? */if (server.masterhost &amp;&amp; server.repl_state == REPL_STATE_CONNECTED &amp;&amp;    (time(NULL)-server.master-&gt;lastinteraction) &gt; server.repl_timeout){serverLog(LL_WARNING,&quot;MASTER timeout: no data nor PING received...&quot;);    freeClient(server.master);}</code></pre><h3 id="接收 -RDB- 文件">接收 RDB 文件</h3><p>接收 rdb 数据有两种方式，一种是磁盘化的，一种是无磁盘化的。</p><blockquote><p>从 V2.8.18 开始，redis 引入了“无硬盘复制”选项，开启该选项时，redis 在与 slave 进行复制初始化时将不会将快照内容存储到硬盘上，而是直接通过网络发送给 slave，避免了硬盘的性能瓶颈，可以在配置文件中使用 <strong>repl-diskless-sync</strong> 选项来配置开启该功能。</p></blockquote><p>两种方式发送的数据格式是不一样的。<br>磁盘化复制时，master 先生成 rdb 文件，然后将文件内容加上 <code>$&lt;len&gt;/r/n</code> 的头部后，发送给 slave。<br>而无磁盘化复制时，master 直接把 rdb 数据发送给你 slave 时，以 <code>$EOF:&lt;XXX&gt;\r\n</code> 开头，并以 <code>&lt;XXX&gt;</code> 结尾，开头和结尾的 <code>&lt;XXX&gt;</code> 内容相同，都是 40 个字节，是由 <strong>0123456789abcdef</strong> 中的字符组成的随机字符串，为了校验数据的是否发送完成。</p><p>该流程主要是回调函数 <code>readSyncBulkPayload</code> 中的逻辑。<br>首先读取 master 传过来的辅助信息。</p><pre><code class="language-c">if (server.repl_transfer_size == -1) {    /* 第一行内容 $&lt;len&gt;/r/n */    if (syncReadLine(fd,buf,1024,server.repl_syncio_timeout*1000) == -1) {        serverLog(LL_WARNING,                  &quot;I/O error reading bulk count from MASTER: %s&quot;,                  strerror(errno));        goto error;    }    if (buf[0] == '-') {        serverLog(LL_WARNING,                  &quot;MASTER aborted replication with an error: %s&quot;,                  buf+1);        goto error;    } else if (buf[0] == '\0') {        server.repl_transfer_lastio = server.unixtime;        return;    } else if (buf[0] != '$') {serverLog(LL_WARNING,&quot;Bad protocol from MASTER, the first byte is not '$' (we received '%s'), are you sure the host and port are right?&quot;, buf);        goto error;    }  /* 有两种可能的 bulk payload 格式，正常的是 $&lt;count&gt;   * 还有一种可能就是无磁盘化主从同步时，因为这个时候不知道后面要传输数据的长度，因此会发送一个分隔符，   * 格式为 $EOF:&lt;40 bytes delimiter&gt;   * 在发送完 rdb 数据后，分隔符会再次被发送，以便让接收端知道数据发送完成了。   * 分隔符足够的长和随机，因此真实文件内容碰撞的可能性可以被忽略。*/    if (strncmp(buf+1,&quot;EOF:&quot;,4) == 0 &amp;&amp; strlen(buf+5) &gt;= CONFIG_RUN_ID_SIZE) {      usemark = 1;      memcpy(eofmark,buf+5,CONFIG_RUN_ID_SIZE);      memset(lastbytes,0,CONFIG_RUN_ID_SIZE);      server.repl_transfer_size = 0;      serverLog(LL_NOTICE,                &quot;MASTER &lt;-&gt; SLAVE sync: receiving streamed RDB from master&quot;);    } else {      usemark = 0;      server.repl_transfer_size = strtol(buf+1,NULL,10);      serverLog(LL_NOTICE,                &quot;MASTER &lt;-&gt; SLAVE sync: receiving %lld bytes from master&quot;,                (long long) server.repl_transfer_size);    }    return;}</code></pre><p>同步读取第一行内容，当开启了无磁盘化同步时，有一点需要注意，保存完 eofmark 后，要把 <code>repl_transfer_size</code> 变量置为一个非 -1 的值，防止下次事件触发后又进到这个逻辑里来了。而正常同步时，可以读到 <code>repl_transfer_size</code> 的大小。<br>通过 <code>usemark</code> 来标记同步类型，值为 1 表示无磁盘化的同步，值为 0 表示磁盘化同步。</p><pre><code class="language-c">/* Read bulk data */if (usemark) {readlen = sizeof(buf);} else {    left = server.repl_transfer_size - server.repl_transfer_read;    readlen = (left &lt; (signed)sizeof(buf)) ? left : (signed)sizeof(buf);}</code></pre><p>以上逻辑来调整每次从 socket 中读取数据的长度，因为 usemark 时，不知道要读取的数据总长度。</p><pre><code class="language-c">nread = read(fd,buf,readlen);if (nread &lt;= 0) {    serverLog(LL_WARNING,&quot;I/O error trying to sync with MASTER: %s&quot;,              (nread == -1) ? strerror(errno) : &quot;connection lost&quot;);    cancelReplicationHandshake();    return;}</code></pre><p>计算出 readlen 后，读取数据，如果读错了，要断开连接，清理 fd ，重置同步状态等，<code>cancelReplicationHandshake</code> 的逻辑在上面已经说过。<br>如果是 usemark，那么需要校验 eofmark，以便知道数据是否已经读完。</p><pre><code class="language-c">int eof_reached = 0;if (usemark) {    /* Update the last bytes array, and check if it matches our delimiter.*/    if (nread &gt;= CONFIG_RUN_ID_SIZE) {memcpy(lastbytes,buf+nread-CONFIG_RUN_ID_SIZE,CONFIG_RUN_ID_SIZE);    } else {        int rem = CONFIG_RUN_ID_SIZE-nread;        memmove(lastbytes,lastbytes+nread,rem);        memcpy(lastbytes+rem,buf,nread);    }    /* 读到 EOF 了 */    if (memcmp(lastbytes,eofmark,CONFIG_RUN_ID_SIZE) == 0) eof_reached = 1;}</code></pre><p>如果读到的数据长度 &gt;= 40，那么截取 buf 最后 40 个字符。否则使用 <code>memmove</code> 和 <code>memcpy</code> 将最后的 40 个字节填满，这部分操作有点绕，画了个图帮助理解，</p><p><img src="http://ww1.sinaimg.cn/large/71ca8e3cly1g5w95590gbj20h60873z7.jpg" srcset="/img/loading.gif" alt="lastbytes"></p><p>然后根据前面记录 eofmark 去判断是不是数据接收结束了，如果是，<code>eof_reached</code> 置为 1。<br>读完一次数据需要将其写入本地的临时 rdb 文件里，</p><pre><code class="language-c">if (write(server.repl_transfer_fd,buf,nread) != nread) {serverLog(LL_WARNING,&quot;Write error or short write writing to the DB dump file needed for MASTER &lt;-&gt; SLAVE synchronization: %s&quot;, strerror(errno));    goto error;}server.repl_transfer_read += nread; // 更新读了多少数据量</code></pre><p>如果是已经读到末尾了，那么需要从文件中删掉 eofmark，因为它不是 rdb 数据嘛，只是个辅助标识。</p><pre><code class="language-c">if (usemark &amp;&amp; eof_reached) {    if (ftruncate(server.repl_transfer_fd,                  server.repl_transfer_read - CONFIG_RUN_ID_SIZE) == -1)    {serverLog(LL_WARNING,&quot;Error truncating the RDB file received from the master for SYNC: %s&quot;, strerror(errno));        goto error;    }}</code></pre><p>光是 <code>write</code> 了还不够，这只是写到了系统的 cache，还需要做 <code>fsync</code> 将数据落盘。</p><pre><code class="language-c">if (server.repl_transfer_read &gt;=    server.repl_transfer_last_fsync_off + REPL_MAX_WRITTEN_BEFORE_FSYNC){    off_t sync_size = server.repl_transfer_read -      server.repl_transfer_last_fsync_off;    rdb_fsync_range(server.repl_transfer_fd,                    server.repl_transfer_last_fsync_off, sync_size);    server.repl_transfer_last_fsync_off += sync_size;}</code></pre><p>刷盘策略是每 8M 一次。<br>如果不是无磁盘化的主从同步，就要依赖于接收到的数据 size 与第一次传过来的值作比较。</p><pre><code class="language-c">if (!usemark) {if (server.repl_transfer_read == server.repl_transfer_size)        eof_reached = 1;}</code></pre><p>如果完全接收完数据了了，那么需要做一些善后工作，如下代码，</p><pre><code class="language-c"> if (eof_reached) {....}</code></pre><p>首先，把本地 rdb 文件的名字改成配置文件里配置的名字<code>server.rdb_filename</code>。</p><pre><code class="language-c">if (rename(server.repl_transfer_tmpfile,server.rdb_filename) == -1) {serverLog(LL_WARNING,&quot;Failed trying to rename the temp DB into dump.rdb in MASTER &lt;-&gt; SLAVE synchronization: %s&quot;, strerror(errno));    cancelReplicationHandshake();    return;}</code></pre><p>然后需要为加载新的 rdb 文件做一些准备。</p><pre><code class="language-c">signalFlushedDb(-1); // 使得本实例的所有客户端感知到接下来要清空数据库emptyDb(replicationEmptyDbCallback); // 清空所有数据，给 master 发一个 \n</code></pre><pre><code class="language-c">long long emptyDb(void(callback)(void*)) {    int j;    long long removed = 0;    for (j = 0; j &lt; server.dbnum; j++) {removed += dictSize(server.db[j].dict);        dictEmpty(server.db[j].dict,callback);        dictEmpty(server.db[j].expires,callback);    }    if (server.cluster_enabled) slotToKeyFlush();    return removed;}/* Callback used by emptyDb() while flushing away old data to load * the new dataset received by the master. */void replicationEmptyDbCallback(void *privdata) {UNUSED(privdata);    replicationSendNewlineToMaster();}/* 给 master 发 \n 表明自己还活着，在加载数据 */void replicationSendNewlineToMaster(void) {    static time_t newline_sent;    if (time(NULL) != newline_sent) {newline_sent = time(NULL);        if (write(server.repl_transfer_s,&quot;\n&quot;,1) == -1) {/* Pinging back in this stage is best-effort. */}    }}</code></pre><p>清空老数据完老数据，下面开始加载新数据。</p><pre><code class="language-c">aeDeleteFileEvent(server.el,server.repl_transfer_s,AE_READABLE);serverLog(LL_NOTICE, &quot;MASTER &lt;-&gt; SLAVE sync: Loading DB in memory&quot;);if (rdbLoad(server.rdb_filename) != C_OK) {serverLog(LL_WARNING,&quot;Failed trying to load the MASTER synchronization DB from disk&quot;);    cancelReplicationHandshake();    return;}</code></pre><p>在加载新数据之前，需要先删除 socket fd 的可读事件，这是因为在调用 <code>rdbLoad</code> 加载 rdb 数据时，每次调用<code>rioRead</code> 都会因为要计算 checksum 而调用 <code>processEventsWhileBlocked</code> 处理当前已触发的事件，如果不删除该可读事件的话，就会递归进入的本函数中（因此，slave 在加载 rdb 数据时，是不能处理主节点发来的其他数据的）。<br>然后做一些清理工作。</p><pre><code class="language-c">zfree(server.repl_transfer_tmpfile);close(server.repl_transfer_fd);</code></pre><p>根据 socket fd 创建一个 master 的 client。</p><pre><code class="language-c"> /* 创建 master 相关的变量 */replicationCreateMasterClient(server.repl_transfer_s);</code></pre><p>然后可以看下这个 <code>replicationCreateMasterClient</code> 这个函数都干了些什么事情。</p><pre><code class="language-c">void replicationCreateMasterClient(int fd) {server.master = createClient(fd);    server.master-&gt;flags |= CLIENT_MASTER;    server.master-&gt;authenticated = 1;    server.repl_state = REPL_STATE_CONNECTED;    server.master-&gt;reploff = server.repl_master_initial_offset;    memcpy(server.master-&gt;replrunid, server.repl_master_runid,        sizeof(server.repl_master_runid));    if (server.master-&gt;reploff == -1)        server.master-&gt;flags |= CLIENT_PRE_PSYNC;}</code></pre><p>需要注意一点，如果 master 不支持 PSYNC 的话，那么 salve 不会得到 <code>+FULLRESYNC</code> 的回复，也就不会更新 <code>server.repl_master_initial_offset</code> 变量，它就一直是 -1，在这里创建 master client 时，会给它一个标记 <strong>CLIENT_PRE_PSYNC</strong>。</p><p>这里会把状态机更新为 <strong>REPL_STATE_CONNECTED</strong>。<br>最后，如果 aof 功能没有关闭的话，需要重新生成 aof 文件，因为数据已经改变了。</p><pre><code class="language-c">if (server.aof_state != AOF_OFF) {    int retry = 10;    stopAppendOnly();    while (retry-- &amp;&amp; startAppendOnly() == C_ERR) {serverLog(LL_WARNING,&quot;Failed enabling the AOF after successful master synchronization! Trying it again in one second.&quot;);        sleep(1);    }    if (!retry) {serverLog(LL_WARNING,&quot;FATAL: this slave instance finished the synchronization with its master, but the AOF can't be turned on. Exiting now.&quot;);        exit(1);    }}</code></pre><p>到这里，<code>readSyncBulkPayload</code> 函数读取并加载新 rdb 文件的流程就走完了。</p><p>当复制状态变为 <strong>REPL_STATE_CONNECTED</strong> 后，表示进入了命令传播阶段。后续 slave 将 master 当成一个客户端，并接收其发来的命令请求，像处理普通客户端一样处理即可。命令传播在前面的博客已经详细讲过。</p><h3 id="探活机制">探活机制</h3><p>在 master-slave 连接建立以后，他们就通过心跳进行相互探活，这些机制都在 <code>replicationCron</code> 函数里。</p><h4 id="master- 探活">master 探活</h4><p>master 会定期给它所有的 slave 发送 PING。</p><pre><code class="language-c">if ((replication_cron_loops % server.repl_ping_slave_period) == 0) {ping_argv[0] = createStringObject(&quot;PING&quot;,4);    replicationFeedSlaves(server.slaves, server.slaveseldb,                          ping_argv, 1);    decrRefCount(ping_argv[0]);}</code></pre><p>给 slave 发送命令是通过 <code>replicationFeedSlaves</code> 函数实现的。</p><pre><code class="language-c">void replicationFeedSlaves(list *slaves, int dictid, robj **argv, int argc) {....}</code></pre><p>下面看一下该函数的详细实现。</p><pre><code class="language-c">if (server.repl_backlog == NULL &amp;&amp; listLength(slaves) == 0) return;</code></pre><p>如果 <code>repl_backlog</code> 为空，或者是没有 slave，那么这个过程是不必要的，直接返回。必要的时候生成 SELECT 命令，告知 slave 切换数据库。<code>slaveseldb</code> 中保存的是上一次 replication 输出时选择的数据库。</p><pre><code class="language-c">if (server.repl_backlog) {char aux[LONG_STR_SIZE+3];    /* Add the multi bulk reply length. */    aux[0] = '*';    len = ll2string(aux+1,sizeof(aux)-1,argc);    aux[len+1] = '\r';    aux[len+2] = '\n';    feedReplicationBacklog(aux,len+3);    for (j = 0; j &lt; argc; j++) {long objlen = stringObjectLen(argv[j]);        aux[0] = '$';        len = ll2string(aux+1,sizeof(aux)-1,objlen);        aux[len+1] = '\r';        aux[len+2] = '\n';        feedReplicationBacklog(aux,len+3);        feedReplicationBacklogWithObject(argv[j]);        feedReplicationBacklog(aux+len+1,2);    }}</code></pre><p>如果 <code>repl_backlog</code> 不为空，那么组装 redis 协议的命令，这里是 <code>*1\r\n$4\r\nPING</code>，放到 <code>repl_backlog</code> 变量里。</p><h4 id="slave- 探活">slave 探活</h4><pre><code class="language-c">void replicationCron(void) {    ...    if (server.masterhost &amp;&amp; server.master &amp;&amp;          !(server.master-&gt;flags &amp; CLIENT_PRE_PSYNC)) {replicationSendAck();    }    ...}void replicationSendAck(void) {    client *c = server.master;    if (c != NULL) {        c-&gt;flags |= CLIENT_MASTER_FORCE_REPLY;        addReplyMultiBulkLen(c,3);        addReplyBulkCString(c,&quot;REPLCONF&quot;);        addReplyBulkCString(c,&quot;ACK&quot;);        addReplyBulkLongLong(c,c-&gt;reploff);        c-&gt;flags &amp;= ~CLIENT_MASTER_FORCE_REPLY;    }}</code></pre><p>对于非老版本的 master，slave 向它定期发送 <code>REPLCONF ACK &lt;offset&gt;</code> 命令，以便告诉它复制偏移量。</p><h2 id="cluster- 模式">cluster 模式</h2><p>cluster 模式下，使用 <code>CLUSTER REPLICATE &lt;NODE ID&gt;</code> 命令来进行新的主从关系的构建。</p><pre><code class="language-c">void clusterCommand(client *c) {    ...    else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;replicate&quot;) &amp;&amp; c-&gt;argc == 3) {        /* CLUSTER REPLICATE &lt;NODE ID&gt; */        clusterNode *n = clusterLookupNode(c-&gt;argv[2]-&gt;ptr);        /* Lookup the specified node in our table. */        if (!n) {addReplyErrorFormat(c,&quot;Unknown node %s&quot;, (char*)c-&gt;argv[2]-&gt;ptr);            return;        }        /* I can't replicate myself. */        if (n == myself) {addReplyError(c,&quot;Can't replicate myself&quot;);            return;        }        /* Can't replicate a slave. */        if (nodeIsSlave(n)) {addReplyError(c,&quot;I can only replicate a master, not a slave.&quot;);            return;        }        // 我要做别人的 slave， 那么不是不能够有 slots 和数据库数据的        if (nodeIsMaster(myself) &amp;&amp;            (myself-&gt;numslots != 0 || dictSize(server.db[0].dict) != 0)) {            addReplyError(c,                &quot;To set a master the node must be empty and &quot;                &quot;without assigned slots.&quot;);            return;        }        /* Set the master. */        clusterSetMaster(n);        clusterDoBeforeSleep(CLUSTER_TODO_UPDATE_STATE|CLUSTER_TODO_SAVE_CONFIG);        addReply(c,shared.ok);    }    .....}</code></pre><p><strong>很重要的一个检查 </strong> 是，有 slot 或者有数据的 master 节点，不能做此操作，防止丢数据。<br>跳过一些合理性检查，重点函数就是 <code>clusterSetMaster</code> 了，那么它做了什么呢？</p><pre><code class="language-c">void clusterSetMaster(clusterNode *n) {serverAssert(n != myself);    serverAssert(myself-&gt;numslots == 0);    if (nodeIsMaster(myself)) {myself-&gt;flags &amp;= ~(CLUSTER_NODE_MASTER|CLUSTER_NODE_MIGRATE_TO);        myself-&gt;flags |= CLUSTER_NODE_SLAVE;        clusterCloseAllSlots();} else {if (myself-&gt;slaveof)            clusterNodeRemoveSlave(myself-&gt;slaveof,myself); // 解除原有的主从关系    }    myself-&gt;slaveof = n;    clusterNodeAddSlave(n,myself);    replicationSetMaster(n-&gt;ip, n-&gt;port);    resetManualFailover();}</code></pre><p>首先，如果本身是个 master，那么取消掉 master 和 migrating 的 flag，因为该 master 没有数据，可以大胆地取消迁移的叫标记，然后加上 slave 的标记 <strong>CLUSTER_NODE_SLAVE</strong>。<br>如果原本就是个 slave 节点，那么调整自己的主从归属信息，置空以手动主从切换有关的变量值，关于 cluster mf 的逻辑以后会专门去讨论。<br>然后就是前面说过的 <code>replicationSetMaster</code> 函数，触发上也是在 cron 里，就不啰嗦了。</p><p>以上，主从复制中，slave 的逻辑就介绍完了。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之主从复制 (2)</title>
    <link href="/8f9133db.html"/>
    <url>/8f9133db.html</url>
    
    <content type="html"><![CDATA[<p>repl backlog 是一个由 master 维护的固定长度的环形 buffer，默认大小 <strong>1M</strong>，在配置文件中可以通过 <strong>repl-backlog-size</strong> 项进行配置。可以把它看成一个 FIFO 的队列，当队列中元素过多时，最早进入队列的元素被弹出（数据被覆盖）。它为了解决上一篇博客中提到的旧版本主从复制存在的问题而存在的。</p><a id="more"></a><p>与之相关的，在 <code>redisServer</code> 中涉及到很多以 <strong>repl</strong> 为前缀的变量，这个只列举几个，</p><pre><code class="language-c">// 所有 slave 共享一份 backlog, 只针对部分复制char *repl_backlog;// backlog 环形 buffer 的长度long long repl_backlog_size;// backlog 中有效数据大小, 开始时 &lt;repl_backlog_size，但 buffer 满后一直 =repl_backlog_sizelong long repl_backlog_histlen;// backlog 中的最新数据末尾位置(从这里写数据到 backlog)long long repl_backlog_idx;// 最老数据首字节位置，全局范围内（而非积压队列内）的偏移量(从这里读 backlog 数据)long long repl_backlog_off;</code></pre><h3 id="创建 -backlog">创建 backlog</h3><pre><code class="language-c">void syncCommand(client *c) {  // ...  if (listLength(server.slaves) == 1 &amp;&amp; server.repl_backlog == NULL)        createReplicationBacklog();    return;}</code></pre><p>可以看到，在 <strong>SYNC</strong> 和 <strong>PSYNC</strong> 命令的实现函数 <code>syncCommand</code> 末尾，只有当实例只有一个 slave，且 repl_backlog 为空时，会调用 <code>createReplicationBacklog</code> 函数去创建 backlog。这也是为了避免不必要的内存浪费。</p><pre><code class="language-c">void createReplicationBacklog(void) {serverAssert(server.repl_backlog == NULL);    // 默认大小为 1M    server.repl_backlog = zmalloc(server.repl_backlog_size);    server.repl_backlog_histlen = 0;    server.repl_backlog_idx = 0;    // 确保之前使用过 backlog 的 slave 引发错误的 PSYNC 操作    server.master_repl_offset++;    // 尽管没有数据    // 但事实上，第一个字节的逻辑位置是 master_repl_offset 的下一个字节    server.repl_backlog_off = server.master_repl_offset+1;}</code></pre><h3 id="写数据到 -backlog">写数据到 backlog</h3><p>将数据放入 repl backlog 是通过 <strong>feedReplicationBacklog</strong> 函数实现的。</p><pre><code class="language-c">void feedReplicationBacklog(void *ptr, size_t len) {    unsigned char *p = ptr;    // 全局复制偏移量更新    server.master_repl_offset += len;    // 环形 buffer ，每次写尽可能多的数据，并在到达尾部时将 idx 重置到头部    while(len) {        // repl_backlog 剩余长度        size_t thislen = server.repl_backlog_size - server.repl_backlog_idx;        if (thislen &gt; len) thislen = len;        // 从 repl_backlog_idx 开始，copy thislen 的数据        memcpy(server.repl_backlog+server.repl_backlog_idx,p,thislen);        // 更新 idx ，指向新写入的数据之后        server.repl_backlog_idx += thislen;        // 如果 repl_backlog 写满了，则环绕回去从 0 开始        if (server.repl_backlog_idx == server.repl_backlog_size)            server.repl_backlog_idx = 0;        len -= thislen;        p += thislen;        // 更新 repl_backlog_histlen        server.repl_backlog_histlen += thislen;    }    // repl_backlog_histlen 不可能超过 repl_backlog_size，因为之后环形写入时会覆盖开头位置的数据    if (server.repl_backlog_histlen &gt; server.repl_backlog_size)        server.repl_backlog_histlen = server.repl_backlog_size;    server.repl_backlog_off = server.master_repl_offset -                              server.repl_backlog_histlen + 1;}</code></pre><p>以上函数中许多关键变量的更新逻辑比较抽象，下面画个图以辅助理解。<img src="https://s2.ax1x.com/2019/09/08/n8Qbyd.jpg" srcset="/img/loading.gif" alt="n8Qbyd.jpg"></p><p>master_repl_offset 为全局复制偏移量，它的初始值是随机的，假设等于 2。</p><p>在一个空的 repl_backlog 中插入 <strong>abcdef</strong> 时，各变量做如下更新：<br>master_repl_offset = 2 + 6 = 8<br>repl_backlog_idx = 0 + 6 = 6 ≠ 10<br>repl_backlog_histlen = 0 + 6 = 6 &lt; 10<br>repl_backlog_off = 8 - 6 + 1 = 3 （<strong>最老数据 a 在全局范围内的 offset 为 3</strong>）</p><p>接着，插入数据 <strong>ghijkl</strong>，从上图可以看出， repl_backlog  满了，因此前面有 2 个数据被覆盖了。各变量做如下更新：<br>master_repl_offset = 8 + 6 = 14<br>repl_backlog_idx = 6 + 4 = 10 → 0 + 2 = 2 (分两步)<br>repl_backlog_histlen = 6 + 4 = 10 → 10 + 2 = 12 &gt; 10 → 10<br>repl_backlog_off = 14 - 10 + 1 = 5 （<strong>最老的数据 c 在全局范围内的偏离量为 5</strong>）</p><p>接着，插入数据 <strong>mno</strong>，各变量做如下更新,<br>master_repl_offset = 14 + 3 = 17<br>repl_backlog_idx = 2 + 3 = 5<br>repl_backlog_histlen = 10 + 3 = 13 &gt; 10 → 10<br>repl_backlog_off = 17 - 10 + 1 = 8 （<strong>最老的数据 f 在全局范围内的偏离量为 8</strong>）</p><h3 id="从 -backlog- 读数据">从 backlog 读数据</h3><p>当 slave 连上 master 后，会通过 PSYNC 命令将自己的复制偏移量发送给 master，格式为 <code>PSYNC &lt;psync_runid&gt; &lt;psync_offset&gt;</code>。当首次建立连接时，psync_runid 值为 <strong>?</strong>，psync_offset 值为 <strong>-1</strong>。这部分的实现逻辑在 <code>slaveTryPartialResynchronization</code> 函数，下一篇博客会有详解。</p><p>master 根据收到的 psync_offset 值来判断是进行 <strong> 部分重同步 </strong> 还是 <strong> 完全重同步</strong>，以下只看部分重同步的逻辑，完整逻辑在后面的博客中分析。</p><pre><code class="language-c">int masterTryPartialResynchronization(client *c) {// ...  if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;psync_offset,NULL) !=       C_OK) goto need_full_resync;    psync_len = addReplyReplicationBacklog(c,psync_offset);  // ...}</code></pre><p>读取 backlog 数据的逻辑在 <code>addReplyReplicationBacklog</code> 函数中实现。</p><pre><code class="language-c">long long addReplyReplicationBacklog(client *c, long long offset) {  // ....  if (server.repl_backlog_histlen == 0) {serverLog(LL_DEBUG, &quot;[PSYNC] Backlog history len is zero&quot;);        return 0;    }    // ...  // 计算需要跳过的数据长度    skip = offset - server.repl_backlog_off;    //  将 j 指向 backlog 中最老的数据（在 backlog 中的位置）    j = (server.repl_backlog_idx +        (server.repl_backlog_size-server.repl_backlog_histlen)) %        server.repl_backlog_size;    // 加上要跳过的 offset  j = (j + skip) % server.repl_backlog_size;    // 要发送数据的总长度  len = server.repl_backlog_histlen - skip;    serverLog(LL_DEBUG, &quot;[PSYNC] Reply total length: %lld&quot;, len);    while(len) {        long long thislen =            ((server.repl_backlog_size - j) &lt; len) ?            (server.repl_backlog_size - j) : len;        serverLog(LL_DEBUG, &quot;[PSYNC] addReply() length: %lld&quot;, thislen);        // 从 backlog 的 j 这个位置开始发送数据        addReplySds(c,sdsnewlen(server.repl_backlog + j, thislen));        len -= thislen;        // j 切换到 0 (有可能数据还没发送完)        j = 0;    }    return server.repl_backlog_histlen - skip;}</code></pre><p>不好理解的是从 backlog 中的哪里开始发送数据给 slave，上面代码中有两处计算逻辑，我认为主要是第一处，可以分情况进行拆解。<br>1）当 backlog 中有效数据充满了整个 backlog 时，即 backlog 被完全利用，计算退化成<br><code>j = server.repl_backlog_idx % server.repl_backlog_size</code>，由于 repl_backlog_idx 不可能大于 server.repl_backlog_size，所以计算结果就等于 <strong>server.repl_backlog_idx</strong>，它是读写数据的分割点。<br>2）当 backlog 中尚有未使用的空间时，repl_backlog_idx 等于 server.repl_backlog_histlen，计算退化成 <code>server.repl_backlog_size % server.repl_backlog_size = 0</code>。<br>我觉得这部分逻辑完全可以简化点，不然还真不好理解。然后，后面就是加上 skip offset 的计算。</p><p>另外，发送数据时需要注意，上面所说的第 1）种情况下，idx 在 backlog 中间，分两次发送，即</p><p><img src="https://s2.ax1x.com/2019/09/08/n8wK1I.jpg" srcset="/img/loading.gif" alt="n8wK1I.jpg"></p><p>这时，会在 master 上看到日志如下日志，<br><strong>Partial resynchronization request from xxx accepted. Sending xxx bytes of backlog starting from offset xxx.</strong></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之主从复制 (1)</title>
    <link href="/a4bc6018.html"/>
    <url>/a4bc6018.html</url>
    
    <content type="html"><![CDATA[<p>在分布式系统中，为了解决单点问题，通常会把数据集复制多个副本部署到其他机器，以满足故障恢复和负载均衡等需求。redis 为我们提供的复制功能，实现了相同数据的多个副本，这也是其实现 HA 的基础。</p><a id="more"></a><p>参与 redis 复制功能的节点被分成两个角色，主节点（<strong>master</strong>）和从节点（<strong>slave</strong>），复制的数据流是单向的，即 <strong>master → slave</strong>。<br>默认情况下，每个 redis 实例都是 master，mater 与 slave 的关系为 <strong>1:n</strong>（也可以没有 slave），但一个 slave 只能有一个 master。</p><p>redis 的复制功能涉及同步（<strong>sync</strong>）和命令传播（<strong>command propagate</strong>）两个阶段。<br><strong>同步 </strong> 阶段用于将 slave 的数据库状态更新至 master 当前所处的数据库状态，即追数据阶段；<br><strong>命令传播 </strong> 阶段则用于当 master 数据库状态改变，导致主从节点数据库状态不一致时，使之重新回到一致状态。</p><h3 id="同步阶段">同步阶段</h3><p>在 <strong>2.8</strong> 版本以前，slave 对 master 的同步，是通过 slave 向 master 发送 <strong>SYNC</strong> 命令完成的。</p><p>1）slave 向 master 发送 <strong>SYNC</strong>；<br>2）master 收到 SYNC 后，执行 <strong>BGSAVE</strong> 命令，生成包含当前数据库状态的 RDB 文件，同时自身使用一个 buffer 记录从现在开始执行的所有改变其数据库状态的命令，RDB 生成完毕后将其发送给 slave；<br>3）slave 收到 RDB 文件后，载入数据，将自己的数据库状态更新至 master 执行 BGSAYE 时的状态；<br>4）master 将 buffer 累积的命令发给 slave；<br>5）slave 解析 master 发来的命令并执行，将数据追至与 master 当前所处的状态一致。</p><p>如果以上任一一步因为网络或者其他原因而 <strong> 中断</strong>，当 slave 再次连上 master 时，master 仍然需要重新做一个 BGSAVE，而这个命令是通过 <code>fork</code> 子进程来做的，频繁执行会影响性能，且复制效率低下。</p><p>为解决以上问题，redis 从 <strong>2.8</strong> 版本开始，引入新的同步命令 <strong>PSYNC</strong> 以支持断点续传。<br>要支持断点续传，就需要记录上次同步的位置，借助了以下三个变量：</p><p>1）master/slave 的复制偏移量(replication offset)；<br>2）master 的复制积压缓冲区(replication backlog)；<br>3）服务器的运行 ID(run ID)。</p><p>具体细节可以参考《<strong>redis 设计与实现</strong>》这本书的第 15 章。</p><h3 id="命令传播阶段">命令传播阶段</h3><p>在 <code>redisServer</code> 结构体中有一个 <code>dirty</code> 变量记录了自上一次成功执行 save 或者 bgsave 之后，数据库状态改变的次数。通过比较执行命令前后 的 <code>dirty</code> 值，就可以知道当前命令执行后数据库状态是否发生了改变，只有改变了才需要做 <strong>command propagate</strong>。</p><pre><code class="language-c">void call(client *c, int flags) {...    dirty = server.dirty;    start = ustime();    c-&gt;cmd-&gt;proc(c);    duration = ustime()-start;    dirty = server.dirty-dirty;    if (dirty &lt; 0) dirty = 0;    ...    if (dirty) propagate_flags |= (PROPAGATE_AOF|PROPAGATE_REPL);    ...    if (propagate_flags != PROPAGATE_NONE)      propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);    ...}void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc,               int flags){if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF)        feedAppendOnlyFile(cmd,dbid,argv,argc);    if (flags &amp; PROPAGATE_REPL)        replicationFeedSlaves(server.slaves,dbid,argv,argc);}</code></pre><p>对于主从复制的命令传播，在 <code>replicationFeedSlaves</code> 函数中实现。</p><pre><code class="language-c">void replicationFeedSlaves(list *slaves, int dictid, robj **argv, int argc) {    listNode *ln;    listIter li;    int j, len;    char llstr[LONG_STR_SIZE];    // 如果 backlog buffer 为空，且没有 slave，直接返回    if (server.repl_backlog == NULL &amp;&amp; listLength(slaves) == 0) return;    serverAssert(!(listLength(slaves) != 0 &amp;&amp; server.repl_backlog == NULL));    // 如果 dictid 与上一次 repl 选择的不一致，需要插入一条 select 命令    if (server.slaveseldb != dictid) {        robj *selectcmd;        ......    }    server.slaveseldb = dictid;    // 将命令以 redis 协议的格式写入 replication backlog    if (server.repl_backlog) {char aux[LONG_STR_SIZE+3];        /* Add the multi bulk reply length. */        aux[0] = '*';        len = ll2string(aux+1,sizeof(aux)-1,argc);        aux[len+1] = '\r';        aux[len+2] = '\n';        feedReplicationBacklog(aux,len+3);        for (j = 0; j &lt; argc; j++) {            // $..CRLF            long objlen = stringObjectLen(argv[j]);            aux[0] = '$';            len = ll2string(aux+1,sizeof(aux)-1,objlen);            aux[len+1] = '\r';            aux[len+2] = '\n';            feedReplicationBacklog(aux,len+3);            feedReplicationBacklogWithObject(argv[j]);            feedReplicationBacklog(aux+len+1,2); // CRLF        }    }    /* 将命令发送给所有的 slave. */    listRewind(server.slaves,&amp;li);    while((ln = listNext(&amp;li))) {        client *slave = ln-&gt;value;        /* Don't feed slaves that are still waiting for BGSAVE to start */        if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue;        // 以 redis 协议的格式发送给 slave        addReplyMultiBulkLen(slave,argc);        for (j = 0; j &lt; argc; j++)            addReplyBulk(slave,argv[j]);    }}</code></pre><p>以上便是主从同步的两个阶段，更多相关代码详解请看后面的博客分析。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redigo 源码分析</title>
    <link href="/1bcb9a09.html"/>
    <url>/1bcb9a09.html</url>
    
    <content type="html"><![CDATA[<p>使用 golang 开发项目时经常会使用到 redis 服务，这时就需要一个趁手的 sdk，所以就在 github 中找了一个 star 较多的项目，这就是本篇的主角 <strong>redigo</strong>，同时这也是 redis 的 <a href="https://redis.io/clients#go" target="_blank" rel="noopener"> 官方推荐</a>。</p><p>不过在使用过程中遇到了一些小问题，因此就去了解了一下源码，以下作为一个笔记。</p><a id="more"></a><p>redigo 项目代码量较少，且注释明确，适合阅读学习。<br>redigo 主要完成了以下功能:</p><ul><li><p>与 redis server 建立连接</p></li><li><p>按照 <a href="https://redis.io/topics/protocol" target="_blank" rel="noopener">RESP</a> 协议进行命令组装</p></li><li><p>向 Redis server 发送组装好的命令</p></li><li><p>接收 Redis server 返回的数据</p></li><li><p>将返回数据解析成 go 的数据类型</p></li><li><p>提供连接池的使用方式</p></li></ul><h2 id="1- 代码结构">1. 代码结构</h2><pre><code class="language-shell">redis├── conn.go  // 实现 redis.go 中定义的接口，完成以上主要功能├── conn_test.go├── doc.go├── go17.go├── log.go├── pool.go // pool 相关代码├── pool_test.go├── pre_go17.go├── pubsub.go├── pubsub_test.go├── redis.go // 定义接口├── reply.go // 返回数据的类型转换├── reply_test.go├── scan.go├── scan_test.go├── script.go // lua 脚本相关代码├── script_test.go├── test_test.go└── zpop_example_test.go</code></pre><p>项目主体主要有以上代码组成。</p><h2 id="2- 创建连接">2. 创建连接</h2><p>代码位于文件 <code>conn.go</code>，要创建的连接是一个自定义的数据结构 <code>conn</code>，如下，</p><pre><code class="language-go">// conn is the low-level implementation of Conntype conn struct {    // Shared    mu      sync.Mutex    pending int // 命令计数    err     error    conn    net.Conn    // Read    readTimeout time.Duration    br          *bufio.Reader    // Write    writeTimeout time.Duration    bw           *bufio.Writer    // Scratch space for formatting argument length.    // '*' or '$', length, &quot;\r\n&quot;    lenScratch [32]byte    // Scratch space for formatting integers and floats.    numScratch [40]byte}</code></pre><p>创建连接所需要的参数统一封装到结构体 <code>dialOptions</code> 中，如下，</p><pre><code class="language-go">type dialOptions struct {    readTimeout  time.Duration    writeTimeout time.Duration    dial         func(network, addr string) (net.Conn, error)    db           int    password     string    dialTLS      bool    skipVerify   bool    tlsConfig    *tls.Config}</code></pre><p>其中包含各种超时设置，创建连接使用的函数，以及 TLS 等。<br>参数设置则封装了一系列 <code>Dialxxxx</code> 函数，如 <code>DialWriteTimeout</code>,</p><pre><code class="language-go">// DialWriteTimeout specifies the timeout for writing a single command.func DialWriteTimeout(d time.Duration) DialOption {return DialOption{func(do *dialOptions) {do.writeTimeout = d}}}</code></pre><p>同时需要结合如下结构体完成，</p><pre><code class="language-go">type DialOption struct {f func(*dialOptions)}</code></pre><p>创建连接时使用的是 <code>Dial</code> 函数</p><pre><code class="language-go">// Dial connects to the Redis server at the given network and// address using the specified options.func Dial(network, address string, options ...DialOption) (Conn, error) {    do := dialOptions{dial: net.Dial,}    for _, option := range options { // 设置      option.f(&amp;do)    }    netConn, err := do.dial(network, address)    if err != nil {return nil, err}    // TLS 相关    // ...    c := &amp;conn{      conn:         netConn,      bw:           bufio.NewWriter(netConn),      br:           bufio.NewReader(netConn),      readTimeout:  do.readTimeout,      writeTimeout: do.writeTimeout,    }    if do.password != &quot;&quot; {if _, err := c.Do(&quot;AUTH&quot;, do.password); err != nil {netConn.Close()        return nil, err      }    }    if do.db != 0 {if _, err := c.Do(&quot;SELECT&quot;, do.db); err != nil {netConn.Close()        return nil, err      }    }    return c, nil}</code></pre><p>还有一个类似的 <code>DialURL</code> 函数就不分析了。</p><h2 id="3- 请求与接收">3. 请求与接收</h2><p>非 pipeline 的形式，都是通过 <code>Do</code> 函数去触发这个流程的。</p><pre><code class="language-go">func (c *conn) Do(cmd string, args ...interface{}) (interface{}, error) {c.mu.Lock() // 需要更新 pending 变量，加锁串行    pending := c.pending    c.pending = 0    c.mu.Unlock()    if cmd == &quot;&quot; &amp;&amp; pending == 0 {return nil, nil}    if c.writeTimeout != 0 {c.conn.SetWriteDeadline(time.Now().Add(c.writeTimeout)) // 设置写超时    }    if cmd != &quot;&quot; {if err := c.writeCommand(cmd, args); err != nil { // 将要发送的命令以 RESP 协议写到写 buf 里        return nil, c.fatal(err)      }    }    if err := c.bw.Flush(); err != nil { // buff flush，发送命令      return nil, c.fatal(err)    }    if c.readTimeout != 0 {c.conn.SetReadDeadline(time.Now().Add(c.readTimeout)) // 设置写超时    }    if cmd == &quot;&quot; {reply := make([]interface{}, pending)      for i := range reply {r, e := c.readReply()        if e != nil {return nil, c.fatal(e)        }        reply[i] = r      }      return reply, nil    }    var err error    var reply interface{}    for i := 0; i &lt;= pending; i++ {      var e error      if reply, e = c.readReply(); e != nil { // 解析返回值        return nil, c.fatal(e)      }      if e, ok := reply.(Error); ok &amp;&amp; err == nil {err = e}    }    return reply, err}</code></pre><h3 id="3-1- 发送命令">3.1 发送命令</h3><p>发送命令前必须以 RESP 协议序列化，主要用到以下函数，</p><pre><code class="language-go">func (c *conn) writeCommand(cmd string, args []interface{}) (err error) {c.writeLen('*', 1+len(args)) // +1 是将 cmd 加上，将参数个数写入 buf， 如 *3\r\n    err = c.writeString(cmd)    for _, arg := range args {      if err != nil {break}      switch arg := arg.(type) {      case string:        err = c.writeString(arg)      case []byte:        err = c.writeBytes(arg)      case int:        err = c.writeInt64(int64(arg))      case int64:        err = c.writeInt64(arg)      case float64:        err = c.writeFloat64(arg)      case bool:        if arg {err = c.writeString(&quot;1&quot;)        } else {err = c.writeString(&quot;0&quot;)        }      case nil:        err = c.writeString(&quot;&quot;)      default:        var buf bytes.Buffer        fmt.Fprint(&amp;buf, arg)        err = c.writeBytes(buf.Bytes())      }    }    return err}</code></pre><pre><code class="language-go"> // 用来写参数长度和参数个数，通过前缀传入 * 还是 $ 决定, 如 *3\r\n 或者 $3\r\nfunc (c *conn) writeLen(prefix byte, n int) error {c.lenScratch[len(c.lenScratch)-1] = '\n'    c.lenScratch[len(c.lenScratch)-2] = '\r'    i := len(c.lenScratch) - 3    for {c.lenScratch[i] = byte('0' + n%10)      i -= 1      n = n / 10      if n == 0 {break}    }    c.lenScratch[i] = prefix    _, err := c.bw.Write(c.lenScratch[i:])    return err}</code></pre><p>循环复用 <code>lenScratch</code> 数组，是个好的设计，不会产生很多小的字符串。</p><p>拼接完了参数个数部分，在再拼接参数部分，项目中实现了一系列<code>writexxx</code> 函数，对不同的类型有不同的拼接方式，以 string 类型为例，</p><pre><code class="language-go"> // 用来拼接每个参数，比如 GET，写成 $3\r\nGET\r\nfunc (c *conn) writeString(s string) error {c.writeLen('$', len(s))c.bw.WriteString(s)_, err := c.bw.WriteString(&quot;\r\n&quot;)return err}</code></pre><p>按照 RESP 协议的格式将命令拼接完以后需要发出去，通过 <code>bufio</code> 的 <code>Flush</code> 完成。<br>另外，redigo 还支持 pipeline 的返回方式发送请求，使用到的函数是 <code>Send</code> 和 <code>Flush</code>。在 <code>Send</code>中只是把命令写到 bufio 的 buff 里了，<code>Flush</code> 才会发到对端。</p><h3 id="3-2- 响应解析">3.2 响应解析</h3><p>发送命令成功后， redis server 那边处理完请求后，同样以 RESP 的格式回复。<br>解析函数是 <code>readReply</code>，对照着 RESP 协议看下就好了，还是很简单的。<br>multi bulk reply 可以反复调用 bulk reply 解析函数去递归完成解析。</p><h3 id="3-3- 关闭连接">3.3 关闭连接</h3><p>使用完毕连接以后，需要手动 close 掉，如下，</p><pre><code class="language-go">func (c *conn) Close() error {c.mu.Lock()    err := c.err    if c.err == nil {c.err = errors.New(&quot;redigo: closed&quot;)      err = c.conn.Close()}    c.mu.Unlock()    return err}</code></pre><h2 id="4-pool- 的分析">4. pool 的分析</h2><p>很多人在用 redigo 的时候会使用其连接池，因为使用该 sdk 时间较长，发现了 pool 的实现有两个版本。</p><h3 id="4-1- 老版本 -pool">4.1 老版本 pool</h3><p>主要数据结构为 <code>pool</code>，即</p><pre><code class="language-go">type Pool struct {    // Dial is an application supplied function for creating and configuring a    // connection.    //    // The connection returned from Dial must not be in a special state    // (subscribed to pubsub channel, transaction started, ...).    Dial func() (Conn, error)    // TestOnBorrow is an optional application supplied function for checking    // the health of an idle connection before the connection is used again by    // the application. Argument t is the time that the connection was returned    // to the pool. If the function returns an error, then the connection is    // closed.    // 检测连接的可用性，从外部注入。如果返回 error 则直接关闭连接    TestOnBorrow func(c Conn, t time.Time) error    // Maximum number of idle connections in the pool.    // 最大闲置连接数量    MaxIdle int    // Maximum number of connections allocated by the pool at a given time.    // When zero, there is no limit on the number of connections in the pool.    // 最大活动连接数, 如果为 0，则表示没有限制    MaxActive int    // Close connections after remaining idle for this duration. If the value    // is zero, then idle connections are not closed. Applications should set    // the timeout to a value less than the server's timeout.    // 闲置过期时间，在 get 函数中会有逻辑删除过期的连接    // 如果不设置，连接就不会过期    IdleTimeout time.Duration    // If Wait is true and the pool is at the MaxActive limit, then Get() waits    // for a connection to be returned to the pool before returning.    // 设置如果活动连接达到上限 再获取时候是等待还是返回错误    // 如果是 false 系统会返回 redigo: connection pool exhausted    // 如果是 true 会让协程等待直到有连接释放出来    Wait bool    // mu protects fields defined below.（主要是与状态相关）    mu     sync.Mutex    cond   *sync.Cond    closed bool    active int    // Stack of idleConn with most recently used at the front.    idle list.List}</code></pre><p>该版本中使用了条件变量 <code>Cond</code>来协调多协程获取连接池中的连接<br><code>idle</code> 使用的是 go 标准库 container 中的 list 数据结构，其中存放的是池中的连接，每个连接的数据结构如下，</p><pre><code class="language-go">type idleConn struct {    c Conn    t time.Time}</code></pre><p><code>pooledConnection</code> 结构实现了 <code>Conn</code> 接口的所有方法。</p><pre><code class="language-go">type pooledConnection struct {    p     *Pool // pool    c     Conn  // 当前连接    state int}</code></pre><h4 id="4-1-1- 从 -pool- 获取连接">4.1.1 从 pool 获取连接</h4><pre><code class="language-go">func (p *Pool) Get() Conn {c, err := p.get()    if err != nil {return errorConnection{err}    }    return &amp;pooledConnection{p: p, c: c}}</code></pre><p>当从连接池获取不到时就创建一个连接，所以还是重点看如何从连接池获取一个连接。</p><pre><code class="language-go">func (p *Pool) get() (Conn, error) {p.mu.Lock()    // Prune stale connections.(将过期连接的清理放到每次的 get 中)    // 如果 idletime 没有设置，连接就不会过期，因此也就不必清理    if timeout := p.IdleTimeout; timeout &gt; 0 {for i, n := 0, p.idle.Len(); i &lt; n; i++ {e := p.idle.Back() // 取出最后一个连接        if e == nil {break}        ic := e.Value.(idleConn)        if ic.t.Add(timeout).After(nowFunc()) { // 没有过期，立刻终止检查          break        }        p.idle.Remove(e)        p.release() // 需要操作 active 变量        p.mu.Unlock()        ic.c.Close() // 关闭连接        p.mu.Lock()}    }    for {      // Get idle connection.        for i, n := 0, p.idle.Len(); i &lt; n; i++ {e := p.idle.Front() // 从最前面取一个连接          if e == nil {       // idle 里是空的，先退出循环吧            break          }          ic := e.Value.(idleConn)          p.idle.Remove(e)          test := p.TestOnBorrow          p.mu.Unlock()          if test == nil || test(ic.c, ic.t) == nil { // 返回这个连接            return ic.c, nil          }          ic.c.Close() // 取出来的连接不可用          p.mu.Lock()          p.release()}        // Check for pool closed before dialing a new connection.        if p.closed {p.mu.Unlock()          return nil, errors.New(&quot;redigo: get on closed pool&quot;)        }        // Dial new connection if under limit.        if p.MaxActive == 0 || p.active &lt; p.MaxActive {          dial := p.Dial          p.active += 1          p.mu.Unlock()          c, err := dial()          if err != nil {p.mu.Lock()            p.release()            p.mu.Unlock()            c = nil          }          return c, err        }        // 到达连接池最大连接数了，要不要等呢？        if !p.Wait { // 不 wait 的话就直接返回连接池资源耗尽的错误          p.mu.Unlock()          return nil, ErrPoolExhausted        }        if p.cond == nil {p.cond = sync.NewCond(&amp;p.mu)        }        p.cond.Wait() // wait 等待 release 和 put 后有新的连接可用}}</code></pre><p>当有设置 IdleTimeout 时，那么到了每次 <code>get</code> 连接的时候都会从队尾拿一个连接，检查时间是否过期，如果过期，那么把它删掉，然后 <code>release</code>，这个操作一直持久直至找到一个没有过期的连接。</p><p>然后从 <strong> 队首 </strong> 拿一个连接，拿到后检查可用后返回，不可用的连接处理方式同上面的过期连接。</p><p>如果这个 pool 的状态已经是 close 了，那么直接返回。把这个检查放在这里，使 closed pool 仍然可以清理一些过期连接，减少内存占用。</p><p>如果 pool 没有设置 MaxActive，或者当前 pool 中的 active 没到阈值，那么可以使用 <code>dial</code>函数创建一个新连接，active 值加 1。</p><p>如果逻辑走到这里还没有取到连接，说明现在 pool 里的连接都被用了，如果不想 <code>wait</code>，那么直接返回 pool 资源耗尽的错误 (<code>ErrPoolExhausted</code>)，否则使用 pool 的条件变量 <code>cond</code> 进行 <code>Wait</code>。我们都知道在 <code>Wait</code> 中 会先解锁，然后陷入阻塞等待唤醒。</p><p><code>cond</code>唤醒在 <code>release</code> 函数和 <code>put</code> 函数中，如下，</p><pre><code class="language-go">// release decrements the active count and signals waiters. The caller must// hold p.mu during the call.func (p *Pool) release() {    p.active -= 1    if p.cond != nil {p.cond.Signal() // 通知 wait 的请求返回连接    }}</code></pre><h4 id="4-1-2- 向 -pool-return- 连接">4.1.2 向 pool return 连接</h4><p>用完连接后要还回去，在调用连接的 <code>Close</code> 函数中会使用 <code>put</code>。</p><pre><code class="language-go">func (p *Pool) put(c Conn, forceClose bool) error {err := c.Err()    p.mu.Lock()    if !p.closed &amp;&amp; err == nil &amp;&amp; !forceClose {p.idle.PushFront(idleConn{t: nowFunc(), c: c}) // 放回头部      if p.idle.Len() &gt; p.MaxIdle {c = p.idle.Remove(p.idle.Back()).(idleConn).c // 如果连接池中数量超过了 maxidle，那么从后面删除一个      } else {c = nil}    }    if c == nil {      if p.cond != nil {p.cond.Signal() // 通知      }      p.mu.Unlock()      return nil    }    p.release()    p.mu.Unlock()    return c.Close()}</code></pre><p>将没有出错的连接并且不是别强制关闭的连接放回到 idle list 中，注意，这里是放到 <strong> 队头 </strong>！如果 list 长度大于最大闲置连接数(MaxIdle)，那么从队尾取连接 <code>remove</code> 掉。</p><p><code>Signal</code> 唤醒条件变量。</p><h3 id="4-2- 新版本 -pool">4.2 新版本 pool</h3><p>在版本的 pool 里，自己实现了一个 list，取代 golang 的官方库 list。</p><pre><code class="language-go">type idleList struct { // 只记录头尾count       int // list 长度front, back *poolConn}type poolConn struct { // 双链表节点c          Connt          time.Timecreated    time.Timenext, prev *poolConn}</code></pre><p>同时实现了几个双链表的操作，<code>pushFront</code>、<code>popFront</code> 和 <code>popBack</code>。<br>新版本的 pool 里去掉了条件变量，换上了 channel。</p><pre><code class="language-go">chInitialized uint32 // set to 1 when field ch is initializedch           chan struct{} // limits open connections when p.Wait is trueidle         idleList      // idle connectionswaitCount    int64         // total number of connections waited for.waitDuration time.Duration // total time waited for new connections.</code></pre><p>pool 里的连接个数使用了 buffer channel 进行控制，大小为 <code>MaxActive</code>。<br>在第一次从 pool 中获取连接时，进行 channel 来初始化，即</p><pre><code class="language-go">func (p *Pool) lazyInit() {    // Fast path.    if atomic.LoadUint32(&amp;p.chInitialized) == 1 {return}    // Slow path.    p.mu.Lock()    if p.chInitialized == 0 {p.ch = make(chan struct{}, p.MaxActive)      if p.closed {close(p.ch)      } else {        for i := 0; i &lt; p.MaxActive; i++ {p.ch &lt;- struct{}{}}      }      atomic.StoreUint32(&amp;p.chInitialized, 1)    }    p.mu.Unlock()}</code></pre><h4 id="4-2-1- 从 -pool- 获取连接">4.2.1 从 pool 获取连接</h4><pre><code class="language-go">func (p *Pool) get(ctx context.Context) (*poolConn, error) {// Handle limit for p.Wait == true.    var waited time.Duration    if p.Wait &amp;&amp; p.MaxActive &gt; 0 {p.lazyInit()      // wait indicates if we believe it will block so its not 100% accurate      // however for stats it should be good enough.      wait := len(p.ch) == 0      var start time.Time      if wait {start = time.Now()      }      if ctx == nil {&lt;-p.ch} else {        select {        case &lt;-p.ch:        case &lt;-ctx.Done():          return nil, ctx.Err()}      }      if wait {waited = time.Since(start)      }    }    p.mu.Lock()    if waited &gt; 0 {      p.waitCount++      p.waitDuration += waited    }    // Prune stale connections at the back of the idle list.    if p.IdleTimeout &gt; 0 {      n := p.idle.count      // 清理过期的 conn      for i := 0; i &lt; n &amp;&amp; p.idle.back != nil &amp;&amp; p.idle.back.t.Add(p.IdleTimeout).Before(nowFunc()); i++ {        pc := p.idle.back        p.idle.popBack()        p.mu.Unlock()        pc.c.Close()        p.mu.Lock()        p.active--      }    }    // Get idle connection from the front of idle list.    for p.idle.front != nil {      pc := p.idle.front      p.idle.popFront() // 从前面获取一个连接      p.mu.Unlock()      if (p.TestOnBorrow == nil || p.TestOnBorrow(pc.c, pc.t) == nil) &amp;&amp;        (p.MaxConnLifetime == 0 || nowFunc().Sub(pc.created) &lt; p.MaxConnLifetime) {return pc, nil}      pc.c.Close()      p.mu.Lock()      p.active--    }    // Check for pool closed before dialing a new connection.    if p.closed {p.mu.Unlock()      return nil, errors.New(&quot;redigo: get on closed pool&quot;)    }    // Handle limit for p.Wait == false.    if !p.Wait &amp;&amp; p.MaxActive &gt; 0 &amp;&amp; p.active &gt;= p.MaxActive {p.mu.Unlock()      return nil, ErrPoolExhausted    }   // 新建连接，更新 active    p.active++    p.mu.Unlock()    c, err := p.dial(ctx)    if err != nil {      c = nil      p.mu.Lock()      p.active--      if p.ch != nil &amp;&amp; !p.closed {p.ch &lt;- struct{}{} // 连接创建不成功，将这个名额还给 channel}      p.mu.Unlock()}    return &amp;poolConn{c: c, created: nowFunc()}, err}</code></pre><p>可以看到只有在连接池满了愿意等待时，才回初始化 buffer channel，即调用 <code>lazyInit</code> 函数，省去了不必要的内存占用，可以借鉴。<br>当连接池已满，则 channel 为空，此时取连接的流程会阻塞在 <code>&lt;-p.ch</code>，这跟上一版本的 <code>cond.Wait()</code> 有相同的作用。<br>有相同的清理过期连接的逻辑，以及连接创建逻辑。</p><h4 id="4-2-2- 从 -pool- 获取连接">4.2.2 从 pool 获取连接</h4><pre><code class="language-go">func (p *Pool) put(pc *poolConn, forceClose bool) error {p.mu.Lock()    if !p.closed &amp;&amp; !forceClose {pc.t = nowFunc()      p.idle.pushFront(pc)          // 访问头部      if p.idle.count &gt; p.MaxIdle { // 超出了 MaxIdle 的数量的话，从后面踢掉最后面的一个        pc = p.idle.back        p.idle.popBack()} else {pc = nil}    }    if pc != nil {p.mu.Unlock()      pc.c.Close()      p.mu.Lock()      p.active--    }    if p.ch != nil &amp;&amp; !p.closed {p.ch &lt;- struct{}{} // 放回池子}    p.mu.Unlock()    return nil}</code></pre><p><code>ch</code> 控制着 pool 中连接的数量，当取走一个时，需要 <code>&lt;-ch</code>，当还回一个时，需要 <code>ch &lt;- struct{}{}</code>。<br>另外，还要考虑到某些失败的情况，是否需要将配额还回 <code>ch</code>。</p><h3 id="4-3- 分析">4.3 分析</h3><p>从上面的代码可以看出，不管哪个版本的 pool，获得连接是从 <strong> 队首 </strong> 获取，还连接也是从 <strong> 队首 </strong> 还，淘汰过期连接或者多出的连接是从 <strong> 队尾 </strong> 淘汰。<br>另外，新版本的 pool 实现比老版本更加符合 golang 的语言风格。<br>从某种角度讲，这种 pool 的管理方式会造成 <strong> 某些连接过热 </strong> 的情况，即负载均衡不均，尤其是过期时间设置不合理的情况下，需慎重使用。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
      <tag>sdk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之故障转移</title>
    <link href="/54df012b.html"/>
    <url>/54df012b.html</url>
    
    <content type="html"><![CDATA[<p>在 Redis cluster 中故障转移是个很重要的功能，下面就从故障发现到故障转移整个流程做一下详细分析。</p><a id="more"></a><h2 id="1- 故障检测">1. 故障检测</h2><h3 id="1-1-PFAIL- 标记">1.1 PFAIL 标记</h3><p>集群中每个节点都会定期向其他节点发送 <strong>PING</strong> 消息，以此来检测对方是否在线，如果接收 <strong>PING</strong> 消息的节点 B 没有在规定时间（<strong>cluster_node_timeout</strong>）内回应节点 A <strong>PONG</strong> 消息，那么节点 A 就会将节点 B 标记为疑似下线（probable fail,  <strong>PFAIL</strong>）。</p><pre><code class="language-c">void clusterCron(void) {    // ...    di = dictGetSafeIterator(server.cluster-&gt;nodes);    while((de = dictNext(di)) != NULL) {clusterNode *node = dictGetVal(de);        now = mstime(); /* Use an updated time at every iteration. */        // ...        delay = now - node-&gt;ping_sent;        if (delay &gt; server.cluster_node_timeout) {            /* Timeout reached. Set the node as possibly failing if it is             * not already in this state. */            if (!(node-&gt;flags &amp; (CLUSTER_NODE_PFAIL|CLUSTER_NODE_FAIL))) {                node-&gt;flags |= CLUSTER_NODE_PFAIL;                update_state = 1;            }        }    }    dictReleaseIterator(di);    // ...}</code></pre><p>可以看到，在 <code>clusterCron</code> 函数中如果对节点 B 发出 PING 消息，在 <strong>server.cluster_node_timeout</strong> 时间内没有收到其返回的 PONG 消息，如果节点 B 现在没有被标记成 <strong>CLUSTER_NODE_PFAIL</strong> 状态，那么现在就做下这个标记。<br>可以根据 <strong>ping_sent</strong> 参数进行判断的依据如下，</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {    // ...    if (link-&gt;node &amp;&amp; type == CLUSTERMSG_TYPE_PONG) {link-&gt;node-&gt;pong_received = mstime();        link-&gt;node-&gt;ping_sent = 0;        // ...    }    // ...}</code></pre><p>当节点 A 接收到节点 B 的 PONG 消息时，会把 <strong>ping_sent</strong> 更新成 0，同时记下收到本次 PONG 消息的时间。<br>上面提到的 clusterNode 与 clusterLink 有如下关联关系：<br><img src="http://ww1.sinaimg.cn/large/71ca8e3cly1fzpznib0gij20ff07qjrt.jpg" srcset="/img/loading.gif" alt=""></p><p>可以看出， clusterLink 就是为了接收对端 gossip 消息而设置的。<br>另外，我们发现， 在上面的 <code>clusterCron</code> 函数中将节点标记成 PFAIL 时，会将 update_state 变量置为 1，这会引发后面更改集群状态的逻辑。</p><pre><code class="language-c">if (update_state || server.cluster-&gt;state == CLUSTER_FAIL)    clusterUpdateState();</code></pre><p>集群有两个状态，<strong>CLUSTER_OK</strong> 和  <strong>CLUSTER_FAIL</strong>，如果集群目前状态是 CLUSTER_FAIL，且设置了参数 <code>cluster-require-full-coverage yes</code>，那么此时访问集群会返回错误，意思是可能有某些 slot 没有被 server 接管。<br><code>clusterUpdateState</code> 函数负责更新集群状态，该部分逻辑与本篇博文要讲的主逻辑关系不大，所以放到了后面的 <strong> 补充章节 </strong> 中了。</p><h3 id="1-2-FAIL- 标记">1.2 FAIL 标记</h3><h4 id="1-2-1- 主动标记 -FAIL">1.2.1 主动标记 FAIL</h4><p>被节点 A 标记成 FAIL/ PFAIL 的节点如何让节点 C 知道呢？这主要是通过平常发送的 PING/PONG 消息实现的，在 3.x 的版本时，会尽最大努力把这样的节点放到 gossip 消息的流言部分，到后面的 4.x 版本的代码中每次的 PING/PONG 消息都会把 PFAIL 节点都带上。<br><code>clusterProcessGossipSection</code> 函数用来处理 gossip 消息的流言部分。</p><pre><code class="language-c">void clusterProcessGossipSection(clusterMsg *hdr, clusterLink *link) {uint16_t count = ntohs(hdr-&gt;count);    clusterMsgDataGossip *g = (clusterMsgDataGossip*) hdr-&gt;data.ping.gossip;    clusterNode *sender = link-&gt;node ? link-&gt;node : clusterLookupNode(hdr-&gt;sender);    while(count--) {        // ...        node = clusterLookupNode(g-&gt;nodename);        if (node) {if (sender &amp;&amp; nodeIsMaster(sender) &amp;&amp; node != myself) {if (flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL)) {if (clusterNodeAddFailureReport(node,sender)) {                        serverLog(LL_VERBOSE,                           &quot;Node %.40s reported node %.40s as not reachable.&quot;,                            sender-&gt;name, node-&gt;name);                    }                    markNodeAsFailingIfNeeded(node);                } else {// ...}            }        // ...        }    // ...    }    // ...}</code></pre><p>该函数依次处理 gossip 消息流言部分携带的各节点信息（总节点数的 1/10）。当发现带有 CLUSTER_NODE_FAIL 或者 CLUSTER_NODE_PFAIL 时会调用 <code>clusterNodeAddFailureReport</code> 函数。</p><pre><code class="language-c">int clusterNodeAddFailureReport(clusterNode *failing, clusterNode *sender) {    list *l = failing-&gt;fail_reports;    listNode *ln;    listIter li;    clusterNodeFailReport *fr;    /* If a failure report from the same sender already exists, just update     * the timestamp. */    listRewind(l,&amp;li);    while ((ln = listNext(&amp;li)) != NULL) {        fr = ln-&gt;value;        if (fr-&gt;node == sender) {fr-&gt;time = mstime();            return 0;        }    }    /* Otherwise create a new report. */    fr = zmalloc(sizeof(*fr));    fr-&gt;node = sender;    fr-&gt;time = mstime();    listAddNodeTail(l,fr);    return 1;}</code></pre><p>每一个节点都有一个名为 fail_reports 的 list 结构的变量，用来搜集该异常节点获得了集群中哪些节点的 PFAIL 状态投票。fail_reports 每个成员都是一个 clusterNodeFailReport 结构。</p><pre><code class="language-c">typedef struct clusterNodeFailReport {    struct clusterNode *node;  /* Node reporting the failure condition. */    mstime_t time;             /* Time of the last report from this node. */} clusterNodeFailReport;</code></pre><p>clusterNodeFailReport 中带有时间戳，标记这个节点上一次被报上来处于异常状态的时间。<br>每次调用 <code>clusterNodeAddFailureReport</code> 函数时，先会检查 sender 是否已经为该异常节点投票过了，如果有，更新时间戳，如果没有，把 sender 加入到投票节点中。<br>简单点说就是，在 A 节点看来 B 节点是  PFAIL 状态，在 gossip 通信中把它告诉了 C 节点，C 节点发现这个异常状态的节点，检查一下为 B 节点投过票的节点中有没有  A 节点，如果没有就加进去。</p><p>然后下面就是判断 PFAIL 状态是不是要转变成 FAIL 状态的关键。</p><pre><code class="language-c">void markNodeAsFailingIfNeeded(clusterNode *node) {    int failures;    int needed_quorum = (server.cluster-&gt;size / 2) + 1;    if (!nodeTimedOut(node)) return; /* We can reach it. */    if (nodeFailed(node)) return; /* Already FAILing. */    failures = clusterNodeFailureReportsCount(node);    /* Also count myself as a voter if I'm a master. */    if (nodeIsMaster(myself)) failures++;    if (failures &lt; needed_quorum) return; /* No weak agreement from masters. */    serverLog(LL_NOTICE, &quot;Marking node %.40s as failing (quorum reached).&quot;, node-&gt;name);    /* Mark the node as failing. */    node-&gt;flags &amp;= ~CLUSTER_NODE_PFAIL;    node-&gt;flags |= CLUSTER_NODE_FAIL;    node-&gt;fail_time = mstime();    /* Broadcast the failing node name to everybody, forcing all the other     * reachable nodes to flag the node as FAIL. */    if (nodeIsMaster(myself)) clusterSendFail(node-&gt;name); /* 广播这个节点的 fail 消息 */    clusterDoBeforeSleep(CLUSTER_TODO_UPDATE_STATE|CLUSTER_TODO_SAVE_CONFIG);}</code></pre><p>C 节点收到消息，检查下 A 报过来的异常节点 B，在自己看来是否也是 PFAIL 状态的，如果不是，那么不理会 A 节点本次 report。如果在节点 C 看来，节点 B 已经被标记成 FAIL 了，那么就不需要进行下面的判定了。</p><p>在函数 <code>clusterNodeFailureReportsCount</code> 中会判断计算出把 B 节点标记成 PFAIL 状态的节点的数量 sum，如果 <strong>sum 值小于集群 size 的一半 </strong>，为防止误判，忽略掉这条信息。在函数 <code>clusterNodeFailureReportsCount</code> 中会检查关于 B 节点的 <strong>clusterNodeFailReport</strong>，清理掉那些<strong> 过期的 </strong> 投票，过期时间为 2 倍的 <strong>server.cluster_node_timeout</strong>。</p><p>如果满足条件，节点 C 将节点 B 的 PFAIL 状态消除，标记成 FAIL，同时记下 fail_time，如果 C 节点是个 master，那么将 B 节点 FAIL 的消息广播出去，以便让集群中其他节点尽快知道。</p><pre><code class="language-c">void clusterSendFail(char *nodename) {unsigned char buf[sizeof(clusterMsg)];    clusterMsg *hdr = (clusterMsg*) buf;    clusterBuildMessageHdr(hdr,CLUSTERMSG_TYPE_FAIL);    memcpy(hdr-&gt;data.fail.about.nodename,nodename,CLUSTER_NAMELEN);    clusterBroadcastMessage(buf,ntohl(hdr-&gt;totlen));}</code></pre><p>发送的 gossip 消息类型为 CLUSTERMSG_TYPE_FAIL，广播的节点排除自身和处于 HANDSHAKE 状态节点。</p><h4 id="1-2-2-Gossip- 被动感知 -FAIL">1.2.2 Gossip 被动感知 FAIL</h4><p>前面说过，gossip 消息的处理函数为 <code>clusterProcessPacket</code>，下面看 CLUSTERMSG_TYPE_FAIL 类型的消息如何处理。</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {    // ...    uint16_t type = ntohs(hdr-&gt;type);    // ...    if (type == CLUSTERMSG_TYPE_FAIL) { // fail        clusterNode *failing;        if (sender) {failing = clusterLookupNode(hdr-&gt;data.fail.about.nodename);            if (failing &amp;&amp; !(failing-&gt;flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_MYSELF)))            {                serverLog(LL_NOTICE,                    &quot;FAIL message received from %.40s about %.40s&quot;,                    hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);                failing-&gt;flags |= CLUSTER_NODE_FAIL;                failing-&gt;fail_time = mstime();                failing-&gt;flags &amp;= ~CLUSTER_NODE_PFAIL;                clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG|                                     CLUSTER_TODO_UPDATE_STATE);            }        } else {            serverLog(LL_NOTICE,                &quot;Ignoring FAIL message from unknown node %.40s about %.40s&quot;,                hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);        }    }    // ...}</code></pre><p>集群中另一个节点 D 收到节点 B 广播过来的消息：B 节点 FAIL 了。如果 D 还没有把 B 标记成 FAIL，那么标记成 CLUSTER_NODE_FAIL，并取消 CLUSTER_NODE_PFAIL 标记；否则，忽略，因为 D 已经知道 B 是 FAIL 节点了。</p><h2 id="2- 故障转移">2. 故障转移</h2><p>failover 分为两类，主动 failover（主动切主从）以及被动 failover（被动切主从），下面挨个进行分析。</p><h3 id="2-1- 被动 -failover">2.1 被动 failover</h3><h4 id="2-1-1- 先验条件及初始化">2.1.1 先验条件及初始化</h4><pre><code class="language-c">void clusterCron(void) {    // ...    if (nodeIsSlave(myself)) {clusterHandleSlaveFailover();        // ...    }    // ...}</code></pre><p>是否要做被动主从切换，在 <code>clusterHandleSlaveFailover</code> 函数中有如下的判断逻辑，</p><pre><code class="language-c">if (nodeIsMaster(myself) ||    myself-&gt;slaveof == NULL ||    (!nodeFailed(myself-&gt;slaveof) &amp;&amp; !manual_failover) ||    myself-&gt;slaveof-&gt;numslots == 0){    /* There are no reasons to failover, so we set the reason why we     * are returning without failing over to NONE. */    server.cluster-&gt;cant_failover_reason = CLUSTER_CANT_FAILOVER_NONE;    return;}</code></pre><p>只有满足如下条件的节点才有资格做 failover：</p><ul><li>slave 节点</li><li>master 不为空</li><li>master 负责的 slot 数量不为空</li><li>master 被标记成了 FAIL，或者这是一个主动 failover（manual_failover 为真）</li></ul><p>假设，现在 B 节点的 slave Bx 节点检测到 B 节点挂掉了，通过了以上的条件测试，接下来就会进行 failover。<br>那么下面 Bx 节点就开始在集群中进行拉票，该逻辑也在 <code>clusterHandleSlaveFailover</code> 函数中。</p><pre><code class="language-c">mstime_t auth_age = mstime() - server.cluster-&gt;failover_auth_time;int needed_quorum = (server.cluster-&gt;size / 2) + 1;mstime_t auth_timeout, auth_retry_time;auth_timeout = server.cluster_node_timeout*2;if (auth_timeout &lt; 2000) auth_timeout =2000 ;auth_retry_time = auth_timeout*2;</code></pre><p>cluster 的 <strong>failover_auth_time</strong> 属性，表示 slave 节点开始进行故障转移的时刻。集群初始化时该属性置为 0，一旦满足 failover 的条件后，该属性就置为 <strong> 未来的某个时间点</strong>（不是立马执行），在该时间点，slave 节点才开始进行拉票。<strong>auth_age</strong> 变量表示从发起 failover 流程开始到现在，已经过去了多长时间。<br><strong>needed_quorum</strong> 变量表示当前 slave 节点必须至少获得多少选票，才能成为新的 master。<br><strong>auth_timeout</strong> 变量表示当前 slave 发起投票后，等待回应的超时时间，至少为 2s。如果超过该时间还没有获得足够的选票，那么表示本次 failover 失败。<br><strong>auth_retry_time</strong> 变量用来判断是否可以开始发起下一次 failover 的时间间隔。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_CONNECTED) {data_age = (mstime_t)(server.unixtime - server.master-&gt;lastinteraction) * 1000;} else {data_age = (mstime_t)(server.unixtime - server.repl_down_since) * 1000;}if (data_age &gt; server.cluster_node_timeout)    data_age -= server.cluster_node_timeout;</code></pre><p><strong>data_age</strong> 变量表示距离上一次与我的 master 节点交互过去了多长时间。经过 cluster_node_timeout 时间还没有收到 PONG 消息才会将节点标记为 PFAIL 状态。实际上 data_age 表示在 master 节点下线之前，当前 slave 节点有多长时间没有与其交互过了。</p><blockquote><p>data_age 主要用于判断当前 slave 节点的数据新鲜度；如果 data_age 超过了一定时间，表示当前 slave 节点的数据已经太老了，不能替换掉下线 master 节点，因此在不是手动强制故障转移的情况下，直接返回。</p></blockquote><h4 id="2-1-2- 制定 -failover- 时间">2.1.2 制定 failover 时间</h4><pre><code class="language-c">void clusterHandleSlaveFailover(void) {    // ...    if (auth_age &gt; auth_retry_time) {server.cluster-&gt;failover_auth_time = mstime() +            500 + /* Fixed delay of 500 milliseconds, let FAIL msg propagate. */            random() % 500; /* Random delay between 0 and 500 milliseconds. */        server.cluster-&gt;failover_auth_count = 0;        server.cluster-&gt;failover_auth_sent = 0;        server.cluster-&gt;failover_auth_rank = clusterGetSlaveRank();        /* We add another delay that is proportional to the slave rank.         * Specifically 1 second * rank. This way slaves that have a probably         * less updated replication offset, are penalized.         * */        server.cluster-&gt;failover_auth_time +=            server.cluster-&gt;failover_auth_rank * 1000;        if (server.cluster-&gt;mf_end) {server.cluster-&gt;failover_auth_time = mstime();            server.cluster-&gt;failover_auth_rank = 0;        }        // ...        clusterBroadcastPong(CLUSTER_BROADCAST_LOCAL_SLAVES);        return;    }    // ...}</code></pre><p>满足条件（<strong>auth_age &gt; auth_retry_time</strong>）后，发起故障转移流程。<br>首先设置故障转移发起时刻，即设置 failover_auth_time 时间。</p><pre><code class="language-c">mstime() + 500 + random()%500 + rank*1000</code></pre><p>固定延时 500ms 是为了让 master fail 的消息能够广泛传播到集群，这样集群中的其他节点才可能投票。<br>随机延时是为了避免多个你 slave 节点同时发起 failover 流程。<br>rank 表示 slave 节点的排名，计算方式如下，</p><pre><code class="language-c">int clusterGetSlaveRank(void) {    long long myoffset;    int j, rank = 0;    clusterNode *master;    serverAssert(nodeIsSlave(myself));    master = myself-&gt;slaveof;    if (master == NULL) return 0; /* Never called by slaves without master. */    myoffset = replicationGetSlaveOffset();    for (j = 0; j &lt; master-&gt;numslaves; j++)        if (master-&gt;slaves[j] != myself &amp;&amp;            master-&gt;slaves[j]-&gt;repl_offset &gt; myoffset) rank++;    return rank;}</code></pre><p>可以看出，排名主要是根据复制数据量来定，复制数据量越多，排名越靠前（rank 值越小）。这样做是为了做 failover 时尽量选择一个复制数据量较多的 slave，以尽最大努力保留数据。在没有开始拉选票之前，<strong>每隔一段时间 </strong>（每次调用<code>clusterHandleSlaveFailover</code> 函数，也就是每次 cron 的时间）就会调用一次 <code>clusterGetSlaveRank</code> 函数，以更新当前 slave 节点的排名。</p><p><strong>注意</strong>，如果是 mf，那么 failover_auth_time 和 failover_auth_rank 都置为 0，表示该 slave 节点现在就可以执行故障转移。</p><p>最后向该 master 的所有 slave 广播 PONG 消息，主要是为了更新复制偏移量，以便其他 slave 计算出 failover 时间点。<br>这时，函数返回，就此开始了一轮新的故障转移，当已经处在某一轮故障转移时，执行接下来的逻辑。</p><h4 id="2-1-3-slave- 拉选票">2.1.3 slave 拉选票</h4><p>首先对于一些不合理的 failover 要过滤掉。</p><pre><code class="language-c">/* Return ASAP if we can't still start the election. */if (mstime() &lt; server.cluster-&gt;failover_auth_time) {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_WAITING_DELAY);    return;}/* Return ASAP if the election is too old to be valid. * failover 超时 */if (auth_age &gt; auth_timeout) {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_EXPIRED);    return;}</code></pre><p>然后开始拉选票。</p><pre><code class="language-c">if (server.cluster-&gt;failover_auth_sent == 0) {    server.cluster-&gt;currentEpoch++; // 增加当前节点的 currentEpoch 的值，表示要开始新一轮选举了    server.cluster-&gt;failover_auth_epoch = server.cluster-&gt;currentEpoch;    serverLog(LL_WARNING,&quot;Starting a failover election for epoch %llu.&quot;,              (unsigned long long) server.cluster-&gt;currentEpoch);    /* 向所有节点发送 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，开始拉票 */    clusterRequestFailoverAuth();    server.cluster-&gt;failover_auth_sent = 1; // 表示已经发起了故障转移流程    clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG|                         CLUSTER_TODO_UPDATE_STATE|                         CLUSTER_TODO_FSYNC_CONFIG);    return; /* Wait for replies. */}</code></pre><p>如果 <strong>failover_auth_sent</strong> 为 0，表示没有发起过投票，那么将 currentEpoch 加 1，记录 failover_auth_epoch 为 currentEpoch，函数 <code>clusterRequestFailoverAuth</code> 用来发起投票，failover_auth_sent 置 1，表示该 slave 已经发起过投票了。</p><pre><code class="language-c">void clusterRequestFailoverAuth(void) {unsigned char buf[sizeof(clusterMsg)];    clusterMsg *hdr = (clusterMsg*) buf;    uint32_t totlen;    clusterBuildMessageHdr(hdr,CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST);    /* If this is a manual failover, set the CLUSTERMSG_FLAG0_FORCEACK bit     * in the header to communicate the nodes receiving the message that     * they should authorized the failover even if the master is working. */    if (server.cluster-&gt;mf_end) hdr-&gt;mflags[0] |= CLUSTERMSG_FLAG0_FORCEACK;    totlen = sizeof(clusterMsg)-sizeof(union clusterMsgData);    hdr-&gt;totlen = htonl(totlen);    clusterBroadcastMessage(buf,totlen);}</code></pre><p><code>clusterRequestFailoverAuth</code> 函数向集群广播 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</strong> 类型的 gossip 信息，这类型的信息就是向集群中的 master 节点索要本轮选举中的选票。另外，如果是 mf，那么会在 gossip hdr 中带上 <strong>CLUSTERMSG_FLAG0_FORCEACK</strong> 信息。</p><h4 id="2-1-4- 其他 -master- 投票">2.1.4 其他 master 投票</h4><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST) {if (!sender) return 1;  /* We don't know that node. */    clusterSendFailoverAuthIfNeeded(sender,hdr);}</code></pre><p>在 <code>clusterProcessPacket</code> 函数中处理 gossip 消息，当接收到 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</strong> 类型的消息时，调用 <code>clusterSendFailoverAuthIfNeeded</code> 函数处理，在满足条件的基础上，给 sender 投票。</p><p>注：以下若不进行特殊说明，都是 <code>clusterSendFailoverAuthIfNeeded</code> 函数处理逻辑。</p><h5 id="2-1-4-1- 筛掉没资格投票的节点">2.1.4.1 筛掉没资格投票的节点</h5><pre><code class="language-c"> if (nodeIsSlave(myself) || myself-&gt;numslots == 0) return;</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  slave 节点或者不负责 slot 的 master 节点</p><h5 id="2-1-4-2- 筛掉不需要投票的 -sender">2.1.4.2 筛掉不需要投票的 sender</h5><pre><code class="language-c">uint64_t requestCurrentEpoch = ntohu64(request-&gt;currentEpoch);if (requestCurrentEpoch &lt; server.cluster-&gt;currentEpoch) {    serverLog(LL_WARNING,              &quot;Failover auth denied to %.40s: reqEpoch (%llu) &lt; curEpoch(%llu)&quot;,              node-&gt;name,              (unsigned long long) requestCurrentEpoch,              (unsigned long long) server.cluster-&gt;currentEpoch);    return;}</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  sender 节点集群信息过旧。<br>正常来说，如果 receiver 在接收到 sender 的 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息之前接收了 PING/PONG 消息，会更新自己的 currentEpoch，这时 currentEpoch 会增加，因为 sender 发起选举之前，会先增加自身的 currentEpoch；否则的话，receiver 的 currentEpoch 应该小于 sender。因此 sender 的 currentEpoch 应该 <strong>&gt;=</strong>  receiver 的。有可能 sender 是个长时间下线的节点刚刚上线，这样的节点不能给他投票，因为它的集群信息过旧。</p><pre><code class="language-c">if (server.cluster-&gt;lastVoteEpoch == server.cluster-&gt;currentEpoch) {    serverLog(LL_WARNING,              &quot;Failover auth denied to %.40s: already voted for epoch %llu&quot;,              node-&gt;name,              (unsigned long long) server.cluster-&gt;currentEpoch);    return;}</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  receiver 节点在本轮选举中已经投过票了，避免两个 slave 节点同时赢得本界选举。<br>lastVoteEpoch 记录了在本轮投票中 receiver 投过票的 sender 的 currentEpoch。各 slave 节点独立发起选举，currentEpoch 是相同的，都在原来的基础上加 1。</p><pre><code class="language-c">clusterNode *master = node-&gt;slaveof;if (nodeIsMaster(node) || master == NULL || (!nodeFailed(master) &amp;&amp; !force_ack)){if (nodeIsMaster(node)) {        serverLog(LL_WARNING,                  &quot;Failover auth denied to %.40s: it is a master node&quot;,                  node-&gt;name);    } else if (master == NULL) {        serverLog(LL_WARNING,                  &quot;Failover auth denied to %.40s: I don't know its master&quot;,                  node-&gt;name);    } else if (!nodeFailed(master)) {        serverLog(LL_WARNING,                  &quot;Failover auth denied to %.40s: its master is up&quot;,                  node-&gt;name);    }    return;}</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  sender 是个 master。<br><i class="fa fa-times" aria-hidden="true"></i>  sender 是个没有 master 的 slave。<br><i class="fa fa-times" aria-hidden="true"></i>  sender 的 master 没有 fail，且不是个 mf。</p><pre><code class="language-c">if (mstime() - node-&gt;slaveof-&gt;voted_time &lt; server.cluster_node_timeout * 2){    serverLog(LL_WARNING,              &quot;Failover auth denied to %.40s: &quot;              &quot;can't vote about this master before %lld milliseconds&quot;,              node-&gt;name,              (long long) ((server.cluster_node_timeout*2) - (mstime() - node-&gt;slaveof-&gt;voted_time)));    return;}</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  两次投票时间间隔 <strong> 不能少于 2 倍 的 cluster_node_timeout</strong>。<br>这个裕量时间，使得获得赢得选举的 slave 将新的主从关系周知集群其他节点，避免其他 slave 发起新一轮的投票。</p><pre><code class="language-c">uint64_t requestConfigEpoch = ntohu64(request-&gt;configEpoch);unsigned char *claimed_slots = request-&gt;myslots;for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (bitmapTestBit(claimed_slots, j) == 0) continue;    if (server.cluster-&gt;slots[j] == NULL ||        server.cluster-&gt;slots[j]-&gt;configEpoch &lt;= requestConfigEpoch)    {continue;}    /* If we reached this point we found a slot that in our current slots         * is served by a master with a greater configEpoch than the one claimed         * by the slave requesting our vote. Refuse to vote for this slave. */    serverLog(LL_WARNING,              &quot;Failover auth denied to %.40s: &quot;              &quot;slot %d epoch (%llu) &gt; reqEpoch (%llu)&quot;,              node-&gt;name, j,              (unsigned long long) server.cluster-&gt;slots[j]-&gt;configEpoch,              (unsigned long long) requestConfigEpoch);    return;}</code></pre><p><i class="fa fa-times" aria-hidden="true"></i>  sender 节点声称要接管的 slots，在 receiver 节点看来其中有个别 slot 原来负责节点的 configEpoch 要比 sender 的大，这说明 sender 看到的集群消息太旧了，这可能是一个长时间下线又重新上线的节点。</p><h5 id="2-1-4-3- 在本轮选举投票">2.1.4.3 在本轮选举投票</h5><pre><code class="language-c">clusterSendFailoverAuth(node);server.cluster-&gt;lastVoteEpoch = server.cluster-&gt;currentEpoch;node-&gt;slaveof-&gt;voted_time = mstime(); // 更新投票时间</code></pre><p><code>clusterSendFailoverAuth</code> 函数中发送 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</strong> 类型的 gossip 消息，这就算在本轮选举中投票了，并记录本轮投票的 epoch 以及投票时间。</p><h4 id="2-1-5-slave- 统计选票">2.1.5 slave 统计选票</h4><p>slave 接收到 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</strong> 类型的 gossip 消息，就算统计到一票。</p><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK) { // slave 统计票数    if (!sender) return 1;  /* We don't know that node. */    /* We consider this vote only if the sender is a master serving         * a non zero number of slots, and its currentEpoch is greater or         * equal to epoch where this node started the election. */    if (nodeIsMaster(sender) &amp;&amp; sender-&gt;numslots &gt; 0 &amp;&amp;        senderCurrentEpoch &gt;= server.cluster-&gt;failover_auth_epoch)    {        server.cluster-&gt;failover_auth_count++;        /* Maybe we reached a quorum here, set a flag to make sure             * we check ASAP. */        clusterDoBeforeSleep(CLUSTER_TODO_HANDLE_FAILOVER);    }}</code></pre><p>sender 是个负责 slot 的 master 并且满足 currentEpoch 的要求，那么这张选票有效。出现 <code>senderCurrentEpoch &lt; server.cluster-&gt;failover_auth_epoch</code> 的情况时有可能的，如果这张选票是上一轮选举的获得选票，就不能作数。<br>failover_auth_count 变量中记录了 slave 在本轮选举中获得选票数目。</p><h4 id="2-1-6-slave- 做主从切换">2.1.6 slave 做主从切换</h4><pre><code class="language-c">void clusterHandleSlaveFailover(void) {    // ...    int needed_quorum = (server.cluster-&gt;size / 2) + 1;    if (server.cluster-&gt;failover_auth_count &gt;= needed_quorum) {        /* We have the quorum, we can finally failover the master. */        serverLog(LL_WARNING,                  &quot;Failover election won: I'm the new master.&quot;);        /* Update my configEpoch to the epoch of the election. */        if (myself-&gt;configEpoch &lt; server.cluster-&gt;failover_auth_epoch) {            myself-&gt;configEpoch = server.cluster-&gt;failover_auth_epoch;            serverLog(LL_WARNING,                      &quot;configEpoch set to %llu after successful failover&quot;,                      (unsigned long long) myself-&gt;configEpoch);        }        /* Take responsability for the cluster slots. */        clusterFailoverReplaceYourMaster();} else {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_WAITING_VOTES);    }}</code></pre><p>slave 节点获得足够多选票后， 成为新的 master 节点。<br>更新自己的 configEpoch 为 <strong> 选举协商 </strong> 的 failover_auth_epoch，这是本节点就获得了最新当前集群最大的 configEpoch，表明它看到的集群信息现在是最新的。<br>最后调用 <code>clusterFailoverReplaceYourMaster</code> 函数取代下线主节点，成为新的主节点，并向其他节点广播这种变化。</p><pre><code class="language-c">void clusterFailoverReplaceYourMaster(void) {    int j;    clusterNode *oldmaster = myself-&gt;slaveof;    if (nodeIsMaster(myself) || oldmaster == NULL) return;    /* 1) Turn this node into a master. */    /* 把 myself 标记为 master，并从原 master 里删掉，更新原 master 的涉及 slave 的参数，     * 如果 slave 数量为 0, 去掉它的 CLUSTER_NODE_MIGRATE_TO 标记     */    clusterSetNodeAsMaster(myself);    /* 取消主从复制过程，将当前节点升级为主节点 *、    replicationUnsetMaster();    /* 2) Claim all the slots assigned to our master.     * 接手老的 master 节点负责的槽位     */    for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (clusterNodeGetSlotBit(oldmaster,j)) {clusterDelSlot(j);            clusterAddSlot(myself,j);        }    }    /* 3) Update state and save config. */    clusterUpdateState();    clusterSaveConfigOrDie(1);    /* 4) Pong all the other nodes so that they can update the state     *    accordingly and detect that we switched to master role. */    clusterBroadcastPong(CLUSTER_BROADCAST_ALL);    /* 5) If there was a manual failover in progress, clear the state. */    resetManualFailover();}</code></pre><p>进行必要的 flag 设置和 slots 交接，向集群广播 PONG 消息，并进行善后处理。</p><h4 id="2-1-7- 集群其他节点感知主从变化">2.1.7 集群其他节点感知主从变化</h4><pre><code class="language-c">if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_PONG || type == CLUSTERMSG_TYPE_MEET) {    // ...    /* Check for role switch: slave -&gt; master or master -&gt; slave. */    if (sender) {if (!memcmp(hdr-&gt;slaveof, CLUSTER_NODE_NULL_NAME, sizeof(hdr-&gt;slaveof)))        {            /* Node is a master. set master flag for sender */            clusterSetNodeAsMaster(sender);        }        // ...    }    clusterNode *sender_master = NULL; /* Sender or its master if slave. */    int dirty_slots = 0; /* Sender claimed slots don't match my view? */    if (sender) {sender_master = nodeIsMaster(sender) ? sender : sender-&gt;slaveof;        if (sender_master) {dirty_slots = memcmp(sender_master-&gt;slots, hdr-&gt;myslots, sizeof(hdr-&gt;myslots)) != 0;        }    }    if (sender &amp;&amp; nodeIsMaster(sender) &amp;&amp; dirty_slots)        clusterUpdateSlotsConfigWith(sender,senderConfigEpoch,hdr-&gt;myslots);    // ...}</code></pre><p>集群中其他节点接收到 PONG 消息后，对 sender 进行正确的 role 标记，以某节点 D 为例。<br>对于刚刚做完故障转移的 slave，也即现在 master，在节点 D 看来它负责的 slot 是空的，所以 dirty_slots 为 1。<br>之后调用 <code>clusterUpdateSlotsConfigWith</code> 函数处理 slots 的 dirty diff 信息。</p><p>至此 failover 的逻辑就已经基本完成。</p><h3 id="2-2- 主动 -failover">2.2 主动 failover</h3><p>除了上面的发现故障后集群自动 failover，也可以进行主动的主从切换。</p><h4 id="2-2-1-slave- 节点接受 -cluster-failover- 命令">2.2.1 slave 节点接受 cluster failover 命令</h4><p>主动 failover 是通过 redis 命令实现的，命令格式为 <code>CLUSTER FAILOVER [FORCE|TAKEOVER]</code>，该命令使用详情可以参考这篇 <a href="http://www.redis.cn/commands/cluster-failover.html" target="_blank" rel="noopener"> 文档</a>。</p><pre><code class="language-c">#define CLUSTER_MF_TIMEOUT 5000else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;failover&quot;) &amp;&amp; (c-&gt;argc == 2 || c-&gt;argc == 3)){/* CLUSTER FAILOVER [FORCE|TAKEOVER] */    int force = 0, takeover = 0;    if (c-&gt;argc == 3) {        /* 不与 master 沟通，主节点也不会阻塞其客户端，需要经过选举 */        if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,&quot;force&quot;)) {            force = 1;        /* 不与 master 沟通，不经过选举 */        } else if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,&quot;takeover&quot;)) {            takeover = 1;            force = 1; /* Takeover also implies force. */        /* 与 master 沟通，需要经过选举 */        } else {addReply(c,shared.syntaxerr);            return;        }    }    // ...    server.cluster-&gt;mf_end = mstime() + CLUSTER_MF_TIMEOUT; // mf 的超时时间为 5s}</code></pre><p>cluster failover 命令有三种不同的选项，各有不同的含义，如上面注释所说。takeover 变量标记是否要经过选举， force 变量标记是否需要与 master 沟通。<br>另外，mf 过程有一个过期时间，目前定义为 5s，同时， mf_end 也表示现在正在做 mf。<br>不同的选项有不同的处理方式，如下，</p><pre><code class="language-c">if (takeover) {    // takeover 不会做任何初始化校验。    // 不经过其他节点选举协商，直接将该节点的 current epoch 加 1，然后广播这个新的配置    serverLog(LL_WARNING,&quot;Taking over the master (user request).&quot;);    clusterBumpConfigEpochWithoutConsensus();    clusterFailoverReplaceYourMaster();} else if (force) {    /* If this is a forced failover, we don't need to talk with our     * master to agree about the offset. We just failover taking over     * it without coordination. */    serverLog(LL_WARNING,&quot;Forced failover user request accepted.&quot;);    server.cluster-&gt;mf_can_start = 1;// 可以直接开始选举过程} else {serverLog(LL_WARNING,&quot;Manual failover user request accepted.&quot;);    clusterSendMFStart(myself-&gt;slaveof); // 发送带有 CLUSTERMSG_TYPE_MFSTART 标记的 gossip 包 (只有消息头) 给我的 master}</code></pre><p>takeover 方式最为粗暴，slave 节点不发起选举，而是直接将自己升级为 master，接手原主节点的槽位，增加自己的 configEpoch 后更新配置。<code>clusterFailoverReplaceYourMaster</code> 的逻辑在前面讲过，只有在本轮选举中获得足够多的选票才会调用该函数。<br>force 方式表示可以直接开始选举过程，选举过程也在前面说过了。<br>现在来看看默认方式，处理逻辑为 <code>clusterSendMFStart</code> 函数。该函数主要逻辑就是发送向要做 failover 的 slave 的 master 发送 <code>CLUSTERMSG_TYPE_MFSTART</code> 类型的 gossip 消息。</p><h4 id="2-2-2-master- 节点做 -mf- 准备">2.2.2 master 节点做 mf 准备</h4><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_MFSTART) {    /* This message is acceptable only if I'm a master and the sender     * is one of my slaves. */    if (!sender || sender-&gt;slaveof != myself) return 1;    /* Manual failover requested from slaves.     * Initialize the state accordingly.     * master 收到消息，重置 mf 状态     */    resetManualFailover();    server.cluster-&gt;mf_end = mstime() + CLUSTER_MF_TIMEOUT;    server.cluster-&gt;mf_slave = sender;    pauseClients(mstime()+(CLUSTER_MF_TIMEOUT*2)); // 阻塞客户端 10s    serverLog(LL_WARNING,&quot;Manual failover requested by slave %.40s.&quot;,              sender-&gt;name);}</code></pre><p><code>resetManualFailover</code> 函数中重置与 mf 相关的参数，表示这是一次新的 mf。<br>设置 mf_end，将它的 master 指向 sender（就是那个搞事情的 slave），同时阻塞 client 10s 钟。<br>随后，标记在做 mf 的 master 发送 PING 信息时 hdr 会带上 <strong>CLUSTERMSG_FLAG0_PAUSED</strong> 标记。</p><pre><code class="language-c">void clusterBuildMessageHdr(clusterMsg *hdr, int type) {    // ...      /* Set the message flags. */    if (nodeIsMaster(myself) &amp;&amp; server.cluster-&gt;mf_end)        hdr-&gt;mflags[0] |= CLUSTERMSG_FLAG0_PAUSED;    // ...}</code></pre><p>mflags 记录与 mf 相关的 flag。</p><h4 id="2-2-3-slave- 处理">2.2.3 slave 处理</h4><h5 id="2-2-3-1- 获得 -master- 的 -repl-offset">2.2.3.1 获得 master 的 repl offset</h5><p>slave 节点处理带有  <strong>CLUSTERMSG_FLAG0_PAUSED</strong> 标记的 gossip 消息。</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {    // ...    sender = clusterLookupNode(hdr-&gt;sender);    if (sender &amp;&amp; !nodeInHandshake(sender)) {        // ...        if (server.cluster-&gt;mf_end &amp;&amp; // 处于 mf 状态            nodeIsSlave(myself) &amp;&amp;   // 我是 slave            myself-&gt;slaveof == sender &amp;&amp; // 我的 master 是 sender            hdr-&gt;mflags[0] &amp; CLUSTERMSG_FLAG0_PAUSED &amp;&amp;            server.cluster-&gt;mf_master_offset == 0) // 还没有正式开始时，mf_master_offset 设置为 0        {            server.cluster-&gt;mf_master_offset = sender-&gt;repl_offset; // 从 sender 获得 repl_offset            serverLog(LL_WARNING,                      &quot;Received replication offset for paused &quot;                      &quot;master manual failover: %lld&quot;,                      server.cluster-&gt;mf_master_offset);        }    }    // ...}</code></pre><p>对于那个发起 failover 的 slave，记下其 master 的 repl_offset，如果之前还没有记录下的话。</p><h5 id="2-2-3-2- 向 -maser- 追平 -repl-offset">2.2.3.2 向 maser 追平 repl offset</h5><pre><code class="language-c">void clusterCron(void) {    // ...    if (nodeIsSlave(myself)) {clusterHandleManualFailover();        // ...    }    // ...}void clusterHandleManualFailover(void) {    /* Return ASAP if no manual failover is in progress. */    if (server.cluster-&gt;mf_end == 0) return;    /* If mf_can_start is non-zero, the failover was already triggered so the     * next steps are performed by clusterHandleSlaveFailover(). */    if (server.cluster-&gt;mf_can_start) return;    if (server.cluster-&gt;mf_master_offset == 0) return; /* Wait for offset... */    if (server.cluster-&gt;mf_master_offset == replicationGetSlaveOffset()) {        /* Our replication offset matches the master replication offset         * announced after clients were paused. We can start the failover. */        server.cluster-&gt;mf_can_start = 1;        serverLog(LL_WARNING,                  &quot;All master replication stream processed, &quot;                  &quot;manual failover can start.&quot;);    }}</code></pre><p>在 <code>clusterCron</code> 函数里有 <code>clusterHandleManualFailover</code> 的逻辑。<br>mf_end 为 0，说明此时没有 mf 发生。<br>mf_can_start 非 0 值，表示现在可以此 slave 可以发起选举了。<br>mf_master_offset 为 0，说明现在还没有获得 master 的复制偏移量，需要等一会儿。当 mf_master_offset 值等于 <code>replicationGetSlaveOffset</code> 函数的返回值时，把 mf_can_start 置为 1。另外，应该记得，使用带有 force 选项的 <code>CLUSTER FAILOVER</code> 命令，直接就会把 mf_can_start 置为 1，而 <code>replicationGetSlaveOffset</code> 函数的作用就是检查当前的主从复制偏移量，也就是说主从复制偏移量一定要达到 mf_master_offset 时，slave 才会发起选举，即默认选项有一个追平 repl offset 的过程。</p><p>其他一些选举什么的流程跟被动 failover 没有区别。</p><h4 id="2-2-4- 过期清理 -mf">2.2.4 过期清理 mf</h4><p>主从节点在周期性的<code>clusterCron</code> 中都有一个检查本次 mf 是否过期的函数。</p><pre><code class="language-c">void manualFailoverCheckTimeout(void) {if (server.cluster-&gt;mf_end &amp;&amp; server.cluster-&gt;mf_end &lt; mstime()) {serverLog(LL_WARNING,&quot;Manual failover timed out.&quot;);        resetManualFailover();}}void resetManualFailover(void) {if (server.cluster-&gt;mf_end &amp;&amp; clientsArePaused()) {        server.clients_pause_end_time = 0;        clientsArePaused(); /* Just use the side effect of the function. */}    server.cluster-&gt;mf_end = 0; /* No manual failover in progress. */    server.cluster-&gt;mf_can_start = 0;    server.cluster-&gt;mf_slave = NULL;    server.cluster-&gt;mf_master_offset = 0;}</code></pre><p>如果过期没有做 mf ，那么就会重置它的相关参数。</p><h2 id="3- 附录">3. 附录</h2><h3 id="3-1-epoch- 概念">3.1 epoch 概念</h3><p>在 Redis cluster 里 epoch 是个非常重要的概念，类似于 raft 算法中的 term 概念。Redis cluster 里主要是两种：currentEpoch 和 configEpoch。</p><h4 id="3-1-1-currentEpoch">3.1.1 currentEpoch</h4><blockquote><p>这是一个集群状态相关的概念，可以当做记录集群状态变更的递增版本号。每个集群节点，都会通过 server.cluster-&gt;currentEpoch 记录当前的 currentEpoch。</p><p>集群节点创建时，不管是主节点还是从节点，都置 currentEpoch 为 0。当前节点接收到来自其他节点的包时，如果发送者的 currentEpoch（消息头部会包含发送者的 currentEpoch）大于当前节点的 currentEpoch，那么当前节点会更新 currentEpoch 为发送者的 currentEpoch。因此，集群中所有节点的 currentEpoch 最终会达成一致，相当于对集群状态的认知达成了一致。</p></blockquote><p>currentEpoch 作用在于，集群状态发生改变时，某节点会先增加自身 currentEpoch 的值，然后向集群中其他节点征求同意，以便执行某些动作。目前，仅用于 slave 节点的故障转移流程，在上面分析中也看到了，在发起选举之前，slave 会增加自己的 currentEpoch，并且得到的 currentEpoch 表示这一轮选举的 voteEpoch，当获得了足够多的选票后才会执行故障转移。</p><h4 id="3-1-2-configEpoch">3.1.2 configEpoch</h4><blockquote><p>这是一个集群节点配置相关的概念，每个集群节点都有自己独一无二的 configepoch。所谓的节点配置，实际上是指节点所负责的 slot 信息。</p></blockquote><p>configEpoch 主要用于解决不同的节点就 slot 归属认知发生冲突的情况。公说公有理婆说婆有理，到底听谁的，configEpoch 越大，看到的集群节点配置信息越新，就越有话语权。对于冲突的情况，后面会有博客进行详细分析。</p><p>以下几种情况 configEpoch 会更新：</p><ol><li>新节点加入；</li><li>槽节点映射冲突检测；（slot 归属变更）</li><li>从节点投票选举冲突检测。(主从切换)</li></ol><p>递增 node epoch 称为 bump epoch。关于 configEpoch 有三个原则：</p><ol><li>如果 epoch 不变, 集群就不应该有变更(包括选举和迁移槽位)。</li><li>每个节点的 node epoch 都是独一无二的。</li><li>拥有越高 epoch 的节点, 集群信息越新。</li></ol><h3 id="3-2-clusterUpdateState- 函数逻辑">3.2 clusterUpdateState 函数逻辑</h3><pre><code class="language-c">#define CLUSTER_MAX_REJOIN_DELAY 5000#define CLUSTER_MIN_REJOIN_DELAY 500#define CLUSTER_WRITABLE_DELAY 2000void clusterUpdateState(void) {    // ...    static mstime_t among_minority_time;    static mstime_t first_call_time = 0;    server.cluster-&gt;todo_before_sleep &amp;= ~CLUSTER_TODO_UPDATE_STATE;    /* 时间从第一次调用该函数算起，是为了跳过 DB load 时间。     * cluster 启动时，状态为 CLUSTER_FAIL，     * 这里要等待一定的时间 (2s) 让 cluster 变为 CLUSTER_OK 状态。     */    if (first_call_time == 0) first_call_time = mstime();    if (nodeIsMaster(myself) &amp;&amp;        server.cluster-&gt;state == CLUSTER_FAIL &amp;&amp;        mstime() - first_call_time &lt; CLUSTER_WRITABLE_DELAY) return;    /* 先假设集群状态为 CLUSTER_OK，     * 然后遍历 16384 个 slot，如果发现有 slot 被有被接管，     * 或者接管某 slot 的 node 是 fail 状态，那么把集群设置为 CLUSTER_FAIL，退出循环     */    new_state = CLUSTER_OK;    if (server.cluster_require_full_coverage) {for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (server.cluster-&gt;slots[j] == NULL ||                server.cluster-&gt;slots[j]-&gt;flags &amp; (CLUSTER_NODE_FAIL))            {                new_state = CLUSTER_FAIL;                break;            }        }    }    {       /* 计算 cluster size，计数的是那些至少负责一个 slot 的 node        * 计算 reachable_masters，计数基于 cluster size，        * 加入筛选条件(不带有 CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL) 标记        */        dictIterator *di;        dictEntry *de;        server.cluster-&gt;size = 0;        di = dictGetSafeIterator(server.cluster-&gt;nodes);        while((de = dictNext(di)) != NULL) {clusterNode *node = dictGetVal(de);            if (nodeIsMaster(node) &amp;&amp; node-&gt;numslots) {                server.cluster-&gt;size++;                if ((node-&gt;flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL)) == 0)                    reachable_masters++;            }        }        dictReleaseIterator(di);    }    {/* 如果 reachable_masters 不到 cluster size 一半(a minority partition)，         * 就将集群标记为 CLUSTER_FAIL         */        int needed_quorum = (server.cluster-&gt;size / 2) + 1;        if (reachable_masters &lt; needed_quorum) {            new_state = CLUSTER_FAIL;            among_minority_time = mstime();}    }    if (new_state != server.cluster-&gt;state) {        mstime_t rejoin_delay = server.cluster_node_timeout;        if (rejoin_delay &gt; CLUSTER_MAX_REJOIN_DELAY)            rejoin_delay = CLUSTER_MAX_REJOIN_DELAY;        if (rejoin_delay &lt; CLUSTER_MIN_REJOIN_DELAY)            rejoin_delay = CLUSTER_MIN_REJOIN_DELAY;        /* 处于 minority partition 的时间没有超过 cluster_node_timeout，         * 那么此次不更新集群状态。         */        if (new_state == CLUSTER_OK &amp;&amp;            nodeIsMaster(myself) &amp;&amp;            mstime() - among_minority_time &lt; rejoin_delay)        {return;}        /* Change the state and log the event. */        serverLog(LL_WARNING,&quot;Cluster state changed: %s&quot;,            new_state == CLUSTER_OK ? &quot;ok&quot; : &quot;fail&quot;);        server.cluster-&gt;state = new_state;    }</code></pre><h2 id="4- 参考">4. 参考</h2><p><i class="fa fa-link" aria-hidden="true"></i> <a href="https://blog.csdn.net/gqtcgq/article/details/51830428" target="_blank" rel="noopener">Redis 源码解析：27 集群 (三) 主从复制、故障转移</a></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 持久化之 AOF 重写</title>
    <link href="/d15eb256.html"/>
    <url>/d15eb256.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>因为 AOF 持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF 文件中的内容会原来越多，文件的体积也会越来越大，若不加以控制，体积过大的 AOF 文件很可能对 Redis 服务器、甚至整个宿主计算机造成影响，并且其体积越大，使用 AOF 文件来进行数据还原所需要的时间就越长。</p></blockquote><a id="more"></a><p>为防止 aofrewrite 过程阻塞服务器，Redis 服务器会 <code>fork</code> 一个子进程执行该过程，且任何时刻只能有一个子进程做这件事。</p><h2 id="server- 相关变量">server 相关变量</h2><p>为了保证 AOF 的连续性，父进程把 aofrewrite 期间的写命令缓存起来，等子进程重写之后再追加到新的 AOF 文件。如果 aofrewrite 期间写命令写入量较大的话，子进程结束后，父进程的追加就涉及到 <strong> 大量的写磁盘操作</strong>，造成服务性能下降。</p><p>Redis 通过在父子进程间建立 pipe，把 aofrewrite 期间的写命令通过 pipe 同步给子进程，这样一来，追加写盘的操作也就转嫁给了子进程。Redis server 中与之相关的变量主要有以下几个，主要三个 pipe。</p><pre><code class="language-c">int aof_pipe_write_data_to_child;int aof_pipe_read_data_from_parent;int aof_pipe_write_ack_to_parent;int aof_pipe_read_ack_from_child;int aof_pipe_write_ack_to_child;int aof_pipe_read_ack_from_parent;int aof_stop_sending_diff; /*If true stop sending accumulated diffs to child process. */sds aof_child_diff;        /* AOF diff accumulator child side. */</code></pre><h2 id="实现原理">实现原理</h2><p>aofrewrite 的入口逻辑在 <code>rewriteAppendOnlyFileBackground</code> 函数。</p><pre><code class="language-c">int rewriteAppendOnlyFileBackground(void) {    ...    if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) return C_ERR;    ...}</code></pre><p>要确保没有后台进程做 aofrewrite 或者 rdb，才会考虑做本次的 aofrewrite。</p><h3 id="pipe- 初始化">pipe 初始化</h3><pre><code class="language-c">int rewriteAppendOnlyFileBackground(void) {   ...   if (aofCreatePipes() != C_OK) return C_ERR;   ...}</code></pre><pre><code class="language-c">int aofCreatePipes(void) {int fds[6] = {-1, -1, -1, -1, -1, -1};    int j;    if (pipe(fds) == -1) goto error; /* parent -&gt; children data. */    if (pipe(fds+2) == -1) goto error; /* children -&gt; parent ack. */    if (pipe(fds+4) == -1) goto error; /* children -&gt; parent ack. */    /* Parent -&gt; children data is non blocking. */    if (anetNonBlock(NULL,fds[0]) != ANET_OK) goto error;    if (anetNonBlock(NULL,fds[1]) != ANET_OK) goto error;    /* 注册读事件处理函数，负责处理子进程要求停止数据传输的消息 */    if (aeCreateFileEvent(server.el, fds[2], AE_READABLE, aofChildPipeReadable, NULL) == AE_ERR) goto error;    server.aof_pipe_write_data_to_child = fds[1];    server.aof_pipe_read_data_from_parent = fds[0];    server.aof_pipe_write_ack_to_parent = fds[3];    server.aof_pipe_read_ack_from_child = fds[2];    server.aof_pipe_write_ack_to_child = fds[5];    server.aof_pipe_read_ack_from_parent = fds[4];    server.aof_stop_sending_diff = 0; /* 是否停止管道传输标记位 */    return C_OK;error:    serverLog(LL_WARNING,&quot;Error opening /setting AOF rewrite IPC pipes: %s&quot;,        strerror(errno));    for (j = 0; j &lt; 6; j++) if(fds[j] != -1) close(fds[j]);    return C_ERR;}</code></pre><p>在 <code>aofCreatePipes</code> 函数中，对 pipe 进行初始化，pipe 各变量的用处从名字也可以看出来，一共有三条 pipe，每条 pipe 一来一回，占用两个 fd。</p><p>pipe 1 用于父进程向子进程发送缓存的新数据。子进程在 aofrewrite 时，会定期从该管道中读取数据并缓存起来，并在最后将缓存的数据写入重写的新 AOF 文件，这两个 fd 都设置为非阻塞式的。</p><p>pipe 2 负责子进程向父进程发送结束信号。父进程监听 <strong>fds[2]</strong> 读事件，回调函数为 <strong>aofChildPipeReadable</strong>。父进程不断地接收客户端命令，但是子进程不可能无休止地等待父进程的数据，因此，子进程在遍历完数据库所有数据之后，从 pipe 1 中执行一段时间的读取操作后，就会向 pipe 2 中发送一个特殊标记 “<strong>!</strong>”，父进程收到子进程的 “<strong>!</strong>” 后，就会置 <strong>server.aof_stop_sending_diff</strong>  为 1，表示不再向父进程发送缓存数据了。</p><p>pipe 3 负责父进程向子进程发送应答信号。父进程收到子进程的 “<strong>!</strong>” 后，会通过该管道也向子进程应答一个 “<strong>!</strong>”，表示已收到了停止信号。</p><p>详细过程后面会细说。</p><h3 id="父进程处理逻辑">父进程处理逻辑</h3><h4 id="rewriteAppendOnlyFileBackground- 函数">rewriteAppendOnlyFileBackground 函数</h4><p>接着上面的逻辑，server  <code>fork</code> 出一个子进程，两个进程分别做各有不同的处理，下面先看父进程的一些主要处理（代码有删减）。</p><pre><code class="language-c">int rewriteAppendOnlyFileBackground(void) {    ...    if ((childpid = fork()) == 0) {... ...} else {        server.aof_rewrite_scheduled = 0;        server.aof_child_pid = childpid;        updateDictResizePolicy();        server.aof_selected_db = -1;        replicationScriptCacheFlush();        return C_OK;    }    ...}</code></pre><p><strong>server.aof_rewrite_scheduled</strong> 置零，防止在 <code>serverCron</code> 函数中重复触发 aofrewrite，这时因为 <code>serverCron</code> 中有如下逻辑，</p><pre><code class="language-c">int rewriteAppendOnlyFileBackground(void) {    ...    if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1 &amp;&amp;        server.aof_rewrite_scheduled)    {rewriteAppendOnlyFileBackground();    }    ...}</code></pre><p>这里，<code>updateDictResizePolicy</code> 函数所做的操作是很重要的，如下，</p><pre><code class="language-c">void updateDictResizePolicy(void) {if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1)        dictEnableResize();    else        dictDisableResize();}</code></pre><p>也就是说，在后台有子进程做 aofrewrite 或 rdb 时，就不要做 dict rehash 了。现在大多数操作系统都采用 <strong> 写时复制（copy-on-write）来优化子进程的使用效率</strong>，所以在子进程存在期间，应该避免不必要的内存写入，否则会引起大量的内存 copy，影响性能。COW 的知识可以参考文档 《<a href="https://juejin.im/post/5bd96bcaf265da396b72f855" target="_blank" rel="noopener">Copy On Write 机制了解一下</a>》。</p><p>另外，<strong>server.aof_selected_db</strong> 置为 -1，是为了在子进程进行数据库扫描时插入 select 命令，以便选择正确的数据库。</p><p>####aofRewriteBufferAppend 函数</p><p>在上一篇博客中说过，在 <code>feedAppendOnlyFile</code> 函数 append 写命令时，如果当前有子进程在做 aofrewrite 时，需要将写命令写到 <strong>server.aof_rewrite_buf_blocks</strong> 中一份。该变量是一个链表，其中每个节点最大 10MB。</p><pre><code class="language-c">void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {    ...    if (server.aof_child_pid != -1)        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));}</code></pre><pre><code class="language-c">void aofRewriteBufferAppend(unsigned char *s, unsigned long len) {    ... ...    /* Install a file event to send data to the rewrite child if there is     * not one already. */    if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) {        aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child,            AE_WRITABLE, aofChildWriteDiffData, NULL);    }}</code></pre><p>为 <strong>server.aof_pipe_write_data_to_child</strong> 注册写事件，回调函数为 <code>aofChildWriteDiffData</code>。</p><pre><code class="language-c">void aofChildWriteDiffData(aeEventLoop *el, int fd, void *privdata, int mask) {    listNode *ln;    aofrwblock *block;    ssize_t nwritten;    UNUSED(el);    UNUSED(fd);    UNUSED(privdata);    UNUSED(mask);    while(1) {ln = listFirst(server.aof_rewrite_buf_blocks);        block = ln ? ln-&gt;value : NULL;        if (server.aof_stop_sending_diff || !block) {            aeDeleteFileEvent(server.el,server.aof_pipe_write_data_to_child,                              AE_WRITABLE);            return;        }        if (block-&gt;used &gt; 0) {            nwritten = write(server.aof_pipe_write_data_to_child,                             block-&gt;buf,block-&gt;used);            if (nwritten &lt;= 0) return;            memmove(block-&gt;buf,block-&gt;buf+nwritten,block-&gt;used-nwritten);            block-&gt;used -= nwritten;        }        if (block-&gt;used == 0) listDelNode(server.aof_rewrite_buf_blocks,ln);    }}</code></pre><p>当子进程告诉父进程不要发数据（<strong>server.aof_stop_sending_diff = 1</strong>）或者 <strong>server.aof_rewrite_buf_blocks</strong> 为空时，删除写事件。</p><p>否则，往 pipe1 中写入数据，然后写入的数据从 <strong>server.aof_rewrite_buf_blocks</strong> 删掉。</p><h3 id="子进程处理逻辑">子进程处理逻辑</h3><pre><code class="language-c">int rewriteAppendOnlyFileBackground(void) {    ...    char tmpfile[256];    closeListeningSockets(0);               /* child 关闭不必要的 socket */    redisSetProcTitle(&quot;redis-aof-rewrite&quot;); /* 修改进程名为 redis-aof-rewrite */    snprintf(tmpfile,256,&quot;temp-rewriteaof-bg-%d.aof&quot;, (int) getpid());    ...}</code></pre><p>首先做一些必要的处理，临时 AOF 文件名为 <strong>temp-rewriteaof-bg-%d.aof</strong>。</p><p>然后进入正式的处理函数 <code>rewriteAppendOnlyFile</code>，以下贴上主要代码（有删减）。</p><pre><code class="language-c">int rewriteAppendOnlyFile(char *filename) {    ...    snprintf(tmpfile,256,&quot;temp-rewriteaof-%d.aof&quot;, (int) getpid());    fp = fopen(tmpfile,&quot;w&quot;);    server.aof_child_diff = sdsempty(); /* 初始化 aof_child_diff */    ...}</code></pre><p><strong>aof_child_diff</strong>  变量中存放在 aofwrite 期间，子进程接收到父进程通过 pipe 传过来的缓存数据。</p><p>然后就是扫描数据库的操作。</p><pre><code class="language-c">int rewriteAppendOnlyFile(char *filename) {    ...    rio aof;    for (j = 0; j &lt; server.dbnum; j++) {        redisDb *db = server.db+j;        dict *d = db-&gt;dict;        if (dictSize(d) == 0) continue; // skip empty database        di = dictGetSafeIterator(d);        while((de = dictNext(di)) != NULL) {            ... ...            if (aof.processed_bytes &gt; processed+1024*10) { // 10K                processed = aof.processed_bytes;                aofReadDiffFromParent();}        }        dictReleaseIterator(di);        di = NULL;    }    if (fflush(fp) == EOF) goto werr;    if (fsync(fileno(fp)) == -1) goto werr;    ...}</code></pre><p>以上逻辑里，子进程会挨个 db 扫描每一个 key，根据 key 的类型使用不同的函数进行数据重写，带过期时间的数据，都需要 append 一个 <strong>PEXPIREAT</strong> 命令。</p><p>有一点需要注意，前面说到利用 pipe 优化 aofwrite，可以看到上面的逻辑，每遍历一个 db，如果 rio 写入的数据量超过了 <strong>10K</strong>，那么就通过 pipe 从父进程读一次数据，将数据累加到 <strong>server.aof_child_diff</strong>。</p><pre><code class="language-c">ssize_t aofReadDiffFromParent(void) {char buf[65536]; /* Default pipe buffer size on most Linux systems. */    ssize_t nread, total = 0;    while ((nread = read(server.aof_pipe_read_data_from_parent,buf,sizeof(buf))) &gt; 0) {server.aof_child_diff = sdscatlen(server.aof_child_diff,buf,nread);        total += nread;    }    return total;}</code></pre><p>因为，有客户端可能不断有流量打到父进程，子进程不可能一直等父进程，所以要有一个结束的时刻， Redis 中做了如下决定。</p><pre><code class="language-c">int rewriteAppendOnlyFile(char *filename) {    ...    int nodata = 0;    mstime_t start = mstime();    while(mstime()-start &lt; 1000 &amp;&amp; nodata &lt; 20) {/* 在 1ms 之内，查看从父进程读数据的 fd 是否变成可读的，若不可读则 aeWait()函数返回 0 */        if (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, 1) &lt;= 0)        {            nodata++;            continue;        }        // 当管道的读端可读时，清零 nodata        nodata = 0;        aofReadDiffFromParent();}    ...}</code></pre><p>1ms 超时等待父进程从 pipe 传来数据，如果在 1ms 内有 20 次父进程没传来数据，那么就放弃 <strong>ReadDiffFromParent</strong>。由于 <strong>server.aof_pipe_read_data_from_parent</strong> 在初始化时设置为非阻塞，因此 <code>aeWait</code> 调用返回很快。</p><pre><code class="language-c">if (write(server.aof_pipe_write_ack_to_parent,&quot;!&quot;,1) != 1) goto werr;</code></pre><p>接着通过 pipe2 告诉父进程（发特殊符号 ！）不要再发来缓存数据了。</p><p>还记得前面初始化时，父进程一直在监听 <strong>server.aof_pipe_read_ack_from_child</strong> 的可读事件吧？当收到 “<strong>!</strong>” 后，父进程调用处理函数 <code>aofChildPipeReadable</code>。</p><pre><code class="language-c">void aofChildPipeReadable(aeEventLoop *el, int fd, void *privdata, int mask) {    char byte;    if (read(fd,&amp;byte,1) == 1 &amp;&amp; byte == '!') {serverLog(LL_NOTICE,&quot;AOF rewrite child asks to stop sending diffs.&quot;);        server.aof_stop_sending_diff = 1;        if (write(server.aof_pipe_write_ack_to_child,&quot;!&quot;,1) != 1) {            serverLog(LL_WARNING,&quot;Can't send ACK to AOF child: %s&quot;,                strerror(errno));        }    }    /* Remove the handler since this can be called only one time during a     * rewrite. */    aeDeleteFileEvent(server.el,server.aof_pipe_read_ack_from_child,AE_READABLE);}</code></pre><p>可以看到  <code>server.aof_stop_sending_diff</code> 置为 1，表示不再给子进程发送缓存数据，接着删除 <strong>server.aof_pipe_read_ack_from_child</strong> 上可读事件，给子进程回复一个 “<strong>!</strong>”。</p><p>现在回来看子进程的行为。</p><pre><code class="language-c">int rewriteAppendOnlyFile(char *filename) {    ...    if (syncRead(server.aof_pipe_read_ack_from_parent,&amp;byte,1,5000) != 1 || byte != '!')        goto werr;    ...}</code></pre><p>子进程阻塞 5s 等待父进程发来确认标记 <strong>“!”</strong>，之后就开始做自己的收尾工作，如下：</p><pre><code class="language-c">int rewriteAppendOnlyFile(char *filename) {    ...    aofReadDiffFromParent(); /* 最后一次从父进程累计写入的缓冲区的差异 */    /* 将子进程 aof_child_diff 中保存的差异数据写到 AOF 文件中 */    if (rioWrite(&amp;aof,server.aof_child_diff,sdslen(server.aof_child_diff)) == 0)        goto werr;    /* Make sure data will not remain on the OS's output buffers */    if (fflush(fp) == EOF) goto werr;    if (fsync(fileno(fp)) == -1) goto werr;    if (fclose(fp) == EOF) goto werr;    /* 原子性修改临时文件的名字为 temp-rewriteaof-bg-&lt;pid&gt;.aof */    if (rename(tmpfile,filename) == -1) {unlink(tmpfile);        return C_ERR;    }    ...}</code></pre><p>最后再读取一次 pipe 中的数据，将子进程进行 aofrewrite 期间，<strong>aof_child_diff</strong> 从父进程累积的数据刷盘，最后进行 <code>rename</code> 系统调用。</p><p>经过以上的逻辑处理，server 交给子进程的 aofrewrite 工作就完成了，最终得到一个文件 <strong>temp-rewriteaof-bg-<pid>.aof</strong>，成功返回 0，否则返回 1。</p><h3 id="父进程的收尾工作">父进程的收尾工作</h3><p>子进程在执行完 aofrewrite 后退出，父进程 <code>wait3</code> 到子进程的退出状态后，进行 aofrewrite 的收尾工作。在 <code>serverCron</code> 函数里，有如下逻辑，</p><pre><code class="language-c">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {    ...    if ((pid = wait3(&amp;statloc,WNOHANG,NULL)) != 0) { /* wait3 等待所有子进程 */        int exitcode = WEXITSTATUS(statloc);        int bysignal = 0;        if (WIFSIGNALED(statloc)) bysignal = WTERMSIG(statloc);        if (pid == -1) {serverLog(LL_WARNING,&quot;wait3() returned an error: %s. &quot;                      &quot;rdb_child_pid = %d, aof_child_pid = %d&quot;,                      strerror(errno),                      (int) server.rdb_child_pid,                      (int) server.aof_child_pid);        } else if (pid == server.rdb_child_pid) {backgroundSaveDoneHandler(exitcode,bysignal);        } else if (pid == server.aof_child_pid) { /* aof 子进程结束 */            backgroundRewriteDoneHandler(exitcode,bysignal);        } else {if (!ldbRemoveChild(pid)) {                serverLog(LL_WARNING,                          &quot;Warning, detected child with unmatched pid: %ld&quot;,                          (long)pid);            }        }        updateDictResizePolicy(); /* 更新 dict resize 为可用状态 */}    ...}</code></pre><p><code>wait3</code> 函数表示父进程等待所有子进程的返回值， <strong>WNOHANG</strong> 选项表示没有子进程 exit 时立即返回，man 中对该选项有如下说明， ”<strong>WNOHANG     return immediately if no child has exited</strong>“。</p><p>可以看到如果等到 aofwrite 的子进程 exit，那么使用 <code>backgroundRewriteDoneHandler</code> 函数进行处理，主要如下（代码有删减），</p><pre><code class="language-c">void backgroundRewriteDoneHandler(int exitcode, int bysignal) {    ...    snprintf(tmpfile,256,&quot;temp-rewriteaof-bg-%d.aof&quot;, (int)server.aof_child_pid);    newfd = open(tmpfile,O_WRONLY|O_APPEND);    if (aofRewriteBufferWrite(newfd) == -1) {close(newfd);        goto cleanup;    }    ...}</code></pre><p>打开子进程生成的临时文件 <strong>temp-rewriteaof-bg-<pid>.aof</strong>，调用 <code>aofRewriteBufferWrite</code>，将服务器缓存的剩下的新数据写入该临时文件中，这样该 AOF 临时文件就完全与当前数据库状态一致了。</p><p>那么，下面还有两件事要做，一是将临时 AOF 文件改名，二是切换 fd。</p><pre><code class="language-c">void backgroundRewriteDoneHandler(int exitcode, int bysignal) {    ...    if (server.aof_fd == -1) {        /* AOF disabled */        oldfd = open(server.aof_filename,O_RDONLY|O_NONBLOCK);    } else {        /* AOF enabled */        oldfd = -1; /* We'll set this to the current AOF filedes later. */    }    if (rename(tmpfile,server.aof_filename) == -1) {close(newfd);        if (oldfd != -1) close(oldfd);        goto cleanup;    }    if (server.aof_fd == -1) {        /* AOF disabled, we don't need to set the AOF file descriptor         * to this new file, so we can close it. */        close(newfd);    } else {        /* AOF enabled, replace the old fd with the new one. */        oldfd = server.aof_fd;        server.aof_fd = newfd;        if (server.aof_fsync == AOF_FSYNC_ALWAYS)            aof_fsync(newfd);        else if (server.aof_fsync == AOF_FSYNC_EVERYSEC)            aof_background_fsync(newfd);        server.aof_selected_db = -1; /* Make sure SELECT is re-issued */        aofUpdateCurrentSize();        server.aof_rewrite_base_size = server.aof_current_size;        /* Clear regular AOF buffer since its contents was just written to         * the new AOF from the background rewrite buffer. */        sdsfree(server.aof_buf);        server.aof_buf = sdsempty();}    ...  ...    /* Asynchronously close the overwritten AOF. */    if (oldfd != -1) bioCreateBackgroundJob(BIO_CLOSE_FILE,(void*)(long)oldfd,NULL,NULL);    ...}</code></pre><p>如上，首先将临时 AOF 文件改名，然后就是 oldfd 和 newfd 的处理了，分 <strong> 两种情况</strong>：</p><p>当 AOF 功能关闭时，打开原来的 AOF 文件，获得 oldfd，这里并不关心该操作是否是成功的，如果失败了，那么 oldfd 值为 -1，<code>close(newfd)</code>。</p><p>当 AOF 功能开启时，oldfd 直接置为 -1，将 <strong>aof_fd</strong> 切换成 newfd，根据不同的数据刷盘策略进行 AOF 刷盘，更新相应的参数。</p><p>然后是关闭 oldfd 的逻辑，由于 oldfd 可能是对旧 AOF 文件的最后一个引用，直接 <code>close</code> 可能会阻塞 server，因此创建后台任务去关闭文件。</p><p>最后进行清理工作，如下，</p><pre><code class="language-c">void backgroundRewriteDoneHandler(int exitcode, int bysignal) {    ...    cleanup:        aofClosePipes();        aofRewriteBufferReset();        aofRemoveTempFile(server.aof_child_pid);        server.aof_child_pid = -1;        server.aof_rewrite_time_last = time(NULL)-server.aof_rewrite_time_start;        server.aof_rewrite_time_start = -1;        /* Schedule a new rewrite if we are waiting for it to switch the AOF ON. */        if (server.aof_state == AOF_WAIT_REWRITE)            server.aof_rewrite_scheduled = 1;    ...}</code></pre><p>以上， 父进程就完成了收尾工作，写命令就 <code>write</code> 到 newfd 了。</p><h3 id="时序图">时序图</h3><p>可以将以上父子进程的交互整理出时序图如下，</p><p><img src="http://ww1.sinaimg.cn/large/71ca8e3cly1fznp1jin66j20kk0jh77k.jpg" srcset="/img/loading.gif" alt=""></p><p>上图参考 <a href="http://mysql.taobao.org/monthly/2018/12/06/" target="_blank" rel="noopener">Redis · 原理介绍 · 利用管道优化 aofrewrite</a></p><h2 id="何时重写">何时重写</h2><p>有两个时刻可以触发 AOF 重写。</p><p>【1】手动执行 <code>BGREWRITEAOF</code> 命令。</p><p>【2】自动执行，在 <code>serverCron</code> 函数中根据一定逻辑进行判定。</p><pre><code class="language-c">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {    ...          /* Trigger an AOF rewrite if needed */    if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1 &amp;&amp;        server.aof_rewrite_perc &amp;&amp;        server.aof_current_size &gt; server.aof_rewrite_min_size) /* 默认 64M */    {        long long base = server.aof_rewrite_base_size ? server.aof_rewrite_base_size : 1;        long long growth = (server.aof_current_size*100/base) - 100;        if (growth &gt;= server.aof_rewrite_perc) {rewriteAppendOnlyFileBackground();        }     }}</code></pre><p>也就是说 AOF 文件大小超过了 <strong>server.aof_rewrite_min_size</strong>，并且增长率大于 <strong>server.aof_rewrite_perc</strong> 时就会触发，增长率计算的基数 <strong>server.aof_rewrite_base_size</strong> 是上次 aofrewrite 结束后 AOF 文件的大小。</p><h2 id="附录">附录</h2><p>几个解释。</p><blockquote><p><strong>阻塞模式 </strong> 下，进程或是线程执行到这些函数时必须等待某个事件的发生，如果事件没有发生，进程或线程就被阻塞(死等在被阻塞的地方)，函数不会立即返回。</p><p><strong>非阻塞 non-block 模式 </strong> 下，进程或线程执行此函数时不必非要等待事件的发生，一旦执行肯定返回，以返回值的不同来反映函数的执行情况，如果事件发生则与阻塞方式相同，若事件没有发生则返回一个代码来告知事件未发生，而进程或线程继续执行，所以非阻塞模式效率较高。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 持久化之 AOF</title>
    <link href="/fd3e9e30.html"/>
    <url>/fd3e9e30.html</url>
    
    <content type="html"><![CDATA[<p>除了 RDB 持久化功能之外，Redis 还提供了 AOF（Append Only File）持久化功能。与 RDB 持久化通过保存数据库中的键值对来记录数据库状态不同，AOF 持久化是通过保存 Redis 服务器所执行的写命令来记录数据库状态的。</p><a id="more"></a><h2 id="简介">简介</h2><p>AOF 文件中记录了 Redis 服务器所执行的写命令，以此来保存数据库的状态。AOF 文件本质上是一个 redo log，通过它可以恢复数据库状态。</p><p>随着执行命令的增多，AOF 文件的大小会不断增大，这会导致几个问题，比如，磁盘占用增加，重启加载过慢等。因此， Redis 提供了 AOF 重写机制来控制 AOF 文件大小，下面会细说。</p><p>AOF 文件中写入的所有命令以 Redis 的命令请求协议格式去保存，即 <a href="http://redisdoc.com/topic/protocol.html" target="_blank" rel="noopener">RESP</a> 格式。</p><p>有两种方式可以实现 AOF 功能的开关，如下，</p><ul><li>在 redis 配置文件 <strong>redis.conf</strong> 中有配置项 appendonly， yes 打开 AOF 功能，no 关闭 AOF 功能。</li><li>使用客户端命令<code>config set appendonly yes/no</code> 。</li></ul><h2 id="server- 相关变量">server 相关变量</h2><p>与 AOF 相关的 server 成员变量很多，这里只选择几个进行简要说明。先看后面的章节，之后再回头看本章节，也是个不错的主意。</p><pre><code class="language-c">int aof_state;                  /* AOF_(ON|OFF|WAIT_REWRITE) */int aof_fsync;                  /* Kind of fsync() policy */char *aof_filename;             /* Name of the AOF file */int aof_no_fsync_on_rewrite;    /* Don't fsync if a rewrite is in prog. */int aof_rewrite_perc;           /* Rewrite AOF if % growth is &gt; M and... */off_t aof_rewrite_min_size;     /* the AOF file is at least N bytes. */off_t aof_rewrite_base_size;    /* AOF size on latest startup or rewrite. */off_t aof_current_size;         /* AOF current size. */int aof_rewrite_scheduled;      /* Rewrite once BGSAVE terminates. */pid_t aof_child_pid;            /* PID if rewriting process */list *aof_rewrite_buf_blocks;   /* Hold changes during an AOF rewrite. */sds aof_buf;                   /* AOF buffer, written before entering the event loop */int aof_fd;                     /* File descriptor of currently selected AOF file */int aof_selected_db;            /* Currently selected DB in AOF */time_t aof_flush_postponed_start; /* UNIX time of postponed AOF flush */time_t aof_last_fsync;            /* UNIX time of last fsync() */time_t aof_rewrite_time_last;     /* Time used by last AOF rewrite run. */time_t aof_rewrite_time_start;    /* Current AOF rewrite start time. */int aof_lastbgrewrite_status;     /* C_OK or C_ERR */unsigned long aof_delayed_fsync;  /* delayed AOF fsync() counter */int aof_rewrite_incremental_fsync;/* fsync incrementally while rewriting? */int aof_last_write_status;        /* C_OK or C_ERR */int aof_last_write_errno;         /* Valid if aof_last_write_status is ERR */int aof_load_truncated;           /* Don't stop on unexpected AOF EOF. */</code></pre><h3 id="aof-fsync">aof_fsync</h3><p>表示 AOF 刷盘策略，后面会细说</p><h3 id="aof-child-pid">aof_child_pid</h3><p>由于 aofrewrite 是个耗时操作，因此会 fork 一个子进程去做这件事， aof_child_pid 就标识了子进程的 pid。</p><h3 id="aof-buf">aof_buf</h3><p>该变量保存着所有等待写入到 AOF 文件的协议文本。</p><h3 id="aof-rewrite-buf-blocks">aof_rewrite_buf_blocks</h3><p>该变量用来保存 aofrewrite 期间，server 处理过的需要写入 AOF 文件的协议文本。这个变量采用 list 结构，是考虑到分配到一个非常大的空间并不总是可能的，也可能产生大量的复制工作。</p><h3 id="aof-rewrite-scheduled">aof_rewrite_scheduled</h3><p>可取值有 0 和 1。</p><p>取 1 时，表示此时有子进程正在做 aofrewrite 操作，本次任务后延，等到 <code>serverCron</code> 执行时，合适的情况再执行。或者是执行了 <code>config set appendonly yes</code>, 想把 AOF 功能打开，此时执行的 aofrewrite 失败了，aof_state 仍然处于 <strong>AOF_WAIT_REWRITE</strong> 状态，此时 <strong>aof_rewrite_scheduled</strong> 也会置为 1，等下次再执行 aofrewrite。</p><h3 id="aof-state">aof_state</h3><p>表示 AOF 功能现在的状态，可取值如下，</p><pre><code class="language-c">#define AOF_OFF 0             /* AOF is off */#define AOF_ON 1              /* AOF is on */#define AOF_WAIT_REWRITE 2    /* AOF waits rewrite to start appending */</code></pre><p><strong>AOF_OFF</strong> 表示 AOF 功能处于关闭状态，开关在上一节已经说过，默认 AOF 功能是关闭的。AOF 功能从 off switch 到 on 后，<strong>aof_state</strong> 会从 <strong>AOF_OFF</strong>  变为 <strong>AOF_WAIT_REWRITE</strong>，<code>startAppendOnly</code> 函数完成该逻辑。在 aofrewrite 一次之后，该变量才会从 <strong>AOF_WAIT_REWRITE</strong>  变为 <strong>AOF_ON</strong>。</p><p>可以看到从 ON 切换到 OFF 时，要经历一个中间状态 <strong>AOF_WAIT_REWRITE</strong>，那为何要这么设计呢？再来分析一下 <code>startAppendOnly</code> 函数的逻辑（代码去掉了打印日志的部分）。</p><pre><code class="language-c">server.aof_fd = open(server.aof_filename,O_WRONLY|O_APPEND|O_CREAT,0644);serverAssert(server.aof_state == AOF_OFF);if (server.aof_fd == -1) {char *cwdp = getcwd(cwd,MAXPATHLEN);    return C_ERR;}if (server.rdb_child_pid != -1) {server.aof_rewrite_scheduled = 1;} else if (rewriteAppendOnlyFileBackground() == C_ERR) {close(server.aof_fd);    return C_ERR;}server.aof_state = AOF_WAIT_REWRITE;</code></pre><p>【1】打开 aof 文件，默认名为 appendonly.aof，没有的话就新建空文件，失败则返回。</p><p>【2】切换后，需要做一次 aofrewrite，将 server 中现有的数据转换成协议文本，写到 AOF 文件。但是，这里要 <strong> 注意</strong>，如果此时有子进程在做 bgrdb，那么此次 aofrewrite 需要任务延缓，即 <strong>aof_rewrite_scheduled</strong> 置为 1。</p><p>【3】将 <strong>aof_state</strong> 置为 <strong>AOF_WAIT_REWRITE</strong> 状态。</p><p>而做完第一次 aofrewrite 后，<strong>AOF_WAIT_REWRITE</strong> 转换成 <strong>AOF_ON</strong>，如下，</p><pre><code class="language-c">void backgroundRewriteDoneHandler(int exitcode, int bysignal) {    ...    if (server.aof_state == AOF_WAIT_REWRITE)        server.aof_state = AOF_ON;    ...}</code></pre><p>仔细分析源码发现，在 AOF 持久化的命令追加阶段（后面章节细讲），有如下逻辑,</p><pre><code class="language-c">void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {    ...    if (server.aof_state == AOF_ON)        server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));    if (server.aof_child_pid != -1)        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));    ...}</code></pre><p>很明显，刚开启 AOF 时， <strong>aof_state</strong> 为 <strong>AOF_WAIT_REWRITE</strong> ，处理好的协议文本 buf 无法写入 <strong>aof_buf</strong> 变量 ，但必须写入 <strong>aof_rewrite_buf_blocks</strong>  变量（数据在 aofrewrite 的最后阶段会被写进 AOF 文件）。</p><p>这里是否将命令 append 到 <strong>aof_state</strong> 的判断至关重要，如果修改条件为 <code>server.aof_state != AOF_OFF</code> ，<strong>考虑如下情况</strong>。</p><p>AOF 状态刚打开，尚未完成第一次 aofrewrite，也即，一边 Child 进程数据库中现有数据还未写进 AOF 文件，另一边 Parent 进程仍然持续处理 client 请求，于是，Parent 进程在指定的数据刷盘策略下，将 <strong>aof_buf</strong>  刷盘。如果这时宕机了，当 server 重启后，加载 AOF 文件，在内存中塞入数据，实际上对于用户来说，这部分数据算是脏数据了，因为 AOF 并没有成功打开，未开启 AOF 状态时，数据都在内存中，宕机后，数据会全部丢掉。增加这个中间状态就是为了应对这种情况。所以， <strong>AOF_WAIT_REWRITE</strong> 状态存在的时间范围起始于 <code>startAppendOnly</code> ，到完成第一次 aofrewrite 后切成 <strong>AOF_ON</strong> 。aofrewrite 后再发生宕机，丢失的数据就少多了。</p><p><strong>这只是我个人的理解，不一定正确，欢迎大家斧正。</strong></p><p>另外，如果开启了 AOF，在 redis 启动 加载 AOF 文件时，<strong>aof_state</strong> 也会暂时设置成 <strong>AOF_OFF</strong>，加载完毕之后设置为 <strong>AOF_ON</strong>。</p><h3 id="aof-pipe">aof_pipe_*</h3><p>为了提高 aofrewrite 效率，Redis 通过在父子进程间建立管道，把 aofrewrite 期间的写命令通过管道同步给子进程，追加写盘的操作也就转交给了子进程。aof_pipe_* 变量就是这部分会用到的管道。</p><h2 id="AOF- 持久化">AOF 持久化</h2><h3 id="命令追加">命令追加</h3><p>AOF 功能开启后，每次导致数据库状态发生变化的命令都会经过 <strong> 函数</strong> <code>feedAppendOnlyFile</code> 累积到 <strong>aof_buf</strong> 变量中。如果后台有正在执行的 aofrewrite 任务，还会写一份数据到 <strong>aof_rewrite_buf_blocks</strong> 变量中。</p><h4 id="feedAppendOnlyFile- 函数">feedAppendOnlyFile 函数</h4><p>在该函数中，首先要将数据库切换到当前数据库（ <strong>aof_selected_db</strong> 更新），在 buf 中插入一条 <strong>SELECT</strong> 命令。</p><pre><code class="language-c">sds buf = sdsempty();if (dictid != server.aof_selected_db) {char seldb[64];    snprintf(seldb,sizeof(seldb),&quot;%d&quot;,dictid);    buf = sdscatprintf(buf,&quot;*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n&quot;, (unsigned        long)strlen(seldb),seldb);    server.aof_selected_db = dictid;}</code></pre><p>然后在对需要加入 buf 的命令进行分类处理。</p><p>【1】带有过期时间的命令，调用函数 <code>catAppendOnlyExpireAtCommand</code> 进行协议文本 buf 组装。<strong>EXPIRE</strong>/<strong>PEXPIRE</strong>/<strong>EXPIREAT</strong> 这三个命令直接调用该函数，而 <strong>SETEX</strong>/<strong>PSETEX</strong> 这两个命令需要在调用之前加入一个 <strong>SET</strong> 命令。即，</p><pre><code class="language-c">tmpargv[0] = createStringObject(&quot;SET&quot;,3);tmpargv[1] = argv[1];tmpargv[2] = argv[3];buf = catAppendOnlyGenericCommand(buf,3,tmpargv);decrRefCount(tmpargv[0]);buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);</code></pre><p>【2】普通命令，直接调用函数 <code>catAppendOnlyGenericCommand</code> 进行协议文本 buf 组装。</p><h4 id="catAppendOnlyExpireAtCommand- 函数">catAppendOnlyExpireAtCommand 函数</h4><p>该函数其实就是将所有与过期时间相关的命令转成 <strong>PEXPIREAT</strong> 命令，细化到毫秒。最后调用普通命令组装 buf 函数 <code>catAppendOnlyGenericCommand</code>。</p><pre><code class="language-c">// 构建 PEXPIREAT 命令argv[0] = createStringObject(&quot;PEXPIREAT&quot;,9);argv[1] = key;argv[2] = createStringObjectFromLongLong(when);// 调用 aof 公共函数buf = catAppendOnlyGenericCommand(buf, 3, argv);</code></pre><h4 id="catAppendOnlyGenericCommand- 函数">catAppendOnlyGenericCommand 函数</h4><p>该函数用来把 redis 命令转换成 RESP 协议文本。</p><pre><code class="language-c">sds catAppendOnlyGenericCommand(sds dst, int argc, robj **argv) {char buf[32];    int len, j;    robj *o;    // 比如 *3\r\n    buf[0] = '*';    len = 1+ll2string(buf+1,sizeof(buf)-1,argc);    buf[len++] = '\r';    buf[len++] = '\n';    dst = sdscatlen(dst,buf,len);    for (j = 0; j &lt; argc; j++) {o = getDecodedObject(argv[j]);        buf[0] = '$';        len = 1+ll2string(buf+1,sizeof(buf)-1,sdslen(o-&gt;ptr));        buf[len++] = '\r';        buf[len++] = '\n';        dst = sdscatlen(dst,buf,len);        dst = sdscatlen(dst,o-&gt;ptr,sdslen(o-&gt;ptr));        dst = sdscatlen(dst,&quot;\r\n&quot;,2);        decrRefCount(o);    }    return dst;}</code></pre><p>可以看到，定义了一个 buf 数组，反复使用，通过 len 精确控制 append 到 dst 后的长度。</p><h4 id="aofRewriteBufferAppend- 函数">aofRewriteBufferAppend 函数</h4><p><strong>aof_rewrite_buf_blocks</strong> 变量是一个 list 结构，其中每一个元素都是一个大小为 10M 的 block</p><pre><code class="language-c">#define AOF_RW_BUF_BLOCK_SIZE (1024*1024*10)    /* 10 MB per block */typedef struct aofrwblock {    unsigned long used, free;    char buf[AOF_RW_BUF_BLOCK_SIZE];} aofrwblock;</code></pre><p>这个函数做了两件事情。</p><p>一是，将 <code>catAppendOnlyGenericCommand</code> 获得的协议文本 buf 存到 <strong>aof_rewrite_buf_blocks</strong> 变量，首先拿出来 list 最后一个 block，如果装不下，那先把最后一个 block 填满，剩下的再申请内存。</p><pre><code class="language-c">listNode *ln = listLast(server.aof_rewrite_buf_blocks); // 指向最后一个缓存块aofrwblock *block = ln ? ln-&gt;value : NULL;while(len) {if (block) { // 如果已经有至少一个缓存块，那么尝试将内容追加到这个缓存块里面        unsigned long thislen = (block-&gt;free &lt; len) ? block-&gt;free : len;        if (thislen) {  /* The current block is not already full. */            memcpy(block-&gt;buf+block-&gt;used, s, thislen);            block-&gt;used += thislen;            block-&gt;free -= thislen;            s += thislen;            len -= thislen;        }    }    if (len) {  // 最后一个缓存块没有放得下本次 data，那再申请一个 block        int numblocks;        block = zmalloc(sizeof(*block));        block-&gt;free = AOF_RW_BUF_BLOCK_SIZE;        block-&gt;used = 0;        listAddNodeTail(server.aof_rewrite_buf_blocks,block);        ... ...    }}</code></pre><p>二是，给 <strong>aof_pipe_write_data_to_child</strong> 这个 fd 注册写事件，回调函数为 <code>aofChildWriteDiffData</code>。</p><pre><code class="language-c">/* Install a file event to send data to the rewrite child if there is     * not one already. */if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) {    aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child,                      AE_WRITABLE, aofChildWriteDiffData, NULL);}</code></pre><p>这个属于 aof 重写的逻辑，后面章节会细说，这里先留个心。</p><h4 id="何时进行命令追加">何时进行命令追加</h4><p>也就是说，什么时候会调用<code>feedAppendOnlyFile</code> 呢？有以下两个时机。</p><h5 id="propagate- 函数">propagate 函数</h5><p>大家都知道，Redis 中命令执行的流程，即 <code>processCommand</code> -&gt; <code>call</code> 。在 <code>call</code> 函数中会把某些命令写入 AOF 文件。如何判断某个命令是否需要写入 AOF 呢？</p><p>在 server 结构体中维持了一个 <strong>dirty</strong> 计数器，<strong>dirty</strong> 记录的是服务器状态进行了多少次修改，每次做完 save/bgsave 执行完成后，会将 <strong>dirty</strong> 清 0，而使得服务器状态修改的命令一般都需要写入 AOF 文件和主从同步（排除某些特殊情况）。</p><pre><code class="language-c">dirty = server.dirty;c-&gt;cmd-&gt;proc(c);dirty = server.dirty-dirty;...if (propagate_flags != PROPAGATE_NONE)    propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);</code></pre><p>在 <code>propagate</code> 函数中就会调用到 <code>feedAppendOnlyFile</code>。</p><pre><code class="language-c">void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc,               int flags){if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF)        feedAppendOnlyFile(cmd,dbid,argv,argc);    if (flags &amp; PROPAGATE_REPL)        replicationFeedSlaves(server.slaves,dbid,argv,argc);}</code></pre><h5 id="propagateExpire- 函数">propagateExpire 函数</h5><p>当内存中带有过期时间的 key 过期时，会向 AOF 写入 <strong>del</strong> 命令。</p><pre><code class="language-c">void propagateExpire(redisDb *db, robj *key) {    ...    if (server.aof_state != AOF_OFF)        feedAppendOnlyFile(server.delCommand,db-&gt;id,argv,2);    replicationFeedSlaves(server.slaves,db-&gt;id,argv,2);    ...}</code></pre><p><code>propagateExpire</code> 函数在一些检查 key 是否过期时会调用。</p><h3 id="文件的写入与同步">文件的写入与同步</h3><p>上一步中，将需要写入 AOF 文件的数据先写到了 <strong>aof_buf</strong>  变量中，那么，接下来说一下如何将 <strong>aof_buf</strong> 的内容写进 AOF 文件。</p><h4 id="同步策略">同步策略</h4><blockquote><p>为了提高文件的写入效率，在现代操作系统中，当用户调用 <code>write</code>  函数试，将一些数据写入到文件的时候，操作系统通常会将写入的数据保存在一个内存缓冲区里，等到缓冲区的空间被填满，或者超过了指定的时限后，才真正地将缓冲区中的数据写入磁盘。</p><p>这种做法虽然提高了效率，但也为写入数据带来了安全问题，因为如果计算机宕机，那么保存在内存缓冲区里面的写入数据将会丢失。</p><p>为此，系统提供了  <code>fsync</code> 和 <code>fdatasync</code> 两个同步函数，它们可以强制让操作系统立即将缓存区中的数据写入到硬盘里面，从而确保写入数据的安全性。</p></blockquote><p>要知道，这两个系统调用函数都是阻塞式的，针对如何协调文件写入与同步的关系，该版本 Redis 支持 3 种同步策略，可在配置文件中使用 <strong>appendfsync</strong> 项进行配置，有如下取值，</p><ul><li><p>always。每次有新命令追加到  AOF 文件 时就执行一次同步，, 安全性最高，但是性能影响最大。</p></li><li><p>everysec。每秒执行一次同步。宕机只会丢失一秒钟的命令。这算是一个折中方案。</p></li><li><p>no。将数据同步操作完全交由操作系统处理，性能最好，但是数据可靠性最差。宕机将丢失同步 AOF 文件后的所有写命令。</p></li></ul><p>在 Redis 源码中， 当程序运行在 Linux 系统上时，执行的是 <code>fdatasync</code> 函数，而在其他系统上，则会执行 <code>fsync</code> 函数，即，</p><pre><code class="language-c">#ifdef __linux__#define aof_fsync fdatasync#else#define aof_fsync fsync#endif</code></pre><p><strong>注</strong>：以下叙述均以 <code>fsync</code> 代称。</p><h4 id="如何写入文件">如何写入文件</h4><p>写入文件的逻辑在 <code>flushAppendOnlyFile</code> 函数中实现。下面分两部分来看主要代码。</p><h5 id="文件写入 -，write- 系统调用">文件写入 **，<code>write</code> ** 系统调用</h5><pre><code class="language-c">...// aof 缓存区内没有数据需要写入 disk，无需处理if (sdslen(server.aof_buf) == 0) return;// 如果 sync policy 设置成 everysec，// sync_in_progress 表示是否有 fsync 任务在后台if (server.aof_fsync == AOF_FSYNC_EVERYSEC)    sync_in_progress = bioPendingJobsOfType(BIO_AOF_FSYNC) != 0;// force=0(非强制写入)时，如果后台有 fsync 任务，推迟此次写入，但推迟时间不超过 2sif (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) {if (sync_in_progress) {if (server.aof_flush_postponed_start == 0) { // 首次推迟 write，一次推迟 2s            server.aof_flush_postponed_start = server.unixtime;            return;        } else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) {return;}        // 否则，通过，继续写，因为我们不能等待超过 2s        server.aof_delayed_fsync++;        serverLog(LL_NOTICE,&quot;Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.&quot;);    }}...// 将 aof 缓冲区的内容写到系统缓存区nwritten = write(server.aof_fd, server.aof_buf, sdslen(server.aof_buf));...// 执行了 write 操作，所以要清零延迟 flush 的时间server.aof_flush_postponed_start = 0;</code></pre><p>首先会判断 <strong>aof_buf</strong> 是否为空，如果是，那么不需要执行下面的逻辑，直接返回。</p><p>如果同步策略为 everysec，那么需要查看是否有  <strong>fsync</strong> 任务在后台，调用  <strong>fsync</strong> 使用的是 Redis 中 bio ，如果对这个还不了解，可以参考我之前的文章  《 <a href="http://tech-happen.site/de55b491.html" target="_blank" rel="noopener">Redis Bio 详解</a> 》。为什么要做这个判断呢？</p><blockquote><p>当 <code>fsync</code> 和 <code>write</code> 同一个 fd 时，<code>write</code> 必然阻塞。 当系统 IO 非常繁忙时， <code>fsync</code>() 可能会阻塞， 即使系统 IO 不繁忙， <code>fsync</code> 也会因为数据量大而慢。</p></blockquote><p>因此对于 everysec 策略，需要尽量保证 <code>fsync</code> 和 <code>write</code> 不同时操作同一个 fd。no 策略完全把 <code>fsync</code> 交给了操作系统，操作系统什么时候  <code>fsync</code> ，无从得知。always 策略则是每次都要主从调用 <code>fsync</code>，也没必要做判断。因此，这里的判断，只针对  everysec 策略有效。</p><p>对于 everysec 策略，如果有  <code>fsync</code>  在执行，那么本次  <code>write</code>  <strong>推迟 2 秒钟</strong>，等到下次在进入本函数时，如果推迟时间超过 2 秒，那么更新 <strong>aof_delayed_fsync</strong> 值（info 里可以查到），打印日志 ” <strong>Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</strong> “ ，之后进行 <code>write</code> 系统调用。当然了，系统也提供了 force 选项，去跳过这项是否要推迟 <code>write</code> 的检查。</p><p><code>write</code> 之后，将 <strong>aof_flush_postponed_start</strong> 推迟开始计时值清零，迎接下次检查。</p><p>所以说，AOF 执行 everysec 策略时，如果恰好有 <code>fsync</code> 在长时间的执行，Redis 意外关闭会丢失最多两秒的数据。如果  <code>fsync</code>  运行正常，只有当操作系统 crash 时才会造成最多 1 秒的数据丢失。</p><h5 id="收尾工作，-write- 结果处理">收尾工作， <code>write</code> 结果处理</h5><p><code>write</code> 调用结果可能是正常的，也可能是异常的，那么需要做不同的处理。首先主要看异常处理，</p><pre><code class="language-c">if (nwritten != (signed)sdslen(server.aof_buf)) {    ...    /* Log the AOF write error and record the error code. */    if (nwritten == -1) {...} else { // 如果仅写了一部分，发生错误    // 将追加的内容截断，删除了追加的内容，恢复成原来的文件        if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {...} else {nwritten = -1;}        server.aof_last_write_errno = ENOSPC;    }    // 如果是写入的策略为每次写入就同步，无法恢复这种策略的写，因为我们已经告知使用者，已经将写的数据同步到磁盘了，因此直接退出程序    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {        ...        exit(1);    } else {        // 设置执行 write 操作的状态        server.aof_last_write_status = C_ERR;        if (nwritten &gt; 0) {            // 只能更新当前的 AOF 文件的大小            server.aof_current_size += nwritten;            // 删除 AOF 缓冲区写入的字节            sdsrange(server.aof_buf,nwritten,-1);        }        return; /* We'll try again on the next call... */    }} else {/* Successful write(2). If AOF was in error state, restore the     * OK state and log the event.     */    if (server.aof_last_write_status == C_ERR) {serverLog(LL_WARNING, &quot;AOF write error looks solved, Redis can write again.&quot;);        server.aof_last_write_status = C_OK;    }}</code></pre><p>写入异常的判断，<code>nwritten != (signed)sdslen(server.aof_buf)</code>，<code>write</code> 的数据量与 <strong>aof_buf</strong> 的大小不同。当完全没写入时，打个日志就算了；当仅写入了一部分数据时，使用 <code>ftruncate</code> 函数把 AOF 文件的内容恢复成原来的大小，以备下次重新写入，<strong>nwritten</strong> 置为 -1。使用 <code>ftruncate</code> 的原因是怕操作系统执行了 <code>fsync</code>，因此需要把 AOF 文件的大小恢复。</p><p>如果执行的是 always 同步策略，那么需要返回会客户端错误。对于其他策略，更新 <code>aof_last_write_status</code> ，以便知道上一次做 <code>write</code> 的结果，对于未完全写入的情况，如果上面执行的 <code>ftruncate</code> 失败，此时 <code>nwritten &gt; 0</code>，需要更新 <strong>aof_current_size</strong>，从 <strong>aof_buf</strong> 中减去已经写入的，防止下次有重复数据写入，然后返回。</p><p>如果写入成功，那么视情况更新 <code>aof_last_write_status</code>，表示此次 <code>write</code> 成功。</p><p>下面主要是正常情况的处理。</p><pre><code class="language-c">/* nwritten = -1 时走不到这个步骤 */server.aof_current_size += nwritten; // 正常 write，更新 aof_current_size/* Re-use AOF buffer when it is small enough. The maximum comes from the * arena size of 4k minus some overhead (but is otherwise arbitrary). */if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) {sdsclear(server.aof_buf);} else {sdsfree(server.aof_buf);    server.aof_buf = sdsempty();}/* Don't fsync if no-appendfsync-on-rewrite is set to yes and there are * children doing I/O in the background. */if (server.aof_no_fsync_on_rewrite &amp;&amp; (server.aof_child_pid != -1 || server.rdb_child_pid != -1)) return;/* Perform the fsync if needed. */if (server.aof_fsync == AOF_FSYNC_ALWAYS) {/* aof_fsync is defined as fdatasync() for Linux in order to avoid         * flushing metadata. */    latencyStartMonitor(latency);    aof_fsync(server.aof_fd); /* Let's try to get this data on the disk */    latencyEndMonitor(latency);    latencyAddSampleIfNeeded(&quot;aof-fsync-always&quot;,latency);    server.aof_last_fsync = server.unixtime;} else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp;            server.unixtime &gt; server.aof_last_fsync)) {if (!sync_in_progress) aof_background_fsync(server.aof_fd); // 如果没有正在执行同步，那么创建一个后台任务    server.aof_last_fsync = server.unixtime;}</code></pre><p><strong>aof_buf</strong> 清空，然后根据不同策略进行同步。always 策略时，主动调用 <code>fsync</code>; everysec 策略，则创建 fsync bio 任务。</p><p>另外，有配置项 no-appendfsync-on-rewrite 去决定，当子进程在做 aofrewrite/bgsave 时是否要进行 <code>fsync</code>。</p><h4 id="何时进行文件写入">何时进行文件写入</h4><p>也就是，什么时候会调用 <code>flushAppendOnlyFile</code> 函数，有以下三个时机。</p><h5 id="beforeSleep- 函数">beforeSleep 函数</h5><blockquote><p>Redis 的服务器进程就是一个事件循环，这个循环中的文件事件负责接收客户端请求，以及向客户端发送命令回复，而时间事件则负责像 <code>serverCron</code> 函数这样需要定时运行的函数。</p></blockquote><p>对于 Redis 的事件机制可以参考我之前的文章 《<a href="http://tech-happen.site/85f7b0b4.html" target="_blank" rel="noopener">Redis 中的事件</a>》。</p><p>因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到 <strong>aof_buf</strong> 缓冲区里面，所以在服务器每次结束一个事件循环之前，都会调用 <code>flushAppendOnlyFile</code> 函数，考虑是否需要将  <strong>aof_buf</strong> 缓冲区中的内容写入和同步到 AOF 文件里面。即，</p><pre><code class="language-c">void beforeSleep(struct aeEventLoop *eventLoop) {    ...    /* Write the AOF buffer on disk */    flushAppendOnlyFile(0);    ...}</code></pre><p>这里的调用是非强制写入（force = 0）。</p><h5 id="serverCron- 函数">serverCron 函数</h5><p>Redis 中的时间事件，定期执行  <code>serverCron</code> 函数（从 Redis 2.8 开始，用户可以通过修改  <strong>hz</strong>  选项来调整  <code>serverCron</code>的每秒执行次数），做一些杂事，比如更新服务器各项统计信息、关闭清理客户端、做 AOF 和 RDB 等。</p><pre><code class="language-c">  /* AOF postponed flush: Try at every cron cycle if the slow fsync completed. */if (server.aof_flush_postponed_start) flushAppendOnlyFile(0);</code></pre><p>如果上次 AOF 写入推迟了，那么再次尝试非强制写入。</p><pre><code class="language-c">run_with_period(1000) {if (server.aof_last_write_status == C_ERR)        flushAppendOnlyFile(0);}</code></pre><p>每秒钟检查，如果上次写入 AOF 文件失败了，再次尝试非强制写入。因为需要及时去处理 <code>aof_buf</code>，以及重置 AOF 写入状态的变量 <strong>aof_last_write_status</strong>，每秒做检查，这个频率是足够的。</p><h5 id="stopAppendOnly- 函数">stopAppendOnly 函数</h5><p>当 AOF 功能要关闭时，会调用 <code>stopAppendOnly</code> 函数，尝试一次强制写入，即尽最大努力去保存最多的数据。</p><pre><code class="language-c">void stopAppendOnly(void) {serverAssert(server.aof_state != AOF_OFF);    flushAppendOnlyFile(1);    aof_fsync(server.aof_fd);    close(server.aof_fd);}</code></pre><p>强制写入，并刷盘。</p><h2 id="AOF- 文件载入">AOF 文件载入</h2><p>当 Redis 服务器进程启动时，需要调用 <code>loadDataFromDisk</code> 函数去加载数据。</p><pre><code class="language-c">void loadDataFromDisk(void) {long long start = ustime();    if (server.aof_state == AOF_ON) { // 开启了 aof        if (loadAppendOnlyFile(server.aof_filename) == C_OK)            serverLog(LL_NOTICE,&quot;DB loaded from append only file: %.3f seconds&quot;,(float)(ustime()-start)/1000000);    } else {if (rdbLoad(server.rdb_filename) == C_OK) {            serverLog(LL_NOTICE,&quot;DB loaded from disk: %.3f seconds&quot;,                (float)(ustime()-start)/1000000);        } else if (errno != ENOENT) {serverLog(LL_WARNING,&quot;Fatal error loading the DB: %s. Exiting.&quot;,strerror(errno));            exit(1);        }    }}</code></pre><p>可以看到，如果开启了 AOF 功能，就会调用 <code>loadAppendOnlyFile</code> 函数，加载 AOF 文件中的数据到内存中。否则，会去调用 <code>rdbLoad</code> 函数，加载 RDB 文件。加载 AOF 文件的设计很有意思。</p><pre><code class="language-c">FILE *fp = fopen(filename,&quot;r&quot;);struct redis_stat sb;int old_aof_state = server.aof_state;long loops = 0;off_t valid_up_to = 0; /* Offset of the latest well-formed command loaded. */// 检查文件的正确性, 存在，并且不为空if (fp &amp;&amp; redis_fstat(fileno(fp),&amp;sb) != -1 &amp;&amp; sb.st_size == 0) {    server.aof_current_size = 0;    fclose(fp);    return C_ERR;}if (fp == NULL) {serverLog(LL_WARNING,&quot;Fatal error: can't open the append log file for reading: %s&quot;,strerror(errno));    exit(1);}// 暂时关掉 AOF, 防止向该 filename 中写入新的 AOF 数据server.aof_state = AOF_OFF;</code></pre><p>首先，空文件没有必要再去加载了，提前返回。</p><p>然后，暂时关闭 AOF 功能，这是为了防止在加载 AOF 文件的过程中，又有新的数据写进来</p><pre><code class="language-c">fakeClient = createFakeClient(); // 创建一个不带网络连接的伪客户端startLoading(fp);                // 标记正在 load db，loading = 1// 读 AOF 文件while(1) {    int argc, j;    unsigned long len;    robj **argv;    char buf[128];    sds argsds;    struct redisCommand *cmd;    ... ...        // 如执行命令 SET keytest val，那么写入 AOF 文件中的格式为        // *3\r\n$3\r\nSET\r\n$7\r\nkeytest\r\n$3\r\nval\r\n        if (fgets(buf,sizeof(buf),fp) == NULL) { // 按行读取 AOF 文件，*3            if (feof(fp))                break;            else                goto readerr;        }    if (buf[0] != '*') goto fmterr; // 判断协议是否正确    if (buf[1] == '\0') goto readerr; // 数据完整判断    argc = atoi(buf+1);    if (argc &lt; 1) goto fmterr;    argv = zmalloc(sizeof(robj*)*argc);    fakeClient-&gt;argc = argc;    fakeClient-&gt;argv = argv;    for (j = 0; j &lt; argc; j++) {if (fgets(buf,sizeof(buf),fp) == NULL) { // 依次读到 $3, $7, $3            fakeClient-&gt;argc = j; /* Free up to j-1. */            freeFakeClientArgv(fakeClient);            goto readerr;        }        if (buf[0] != '$') goto fmterr;        len = strtol(buf+1,NULL,10); // 参数长度        argsds = sdsnewlen(NULL,len);        if (len &amp;&amp; fread(argsds,len,1,fp) == 0) { // 依次读到 SET/ keytest/ val            sdsfree(argsds);            fakeClient-&gt;argc = j; /* Free up to j-1. */            freeFakeClientArgv(fakeClient);            goto readerr;        }        argv[j] = createObject(OBJ_STRING,argsds);        if (fread(buf,2,1,fp) == 0) { // 读到 \r\n            fakeClient-&gt;argc = j+1; /* Free up to j. */            freeFakeClientArgv(fakeClient);            goto readerr; /* discard CRLF */        }    }    /* Command lookup */    cmd = lookupCommand(argv[0]-&gt;ptr);    if (!cmd) {serverLog(LL_WARNING,&quot;Unknown command '%s' reading the append only file&quot;, (char*)argv[0]-&gt;ptr);        exit(1);    }    /* Run the command in the context of a fake client */    cmd-&gt;proc(fakeClient);    /* The fake client should not have a reply */    serverAssert(fakeClient-&gt;bufpos == 0 &amp;&amp; listLength(fakeClient-&gt;reply) == 0);    /* The fake client should never get blocked */    serverAssert((fakeClient-&gt;flags &amp; CLIENT_BLOCKED) == 0);    /* Clean up. Command code may have changed argv/argc so we use the         * argv/argc of the client instead of the local variables. */    freeFakeClientArgv(fakeClient);    if (server.aof_load_truncated) valid_up_to = ftello(fp);}</code></pre><p>上面这部分是加载 AOF 文件的关键，以 <code>SET keytest val</code> 命令对应的 AOF 文件内容 <code>*3\r\n$3\r\nSET\r\n$7\r\nkeytest\r\n$3\r\nval\r\n</code> 为例，可以更好地理解上面的逻辑。由于 AOF 文件中存储的数据与客户端发送的请求格式相同完全符合 Redis 的通信协议，因此 Redis Server 创建伪客户端 <strong>fakeClient</strong>，将解析后的 AOF 文件数据像客户端请求一样调用各种指令，<code>cmd-&gt;proc(fakeClient)</code>，将 AOF 文件中的数据重现到 Redis Server 数据库中。</p><p>完成以上逻辑后，进行一些收尾工作，如改回 AOF 状态为 ON，释放伪客户端等，并处理一些异常情况，这里就不展开细讲了。</p><h2 id="参考">参考</h2><ol><li><a href="https://juejin.im/post/5bd96bcaf265da396b72f855" target="_blank" rel="noopener">Copy On Write 机制了解一下</a></li><li><a href="http://mysql.taobao.org/monthly/2018/12/06/" target="_blank" rel="noopener">Redis · 原理介绍 · 利用管道优化 aofrewrite</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>golang 中下划线的使用</title>
    <link href="/3581d0f0.html"/>
    <url>/3581d0f0.html</url>
    
    <content type="html"><![CDATA[<p>在 Golang 里， <code>_</code> （下划线）是个特殊的标识符。前几天看 gin 源码，看到一个有意思的用法。虽然网上的总结博客已有很多，但是总是有点欠缺，于是就有了这一篇，方便以后查阅。</p><a id="more"></a><h3 id="用在 -import">用在 import</h3><p>在导包的时候，常见这个用法，尤其是项目中使用到 mysql 或者使用 pprof 做性能分析时，比如</p><pre><code class="language-go">import _  &quot;net/http/pprof&quot;import _ &quot;github.com/go-sql-driver/mysql&quot;</code></pre><p>这种用法，会调用包中的 <code>init()</code> 函数，让导入的包做初始化，但是却不使用包中其他功能。</p><h3 id="用在返回值">用在返回值</h3><p>该用法也是一个常见用法。Golang 中的函数返回值一般是多个，err 通常在返回值最后一个值。但是，有时候函数返回值中的某个值我们不关心，如何接收了这个值但不使用，代码编译会报错，因此需要将其忽略掉。比如</p><pre><code class="language-go">for _, val := range Slice {}_, err := func()</code></pre><h3 id="用在变量">用在变量</h3><p>我们都知道 Go 语言的接口是非侵入式的，不像 java 和 c++ 那么重，一个结构体只要实现了接口定义的所有函数，我们就说这个接口实现了该接口。有个专门的名字表示这种行为，duck typing，即 <strong> 当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。</strong></p><pre><code class="language-go">type I interface {Sing()}type T struct {}func (t T) Sing() {}type T2 struct {}func (t *T2) Sing() {}// 编译通过var _ I = T{}// 编译通过var _ I = &amp;T{}// 编译失败var _ I = T2{}// 编译通过var _ I = &amp;T2{}</code></pre><p>在这里下划线用来判断结构体是否实现了接口，如果没有实现，在编译的时候就能暴露出问题，如果没有这个判断，后代码中使用结构体没有实现的接口方法，在编译器是不会报错的。</p><p>可以看到上面四个判断只有第三个编译时失败的，报错如下：</p><pre><code class="language-go">./test.go:27:5: cannot use T2 literal (type T2) as type I in assignment:T2 does not implement I (Sing method has pointer receiver)</code></pre><p>这是为什么呢？仔细看上面代码发现，<code>T</code> 实现了 <code>Sing</code> 方法，<code>*T2</code> 实现了 <code>Sing</code> 方法。</p><p>我们都知道，Go 语言中是按值传递的。</p><p>那对于 <code>T2</code> 来说，调用 <code>Sing</code>  方法时，copy 一个副本，然后取地址，通过这个地址是找不到原始调用的那个结构体的，但是 receiver 是个指针，表示此次调用是需要改变调用者内部变量的，很明显，以 <code>T2</code> 类型调用无法完达到这个目的，所以这里是需要报错的。而以 <code>&amp;T2</code> 调用  <code>Sing</code>  方法，则可以，因此不报错。</p><p>而对于 <code>T</code> 来说，不管是否有指针调用，都不会报错，实际上，Go 语言会自动实现 <code>*T</code> 的 <code>Sing</code> 方法。</p><p><strong>当然，这些都是我的个人理解，如果不对的话，欢迎斧正。</strong></p>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之 cluster meet</title>
    <link href="/c62267d.html"/>
    <url>/c62267d.html</url>
    
    <content type="html"><![CDATA[<p>Redis cluster 是 redis 官方提出的分布式集群解决方案，在此之前，有一些第三方的可选方案，如 codis、Twemproxy 等。cluster 内部使用了 gossip 协议进行通信，以达到数据的最终一致性。详细介绍可参考官网 <a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="noopener">Redis cluster tutorial</a>。</p><p>本文试图借着<code>cluster meet</code> 命令的实现来对其中的一些通信细节一探究竟。</p><a id="more"></a><p>我们都知道，当 redis server 以 cluster mode 启动时，节点 B 想加入节点 A 所在的集群，只需要执行 <code>CLUSTER MEET ip port</code> 这个命令即可，通过  gossip  通信，最终 A 所在集群的其他节点也都会认识到 B。大概流程图如下：</p><h2 id="cluster- 初始化">cluster 初始化</h2><p>当  redis server  以 cluster mode 启动时，即配置文件中的 <code>cluster-enabled</code> 选项设置为 <code>true</code>，此时在服务启动时，会有一个 cluster 初始化的流程，这个在之前的文章 《<a href="http://tech-happen.site/e74c6d55.html" target="_blank" rel="noopener">Redis 启动流程</a>》中有提到过，即执行函数 <code>clusterInit</code>。在 cluster 中有三个数据结构很重要， <code>clusterState</code> 、 <code>clusterNode</code> 和 <code>clusterLink</code>。</p><p>每个节点都保存着一个 <code>clusterState</code> 结构，这个结构记录了在当前节点的视角下，集群目前所处的状态，即“我看到的世界是什么样子”。</p><p>每个节点都会使用一个 <code>clusterNode</code> 结构来记录自己的状态， 并为集群中的所有其他节点（包括主节点和从节点）都创建一个相应的 <code>clusterNode</code> 结构， 以此来记录其他节点的状态。</p><p><code>clusterNode</code> 结构的 <code>link</code> 属性是一个 <code>clusterLink</code> 结构， 该结构保存了连接节点所需的有关信息， 比如套接字描述符， 输入缓冲区和输出缓冲区。</p><p>更多的细节可以通过网页 《<a href="http://redisbook.com/preview/cluster/node.html" target="_blank" rel="noopener">redis 设计与实现 - 节点</a>》进行了解。</p><p>该初始化很简单，首先是创建一个  <code>clusterState</code> 结构，并初始化一些成员，如下：</p><pre><code class="language-c">server.cluster = zmalloc(sizeof(clusterState));server.cluster-&gt;myself = NULL;server.cluster-&gt;currentEpoch = 0;     // 新节点的 currentEpoch = 0server.cluster-&gt;state = CLUSTER_FAIL; // 初始状态置为 FAILserver.cluster-&gt;size = 1;server.cluster-&gt;todo_before_sleep = 0;server.cluster-&gt;nodes = dictCreate(&amp;clusterNodesDictType,NULL);server.cluster-&gt;nodes_black_list = dictCreate(&amp;clusterNodesBlackListDictType,NULL);server.cluster-&gt;failover_auth_time = 0;server.cluster-&gt;failover_auth_count = 0;server.cluster-&gt;failover_auth_rank = 0;server.cluster-&gt;failover_auth_epoch = 0;server.cluster-&gt;cant_failover_reason = CLUSTER_CANT_FAILOVER_NONE;server.cluster-&gt;lastVoteEpoch = 0;server.cluster-&gt;stats_bus_messages_sent = 0;server.cluster-&gt;stats_bus_messages_received = 0;memset(server.cluster-&gt;slots,0, sizeof(server.cluster-&gt;slots));clusterCloseAllSlots(); // Clear the migrating/importing state for all the slots</code></pre><p>然后给 node.conf 文件加锁，确保每个节点使用自己的 cluster 配置文件。</p><pre><code class="language-c">if (clusterLockConfig(server.cluster_configfile) == C_ERR)    exit(1);</code></pre><p>借着这个机会学习下 redis 如何使用的文件锁。</p><pre><code class="language-c">int fd = open(filename,O_WRONLY|O_CREAT,0644);if (fd == -1) {    serverLog(LL_WARNING,              &quot;Can't open %s in order to acquire a lock: %s&quot;,              filename, strerror(errno));    return C_ERR;}if (flock(fd,LOCK_EX|LOCK_NB) == -1) {if (errno == EWOULDBLOCK) {        serverLog(LL_WARNING,                  &quot;Sorry, the cluster configuration file %s is already used &quot;                  &quot;by a different Redis Cluster node. Please make sure that &quot;                  &quot;different nodes use different cluster configuration &quot;                  &quot;files.&quot;, filename);    } else {        serverLog(LL_WARNING,                  &quot;Impossible to lock %s: %s&quot;, filename, strerror(errno));    }    close(fd);    return C_ERR;}</code></pre><p>然后加载 node.conf 文件，这个过程还会检查这个文件是否合理。</p><p>如果加载失败（或者配置文件不存在），则以 <code>REDIS_NODE_MYSELF|REDIS_NODE_MASTER</code> 为标记，创建一个 clusterNode 结构表示自己本身，置为主节点，并设置自己的名字为一个 40 字节的随机串；然后将该节点添加到 server.cluster-&gt;nodes 中，这说明这是个新启动的节点，生成的配置文件进行刷盘。</p><pre><code class="language-c">if (clusterLoadConfig(server.cluster_configfile) == C_ERR) {    myself = server.cluster-&gt;myself =        createClusterNode(NULL,CLUSTER_NODE_MYSELF|CLUSTER_NODE_MASTER);    serverLog(LL_NOTICE,&quot;No cluster configuration found, I'm %.40s&quot;,              myself-&gt;name);    clusterAddNode(myself);    saveconf = 1;}if (saveconf) clusterSaveConfigOrDie(1); // 新节点，将配置刷到配置文件中，fsync</code></pre><p>接下来，调用 <code>listenToPort</code> 函数，在集群 gossip 通信端口上创建 socket fd 进行监听。集群内 gossip 通信端口是在 <strong>Redis 监听端口基础上加 10000</strong>，比如如果 Redis 监听客户端的端口为 6379，则集群监听端口就是 16379，该监听端口用于接收其他集群节点发送过来的 gossip 消息。</p><p>然后注册监听端口上的可读事件，事件回调函数为 <code>clusterAcceptHandler</code>。</p><pre><code class="language-c">#define CLUSTER_PORT_INCR 10000if (listenToPort(server.port+CLUSTER_PORT_INCR,                 server.cfd,&amp;server.cfd_count) == C_ERR){exit(1);} else {    int j;    for (j = 0; j &lt; server.cfd_count; j++) {if (aeCreateFileEvent(server.el, server.cfd[j], AE_READABLE,                              clusterAcceptHandler, NULL) == AE_ERR)            serverPanic(&quot;Unrecoverable error creating Redis Cluster &quot;                        &quot;file event.&quot;);    }}</code></pre><p>当前节点收到其他集群节点发来的 TCP 建链请求之后，就会调用 <code>clusterAcceptHandler</code> 函数 accept 连接。在 <code>clusterAcceptHandler</code>函数中，对于每个已经 accept 的链接，都会创建一个<code>clusterLink</code> 结构表示该链接，并注册 socket fd 上的可读事件，事件回调函数为 <code>clusterReadHandler</code>。</p><pre><code class="language-c">#define MAX_CLUSTER_ACCEPTS_PER_CALL 1000void clusterAcceptHandler(aeEventLoop *el, int fd, void *privdata, int mask) {    int cport, cfd;    int max = MAX_CLUSTER_ACCEPTS_PER_CALL;    char cip[NET_IP_STR_LEN];    clusterLink *link;    ... ...    // 如果服务器正在启动，不要接受其他节点的连接, 因为 UPDATE 消息可能会干扰数据库内容    if (server.masterhost == NULL &amp;&amp; server.loading) return;    while(max--) {cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), &amp;cport);        if (cfd == ANET_ERR) {if (errno != EWOULDBLOCK)                serverLog(LL_VERBOSE,                    &quot;Error accepting cluster node: %s&quot;, server.neterr);            return;        }        anetNonBlock(NULL,cfd);        anetEnableTcpNoDelay(NULL,cfd);        ... ...        // 创建一个 link 结构来处理连接        // 刚开始的时候， link-&gt;node 被设置成 null，因为现在我们不知道是哪个节点        link = createClusterLink(NULL);        link-&gt;fd = cfd;        aeCreateFileEvent(server.el,cfd,AE_READABLE,clusterReadHandler,link);    }}</code></pre><p>最后是 reset mf 相关的参数。</p><h2 id="CLUSTER-MEET">CLUSTER MEET</h2><h3 id="一、A- 节点接收 -CLUSTER-MEET- 命令">一、A 节点接收 CLUSTER MEET 命令</h3><p>A 节点在<code>cluster.c</code> -&gt; <code>clusterCommand</code> 函数中，接收到 <code>CLUSTER MEET</code> 命令，即</p><pre><code class="language-c">if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;meet&quot;) &amp;&amp; c-&gt;argc == 4) {    long long port;    // CLUSTER MEET &lt;ip&gt; &lt;port&gt;    if (getLongLongFromObject(c-&gt;argv[3], &amp;port) != C_OK) {addReplyErrorFormat(c,&quot;Invalid TCP port specified: %s&quot;, (char*)c-&gt;argv[3]-&gt;ptr);        return;    }    if (clusterStartHandshake(c-&gt;argv[2]-&gt;ptr,port) == 0 &amp;&amp; errno == EINVAL)    {        addReplyErrorFormat(c,&quot;Invalid node address specified: %s:%s&quot;,                            (char*)c-&gt;argv[2]-&gt;ptr, (char*)c-&gt;argv[3]-&gt;ptr);    } else {addReply(c,shared.ok);    }}</code></pre><p>可以看到重点在 <code>clusterStartHandshake</code> 这个函数。</p><pre><code class="language-c">int clusterStartHandshake(char *ip, int port) {    clusterNode *n;    char norm_ip[NET_IP_STR_LEN];    struct sockaddr_storage sa;    /* IP and Port sanity check */    ... ...    // 检查节点(flag) norm_ip:port 是否正在握手    if (clusterHandshakeInProgress(norm_ip,port)) {        errno = EAGAIN;        return 0;    }    // 创建一个含随机名字的 node，type 为 CLUSTER_NODE_HANDSHAKE|CLUSTER_NODE_MEET    // 相关信息会在 handshake 过程中被修复    n = createClusterNode(NULL,CLUSTER_NODE_HANDSHAKE|CLUSTER_NODE_MEET);    memcpy(n-&gt;ip,norm_ip,sizeof(n-&gt;ip));    n-&gt;port = port;    clusterAddNode(n);    return 1;}</code></pre><pre><code class="language-c">clusterNode *createClusterNode(char *nodename, int flags) {clusterNode *node = zmalloc(sizeof(*node));    if (nodename)        memcpy(node-&gt;name, nodename, CLUSTER_NAMELEN);    else        // 在本地新建一个 nodename 节点，节点名字随机，跟它通信时它会告诉我真实名字        getRandomHexChars(node-&gt;name, CLUSTER_NAMELEN);    node-&gt;ctime = mstime(); // mstime    node-&gt;configEpoch = 0;    node-&gt;flags = flags;    memset(node-&gt;slots,0,sizeof(node-&gt;slots));    node-&gt;slaveof = NULL;    ... ...    node-&gt;link = NULL; // link 为空, 在 clusterCron 中能检查的到    memset(node-&gt;ip,0,sizeof(node-&gt;ip));    node-&gt;port = 0;    node-&gt;fail_reports = listCreate();    ... ...    listSetFreeMethod(node-&gt;fail_reports,zfree);    return node;}</code></pre><p>这个函数会首先进行一些 ip 和 port 的合理性检查，然后去遍历所看到的 nodes，这个 ip:port 对应的 node 是不是正处于 <code>CLUSTER_NODE_HANDSHAKE</code> 状态，是的话，就说明这是重复 meet，没必要往下走。之后，通过 <code>createClusterNode</code> 函数创建一个带有 <code>CLUSTER_NODE_HANDSHAKE|CLUSTER_NODE_MEET</code> 标记的节点，名字为一个 <strong> 随机 </strong> 的 40 字节字符串（因为此时对 A 来说，B 是一个陌生的节点，信息除了 ip 和 port，其他都不知道），通过 <code>clusterAddNode</code> 函数加到自己的 nodes 中。</p><p>这个过程成功后，就返回给客户端 OK 了，其他事情需要通过 gossip 通信去做。</p><h3 id="二、A- 节点发送 -MEET- 消息给 -B- 节点">二、A 节点发送 MEET 消息给 B 节点</h3><p>A 节点在定时任务 <code>clusterCron</code> 中，会做一些事情。</p><pre><code class="language-c">handshake_timeout = server.cluster_node_timeout;if (handshake_timeout &lt; 1000) handshake_timeout = 1000;// 检查是否有 disconnected nodes 并且重新建立连接di = dictGetSafeIterator(server.cluster-&gt;nodes); // 遍历所有节点while((de = dictNext(di)) != NULL) {clusterNode *node = dictGetVal(de);     // 忽略掉 myself 和 noaddr 状态的节点    if (node-&gt;flags &amp; (CLUSTER_NODE_MYSELF|CLUSTER_NODE_NOADDR)) continue;    // 节点处于 handshake 状态，且状态维持时间超过 handshake_timeout，那么从 nodes 中删掉它    if (nodeInHandshake(node) &amp;&amp; now - node-&gt;ctime &gt; handshake_timeout) {clusterDelNode(node);        continue;    }    // 刚刚收到 cluster meet 命令创建的新 node ，或是 server 刚启动，或是由于某种原因断开了    if (node-&gt;link == NULL) {        int fd;        mstime_t old_ping_sent;        clusterLink *link;        // 对端 gossip 通信端口为 node 端口 + 10000，创建 tcp 连接, 本节点相当于 client        fd = anetTcpNonBlockBindConnect(server.neterr, node-&gt;ip, node-&gt;port+CLUSTER_PORT_INCR, NET_FIRST_BIND_ADDR);        ... ...        link = createClusterLink(node);        link-&gt;fd = fd;        node-&gt;link = link;        // 注册 link-&gt;fd 上的可读事件，事件回调函数为 clusterReadHandler        aeCreateFileEvent(server.el,link-&gt;fd,AE_READABLE, clusterReadHandler,link);        ... ...        // 如果 node 带有 MEET flag，我们发送一个 MEET 包而不是 PING,        // 这是为了强制让接收者把我们加到它的 nodes 中        clusterSendPing(link, node-&gt;flags &amp; CLUSTER_NODE_MEET ? CLUSTERMSG_TYPE_MEET : CLUSTERMSG_TYPE_PING);        ... ...        node-&gt;flags &amp;= ~CLUSTER_NODE_MEET;        ... ...    }}dictReleaseIterator(di);</code></pre><p>可以看到，遍历自己看到的 nodes，当遍历到 B 节点时，由于 <code>node-&gt;link == NULL</code>，因此会监听 B 的启动端口号 +10000，即 gossip 通信端口，然后注册可读事件，处理函数为 <code>clusterReadHandler</code>。接着会发送 <strong>CLUSTER_NODE_MEET</strong> 消息给 B 节点，消除掉 B 节点的 <strong>meet</strong> 状态。</p><h3 id="三、B- 节点处理 -A- 发来的 -MEET- 消息">三、B 节点处理 A 发来的 MEET  消息</h3><p>当 B 节点接收到 A 节点发送 gossip 时，回调函数 <code>clusterAcceptHandler</code> 进行处理，然后会 accept 对端的 connect（B 作为 server，对端作为 client），注册可读事件，回调函数为 <code>clusterReadHandler</code>，基本逻辑如下，</p><pre><code class="language-c">void clusterAcceptHandler(aeEventLoop *el, int fd, void *privdata, int mask) {    int cport, cfd;    int max = MAX_CLUSTER_ACCEPTS_PER_CALL;    char cip[NET_IP_STR_LEN];    clusterLink *link;    UNUSED(el);    UNUSED(mask);    UNUSED(privdata);    // 如果服务器正在启动，不要接受其他节点的链接，因为 UPDATE 消息可能会干扰数据库内容    if (server.masterhost == NULL &amp;&amp; server.loading) return;    while(max--) { // 1000 个请求        cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), &amp;cport);        if (cfd == ANET_ERR) {if (errno != EWOULDBLOCK)                serverLog(LL_VERBOSE,                    &quot;Error accepting cluster node: %s&quot;, server.neterr);            return;        }        anetNonBlock(NULL,cfd);        anetEnableTcpNoDelay(NULL,cfd);        serverLog(LL_VERBOSE,&quot;Accepted cluster node %s:%d&quot;, cip, cport);        // 创建一个 link 结构来处理连接        // 刚开始的时候， link-&gt;node 被设置成 null，因为现在我们不知道是哪个节点        link = createClusterLink(NULL);        link-&gt;fd = cfd;        aeCreateFileEvent(server.el,cfd,AE_READABLE,clusterReadHandler,link);    }}</code></pre><p>可以看到每次 accept 对端 connect 时，都会创建一个 <code>clusterLink</code> 结构用来接收数据，</p><pre><code class="language-c">typedef struct clusterLink {    mstime_t ctime;             /* Link creation time */    int fd;                     /* TCP socket file descriptor */    sds sndbuf;                 /* Packet send buffer */    sds rcvbuf;                 /* Packet reception buffer */    struct clusterNode *node;   /* Node related to this link if any, or NULL */} clusterLink;</code></pre><p><code>clusterLink</code> 有一个指针是指向 node 自身的。</p><p>B 节点接收到 A 节点发送过来的信息，放到 <code>clusterLink</code> 的 <code>rcvbuf</code> 字段，然后使用 <code>clusterProcessPacket</code> 函数来处理（接收数据过程很简单，不做分析）。</p><p>所以 <code>clusterProcessPacket</code> 函数的作用是处理别人发过来的 gossip 包。</p><pre><code class="language-c">if (!sender &amp;&amp; type == CLUSTERMSG_TYPE_MEET) {    clusterNode *node;    // 创建一个带有 CLUSTER_NODE_HANDSHAKE 标记的 cluster node，名字随机    node = createClusterNode(NULL,CLUSTER_NODE_HANDSHAKE);    nodeIp2String(node-&gt;ip,link); // ip 和 port 信息均从 link 中获得    node-&gt;port = ntohs(hdr-&gt;port);    clusterAddNode(node);    clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG);}.....clusterSendPing(link,CLUSTERMSG_TYPE_PONG);</code></pre><p>由于这时 B 节点还不认识 A 节点，因此 B 节点从自己的 nodes 中找 A 节点是找不到的，所以 sender 是空，因此会走进如上的这段逻辑。同样以随机的名字，CLUSTER_NODE_HANDSHAKE 为 flag 创建一个 node，加入自己的 nodes 中。</p><p><strong>在这个逻辑末尾会给 A 节点回复一个 PONG 消息</strong>。</p><h3 id="四、A- 节点处理 -B- 节点回复的 -PONG- 消息">四、A 节点处理 B 节点回复的 PONG 消息</h3><p>同样是在 <code>clusterProcessPacket</code> 中处理 gossip 消息。</p><pre><code class="language-c">if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_PONG || type == CLUSTERMSG_TYPE_MEET) {    ... ...    if (link-&gt;node) {if (nodeInHandshake(link-&gt;node)) { // node 处于握手状态            ... ...            clusterRenameNode(link-&gt;node, hdr-&gt;sender); // 修正节点名            link-&gt;node-&gt;flags &amp;= ~CLUSTER_NODE_HANDSHAKE; // 消除 handshake 状态            link-&gt;node-&gt;flags |= flags&amp;(CLUSTER_NODE_MASTER|CLUSTER_NODE_SLAVE);            clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG);        }}</code></pre><p>这个时候 A 节点会根据 B 节点发来的消息，更正 A 节点 nodes 中关于 B 节点的名字，以及消除 <strong>handshake</strong> 状态。</p><h3 id="五、B- 节点发送 -PING- 消息给 -A- 节点">五、B 节点发送 PING 消息给 A 节点</h3><p>当 B 节点在做 <code>clusterCron</code> 时，发现自己看到的 A 节点中的 link 为空，即 <code>node-&gt;link == NULL</code>，这与上面讲的 A 节点给 B 节点发 MEET 消息类似，不过在 B 节点看了 A 节点没有 meet flag，因此发送的是 PING 消息。</p><h3 id="六、A- 节点处理 -B- 节点发来的 -PING- 消息">六、A 节点处理 B 节点发来的 PING 消息</h3><p>做一些逻辑，不过跟这次要讨论的事情无关，后面会详写。</p><p><strong>对于 PING 和 MEET 消息，无论如何都是会回复一个 PONG 消息的</strong>。</p><h3 id="七、B- 节点处理 -A- 节点回复的 -PONG- 消息">七、B 节点处理 A 节点回复的 PONG 消息</h3><p>逻辑同上，将 B 节点的 nodes 中 A 节点的名字进行更正，然后去掉 A 节点的 handshake flag。</p><h3 id="补充">补充</h3><p>上面流程的 <strong> 第四步 </strong> 之后，在 A 看来 B 节点就已经是个完好的节点了，且建立了 A 到 B 的 link。实际上，上面的 <strong> 第五至七步 </strong> 是不确定的，可能存在如下并行逻辑，即，</p><p>A 节点恰好选中了 B 节点发送 PING 消息，当 B 节点接收到这个 PING 消息后，填充自己看到的 A 节点，消除掉 handshake 状态，但是此时 B 节点的 <code>server.cluster-&gt;nodes</code> 中到 A 节点的 link 仍然是空，即，没办法给 A 发 gossip 消息。</p><p>这两个逻辑哪个先发生不一定，但是最终的状态都是，A 节点与 B 节点之间有两条 link，一条是 A 节点创建的到 B 节点的 link，一条是 B 节点创建的到 A 节点的 link。两个节点地位一样，可以同时给对方发信息，如果只保留一条 link 其实也是可以的，不过逻辑会复杂很多，不方便。</p><h2 id="小结">小结</h2><p>至此，一个 <code>cluster meet</code> 命令执行的完整过程就解释清楚了，画了一个流程图可以帮助更好的理解这个流程。</p><p><img src="http://ww1.sinaimg.cn/mw690/71ca8e3cly1fycksh2170j20pu0nbjst.jpg" srcset="/img/loading.gif" alt="cluster meet"></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之启动流程</title>
    <link href="/35a9decf.html"/>
    <url>/35a9decf.html</url>
    
    <content type="html"><![CDATA[<p>说说 redis 的启动流程。</p><a id="more"></a><p>首先要找到 <strong> 启动函数</strong>，我们知道 C 程序从 <code>main</code> 函数开始，所以，就找到了“梦想”开始的地方 <code>server.c</code> -&gt; <code>main</code>。<br>这里主要讲启动过程中的主要部分，所以并不会一一涉及到。</p><h2 id="大概启动流程">大概启动流程</h2><h3 id="initServerConfig- 函数">initServerConfig 函数</h3><p>整个代码中最重要的结构体莫过于 <code>struct redisServer server</code>，它以一个全局变量的形式出现。本函数主要是对它的成员进行赋值操作，这些成员基本上是可以通过 redis.conf 文件来配置。</p><h4 id="大部分成员赋初值">大部分成员赋初值</h4><p>比如：</p><table><thead><tr><th>server 字段</th><th>含义</th></tr></thead><tbody><tr><td>runid</td><td>节点标识占用 40B</td></tr><tr><td>port</td><td>启动端口默认为 6379</td></tr><tr><td>tcp_backlog</td><td>默认 511B</td></tr><tr><td>aof_fsync</td><td>默认 aof 每秒刷盘，但是 aof 默认关闭</td></tr><tr><td>aof_filename</td><td>默认 aof 文件名为 appendonly.aof</td></tr><tr><td>rdb_filename</td><td>默认 rdb 文件名为 dump.rdb</td></tr><tr><td>cluster_node_timeout</td><td>默认 15s，默认 cluster 模式关闭</td></tr></tbody></table><h4 id="默认 -rdb- 触发条件">默认 rdb 触发条件</h4><pre><code class="language-c">appendServerSaveParams(60 * 60,1);  /* save after 1 hour and 1 change */appendServerSaveParams(300,100);    /* save after 5 minutes and 100 changes */appendServerSaveParams(60,10000);   /* save after 1 minute and 10000 changes */</code></pre><h4 id="Replication-related">Replication related</h4><p>包含对 backlog 的相关设置。</p><h4 id="Double-constants-initialization">Double constants initialization</h4><p>浮点数据精度设置。</p><h4 id="client-output-buffer-limit">client output buffer limit</h4><p>一共有三种类型，如下：</p><pre><code class="language-c">clientBufferLimitsConfig clientBufferLimitsDefaults[CLIENT_TYPE_OBUF_COUNT] = {{0, 0, 0},                         /* normal */    {1024*1024*256, 1024*1024*64, 60}, /* slave */    {1024*1024*32, 1024*1024*8, 60}    /* pubsub */};</code></pre><h4 id="redis- 命令表">redis 命令表</h4><p>初始化 redis 命令表放到 <code>server.commands</code>中，这主要是在 <code>populateCommandTable</code> 函数中完成的。</p><p><strong>注意 </strong>：考虑到在 redis.conf 配置文件中可以使用 rename-command 来对 Command 进行重命名（通常是为了安全考虑而禁用某些命令），因此命令表保存了<strong> 两份</strong>，即 <code>server.commands</code> 和 <code>server.orig_commands</code>。</p><p>同时还对一些经常查询的命令单独提出来，分别放到以下变量中，</p><pre><code class="language-c">struct redisCommand *delCommand, *multiCommand, *lpushCommand, *lpopCommand,                    *rpopCommand, *sremCommand, *execCommand;</code></pre><h4 id="Slow-log">Slow log</h4><p>默认时间为 <strong>10ms</strong>。</p><h3 id="sentinel- 模式">sentinel 模式</h3><p>以下方式进行该模式的开启：</p><pre><code class="language-c">int checkForSentinelMode(int argc, char **argv) {    int j;    if (strstr(argv[0],&quot;redis-sentinel&quot;) != NULL) return 1;    for (j = 1; j &lt; argc; j++)        if (!strcmp(argv[j],&quot;--sentinel&quot;)) return 1;    return 0;}</code></pre><p>使用命令行参数 <code>--sentinel</code>，或者直接使用二进制文件 <code>redis-sentinel</code>。</p><p><strong>如果开启 </strong> 了该模式，那么进行相应的初始，没开启就跳过。</p><pre><code class="language-c">if (server.sentinel_mode) {initSentinelConfig(); // sentinel 默认端口 26379    initSentinel(); // sentinel 变量赋初值}</code></pre><h3 id="命令行参数解析并载入配置文件">命令行参数解析并载入配置文件</h3><p>主要还是获得配置文件的 <strong> 绝对路径</strong> <code>server.configfile = getAbsolutePath(configfile)</code>。</p><p>配置文件的载入有专门的函数</p><pre><code class="language-c">void loadServerConfig(char *filename, char *options){}</code></pre><p>载入配置文件后，会覆盖之前对于 server 的某些默认配置。实际上，当 redis-server 启动后，一些配置可以通过 <code>config get</code> 命令查看，也可以通过 <code>config set</code> 命令进行修改，修改后 <code>config rewrite</code> 刷盘。</p><h3 id="initServer- 函数">initServer 函数</h3><p>不同于 <code>initServerConfig</code> 函数，该函数主要初始化一些 redis-server 运行中的成员。</p><h4 id="信号处理">信号处理</h4><p>通过 redis 来复习下信号处理。</p><pre><code class="language-c">// 忽略 SIGHUP 和 SIGPIPE 信号signal(SIGHUP, SIG_IGN);signal(SIGPIPE, SIG_IGN);</code></pre><pre><code class="language-c">void setupSignalHandlers(void) {    struct sigaction act;    sigemptyset(&amp;act.sa_mask);    act.sa_flags = 0;    act.sa_handler = sigShutdownHandler;    sigaction(SIGTERM, &amp;act, NULL);    sigaction(SIGINT, &amp;act, NULL);    return;}</code></pre><p>主要是程序退出的善后工作。</p><h4 id="系统日志">系统日志</h4><pre><code class="language-c">if (server.syslog_enabled) {    openlog(server.syslog_ident, LOG_PID | LOG_NDELAY | LOG_NOWAIT,            server.syslog_facility);}</code></pre><p>前提是使用到了系统的 rsyslog。</p><h4 id="createSharedObjects- 函数">createSharedObjects 函数</h4><p>该函数把一些常用的字符串保存起来，目的就是为了减少不断申请释放时 CPU 时间，内存碎片等等。</p><p>比如 <code>shared.ok = createObject(OBJ_STRING,sdsnew(&quot;+OK\r\n&quot;))</code>。</p><p><strong>额外说明的是</strong>，这里还初始化了一个很大的共享数字对象，0 到 999。因此在设置 value 时可以使用这些数字可以减少内存的使用。</p><pre><code class="language-c">#define OBJ_SHARED_INTEGERS 10000for (j = 0; j &lt; OBJ_SHARED_INTEGERS; j++) { // 10000 个数字    shared.integers[j] = createObject(OBJ_STRING,(void*)(long)j);    shared.integers[j]-&gt;encoding = OBJ_ENCODING_INT;}</code></pre><p><code>struct sharedObjectsStruct shared</code> 也是一个全局变量。</p><h4 id="adjustOpenFilesLimit- 函数">adjustOpenFilesLimit 函数</h4><p>该函数根据配置文件中配置的最大 client 数量增大可以打开的最多文件数。</p><h4 id="创建 -eventLoop">创建 eventLoop</h4><pre><code class="language-c"> server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR)</code></pre><p>这里假设 io 多路复用使用的是 epoll，这也是用的最多的。</p><h4 id="初始化数据库对象">初始化数据库对象</h4><pre><code class="language-c">server.db = zmalloc(sizeof(redisDb)*server.dbnum);</code></pre><p>数据库对象 <code>struct redisDb</code>，有 16 个。</p><h4 id="监听 -port- 端口">监听 port 端口</h4><pre><code class="language-c">if (server.port != 0 &amp;&amp;    listenToPort(server.port,server.ipfd,&amp;server.ipfd_count) == C_ERR)    exit(1);</code></pre><p>监听 <code>server.port</code>，并把返回的 fd 存储在  <code>server.ipfd</code> 中，有报错就返回。</p><h4 id="创建系统 -cron- 定时器">创建系统 cron 定时器</h4><pre><code class="language-c">if(aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR) {serverPanic(&quot;Can't create the serverCron time event.&quot;);    exit(1);}</code></pre><p>注册定时时间，绑定回调函数 <code>serverCron</code>，在该函数中我们可以看到，执行周期为 <code>1000/server.hz</code> ms，因此每秒会执行<code>server.hz</code>（该值用户可配）。</p><p>那为什么是这个频率呢？redis 中对于事件处理在之前的一篇博客中写过，可以参考下 <a href="http://tech-happen.site/85f7b0b4.html" target="_blank" rel="noopener">Redis 中的事件</a>，这里也可以简单回顾下。</p><p>时间事件处理函数 <code>ae.c</code>-&gt; <code>processTimeEvents</code> 中，会根据时间事件的回调返回值来决定这时一个周期事件还是一次性事件，即</p><pre><code class="language-c">{    int retval;    id = te-&gt;id;    retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData);    processed++;    if (retval != AE_NOMORE) {aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);    } else {te-&gt;id = AE_DELETED_EVENT_ID;}}</code></pre><h4 id="监听 - 接收用户请求">监听 / 接收用户请求</h4><pre><code class="language-c">for (j = 0; j &lt; server.ipfd_count; j++) {if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, // 监听可读事件                          acceptTcpHandler,NULL) == AE_ERR)    {        serverPanic(&quot;Unrecoverable error creating server.ipfd file event.&quot;);    }}</code></pre><p>接收用户请求（用户连接会从这里进来），监听可读事件，注册回调函数 <code>acceptTcpHandler</code>。</p><h4 id="cluster- 初始化">cluster 初始化</h4><p>如果开启了 cluster mode，会进行相应的初始化。</p><pre><code class="language-c">if (server.cluster_enabled) clusterInit();</code></pre><h4 id="其他环境初始化">其他环境初始化</h4><pre><code class="language-c">replicationScriptCacheInit();scriptingInit(1);slowlogInit();latencyMonitorInit();bioInit();</code></pre><h3 id="设置进程名">设置进程名</h3><p>这个函数很实用的，方便 ps 看到良好格式的进程名。一起来复习下。</p><pre><code class="language-c">void redisSetProcTitle(char *title) {#ifdef USE_SETPROCTITLE    char *server_mode = &quot;&quot;;    if (server.cluster_enabled) server_mode = &quot; [cluster]&quot;;    else if (server.sentinel_mode) server_mode = &quot; [sentinel]&quot;;    setproctitle(&quot;%s %s:%d%s&quot;,        title,        server.bindaddr_count ? server.bindaddr[0] : &quot;*&quot;,        server.port,        server_mode);#else    UNUSED(title);#endif}</code></pre><h3 id="加载持久化数据">加载持久化数据</h3><p>如果不是以 sentinel 模式启动的，那么会加载持久化的数据，处理函数为 <code>loadDataFromDisk</code>。</p><p>如果开启了 aof，那么就加载 aof 文件，否则加载 rdb 文件。</p><h5 id="loadAppendOnlyFile">loadAppendOnlyFile</h5><p>该函数用来记载  aof 文件，主要流程就是创建一个伪客户端，从 aof  文件中解析出来命令，让 server 重新执行一遍。</p><pre><code class="language-c">if (buf[0] != '*') goto fmterr;   // 判断协议是否正确if (buf[1] == '\0') goto readerr; // 判断数据完整判断argc = atoi(buf+1);if (argc &lt; 1) goto fmterr;argv = zmalloc(sizeof(robj*)*argc); // argc 个 robj 对象fakeClient-&gt;argc = argc;fakeClient-&gt;argv = argv;for (j = 0; j &lt; argc; j++) {if (fgets(buf,sizeof(buf),fp) == NULL) { // 每行最多 128B        fakeClient-&gt;argc = j; /* Free up to j-1. */        freeFakeClientArgv(fakeClient);        goto readerr;    }    if (buf[0] != '$') goto fmterr;    len = strtol(buf+1,NULL,10); // 命令的长度    argsds = sdsnewlen(NULL,len);    if (len &amp;&amp; fread(argsds,len,1,fp) == 0) {sdsfree(argsds);        fakeClient-&gt;argc = j; /* Free up to j-1. */        freeFakeClientArgv(fakeClient);        goto readerr;    }    argv[j] = createObject(OBJ_STRING,argsds);    if (fread(buf,2,1,fp) == 0) { // \r\n        fakeClient-&gt;argc = j+1; /* Free up to j. */        freeFakeClientArgv(fakeClient);        goto readerr; /* discard CRLF */    }}cmd = lookupCommand(argv[0]-&gt;ptr);if (!cmd) {serverLog(LL_WARNING,&quot;Unknown command '%s' reading the append only file&quot;, (char*)argv[0]-&gt;ptr);    exit(1);}// 用 fakeClient 执行命令cmd-&gt;proc(fakeClient);</code></pre><p>以上函数就是 aof 文件解析过程。</p><p>附上一段 redis 协议数据，方便分析函数。</p><pre><code class="language-c">*3$3SET$2xx$2yy*3</code></pre><p><strong>注意</strong>：在加载 aof 文件过程中，会暂时关闭 aof。</p><h5 id="rdbLoad">rdbLoad</h5><p>该函数用来加载 rdb 文件。与 aof 加载不同的是，解析 rdb 文件后直接放入内存中。</p><h3 id="事件循环初始化">事件循环初始化</h3><pre><code class="language-c">// 进入事件循环之前执行 beforeSleep() 函数aeSetBeforeSleepProc(server.el,beforeSleep);// 开始事件循环aeMain(server.el);// 服务器关闭，删除事件循环aeDeleteEventLoop(server.el);</code></pre><h2 id="小结">小结</h2><p>画了一个流程图，可以很好的体现以上流程。<br><img src="http://ww1.sinaimg.cn/large/71ca8e3cly1fxz66ssdg9j209a0pdac8.jpg" srcset="/img/loading.gif" alt="redis server setup"></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 源码之 Bio</title>
    <link href="/9ceee0f6.html"/>
    <url>/9ceee0f6.html</url>
    
    <content type="html"><![CDATA[<p>很多人提到 Redis 时都会讲这是一个 <strong> 单线程 </strong> 的内存数据库，其实不然。虽然 Redis 把处理网络收发和执行命令这些操作都放在了主工作线程，但是除此之外还有许多 bio 后台线程也在兢兢业业的工作着，比如用来处理关闭文件和刷盘这些比较重的 IO 操作。bio，即 Background I/O。</p><p>Redis 源码中关于 bio 的部分，主要在 <code>bio.h</code> 和 <code>bio.c</code> 这两个文件中。</p><a id="more"></a><h3 id="任务类型">任务类型</h3><pre><code class="language-c">/* Background job opcodes */#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */#define BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */#define BIO_NUM_OPS       2</code></pre><p>从上面代码可以看出，在 3.2 的版本的 redis 中 Bio 负责两种类型任务。一是关闭文件，二是 aof 持久化。4.x 的版本增加了惰性删除的任务。每种类型的任务都有单独的线程去处理，并配置相关的锁和条件变量用于同步。同一类型的任务组成 list，按 <strong>FIFO</strong> 的顺序执行。</p><p>源码中有如下定义：</p><pre><code class="language-c">// 任务线程数组static pthread_t bio_threads[BIO_NUM_OPS];// 锁static pthread_mutex_t bio_mutex[BIO_NUM_OPS];// 条件变量static pthread_cond_t bio_condvar[BIO_NUM_OPS];// 任务 list 数组static list *bio_jobs[BIO_NUM_OPS];// pending 的任务数量static unsigned long long bio_pending[BIO_NUM_OPS];</code></pre><p>Job 的数据结构很简单，在源码中定义如下：</p><pre><code class="language-c">struct bio_job {    time_t time; /* Time at which the job was created. */    void *arg1, *arg2, *arg3;};</code></pre><p>其他有用的宏定义</p><pre><code class="language-c">#define REDIS_THREAD_STACK_SIZE (1024*1024*4)</code></pre><h3 id="API- 详解">API 详解</h3><pre><code class="language-c">void bioInit(void);void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3);unsigned long long bioPendingJobsOfType(int type);void bioKillThreads(void);void bioWaitPendingJobsLE(int type, unsigned long long num); // 本版本未实现time_t bioOlderJobOfType(int type); // 本版本未实现</code></pre><h4 id="bioInit- 初始化">bioInit 初始化</h4><pre><code class="language-c">void bioInit(void) {    pthread_attr_t attr;    pthread_t thread;    size_t stacksize;    int j;    // 初始化各任务类型的锁和条件变量, BIO_NUM_OPS 个    for (j = 0; j &lt; BIO_NUM_OPS; j++) {pthread_mutex_init(&amp;bio_mutex[j],NULL);        pthread_cond_init(&amp;bio_condvar[j],NULL);        bio_jobs[j] = listCreate();        bio_pending[j] = 0;    }    // 设置 stack 大小，因为某些系统默认值可能很小    pthread_attr_init(&amp;attr);    pthread_attr_getstacksize(&amp;attr,&amp;stacksize);    if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */    while (stacksize &lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2;    pthread_attr_setstacksize(&amp;attr, stacksize);    // 创建线程。    for (j = 0; j &lt; BIO_NUM_OPS; j++) {void *arg = (void*)(unsigned long) j;        if (pthread_create(&amp;thread,&amp;attr,bioProcessBackgroundJobs,arg) != 0) {serverLog(LL_WARNING,&quot;Fatal: Can't initialize Background Jobs.&quot;);            exit(1);        }        bio_threads[j] = thread;    }}</code></pre><p>上面创建线程时，回调函数 <code>bioProcessBackgroundJobs</code>传入一个参数来代表 job 类型，这样方便找到相应的线程处理不同的任务，像上面说的那样 ， 0  表示文件关闭任务， 1 表示 aof 任务。</p><h4 id="bioProcessBackgroundJobs- 任务处理">bioProcessBackgroundJobs 任务处理</h4><pre><code class="language-c">void *bioProcessBackgroundJobs(void *arg) {    struct bio_job *job;    unsigned long type = (unsigned long) arg;// 传入参数为 job type    sigset_t sigset;    // 检查传入 type 的合理性    if (type &gt;= BIO_NUM_OPS) {serverLog(LL_WARNING, &quot;Warning: bio thread started with wrong type %lu&quot;,type);        return NULL;    }    // 设置线程可以被其他线程调用 pthread_cancel 函数取消 / 终止 （其他线程发来 cancel 请求）    pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL); // 设置本线程对 cancel 信号的反应    // 收到信号后继续运行至下一个取消点再退出，默认是立即退出，与 PTHREAD_CANCEL_ENABLE 配合使用    pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);    pthread_mutex_lock(&amp;bio_mutex[type]);    // 阻塞 SIGALRM， 确保只有主线程将收到 watchdog 信号    sigemptyset(&amp;sigset);    sigaddset(&amp;sigset, SIGALRM);    if (pthread_sigmask(SIG_BLOCK, &amp;sigset, NULL))        serverLog(LL_WARNING,            &quot;Warning: can't mask SIGALRM in bio.c thread: %s&quot;, strerror(errno));    while(1) {        listNode *ln;        // 当没有 type 类型的任务时，会阻塞在这里，等待条件变量触发，这里会释放锁        // 当被激活后们首先要加锁        if (listLength(bio_jobs[type]) == 0) {pthread_cond_wait(&amp;bio_condvar[type],&amp;bio_mutex[type]);            continue;        }        // 从这种任务的 list 中取出来一个        ln = listFirst(bio_jobs[type]);        job = ln-&gt;value;        pthread_mutex_unlock(&amp;bio_mutex[type]);        // 不同类型的 job 做不同的处理        if (type == BIO_CLOSE_FILE) {close((long)job-&gt;arg1);        } else if (type == BIO_AOF_FSYNC) {aof_fsync((long)job-&gt;arg1);        } else {serverPanic(&quot;Wrong job type in bioProcessBackgroundJobs().&quot;);        }        zfree(job);        /*         * 下一次循环前需要再一次加锁         * 如果没有相应的 job，将再一次在 pthread_cond_wait() 阻塞住。         */        pthread_mutex_lock(&amp;bio_mutex[type]);        listDelNode(bio_jobs[type],ln); // 删掉执行过的 job        bio_pending[type]--; // 这种类型还没有出来 job 数减去 1    }}</code></pre><p>以上是 bio 处理 job 的过程，这个就是一个死循环，不断地取到 job 进行处理。</p><p>这个过程需要参考着以下新加某种类型的一个 job 来看。</p><h4 id="bioCreateBackgroundJob- 创建 -job">bioCreateBackgroundJob 创建 job</h4><p>下面的函数将创建一个特定类型的 job， 并放入相应的 job list 中。</p><pre><code class="language-c">void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3) {struct bio_job *job = zmalloc(sizeof(*job));    job-&gt;time = time(NULL);    job-&gt;arg1 = arg1;    job-&gt;arg2 = arg2;    job-&gt;arg3 = arg3;    pthread_mutex_lock(&amp;bio_mutex[type]); // 加锁    listAddNodeTail(bio_jobs[type],job); // 将新的 job 放到对应 job queue 中    bio_pending[type]++;    pthread_cond_signal(&amp;bio_condvar[type]); // 条件变量通知有新的 job 产生    pthread_mutex_unlock(&amp;bio_mutex[type]);// 解锁}</code></pre><p>在该版本的源码中，有两个地方使用到了 <code>bioCreateBackgroundJob</code> 这个函数。</p><pre><code class="language-c">// 执行 fsync() 刷盘的后台任务void aof_background_fsync(int fd) {bioCreateBackgroundJob(BIO_AOF_FSYNC,(void*)(long)fd,NULL,NULL);}</code></pre><pre><code class="language-c">// 异步关闭重写的 aof 文件if (oldfd != -1) {bioCreateBackgroundJob(BIO_CLOSE_FILE,(void*)(long)oldfd,NULL,NULL);}</code></pre><p>可以发现这个用例中，创建 job 的第一个参数都是一个 fd，其他参数都置空了。</p><h3 id="一个完整的 -bio- 任务处理过程">一个完整的 bio 任务处理过程</h3><p>首先服务器启动时，调用 <code>bioInit</code> 函数，进行不同类型 job 线程、锁、条件变量等的初始化，每种类型 job 有自己的处理线程，初始化时会注册回调函数 <code>bioProcessBackgroundJobs</code> 处理各种 job。</p><p>还没有 job 时，各个 job 处理流程在经过 <code>pthread_mutex_lock(&amp;bio_mutex[type])</code> 的加锁后，在 job 处理循环中 <code>pthread_cond_wait(&amp;bio_condvar[type],&amp;bio_mutex[type])</code> 处阻塞住，随之 <strong> 释放锁 </strong> <code>bio_mutex[type]</code>,  <code>pthread_cond_wait</code> 在阻塞时，会释放锁，所以在<strong> 使用前需要先加锁</strong>。</p><p>这时在主线程中创建某个类型的 job，创建过程中，先加锁 <code>pthread_mutex_lock(&amp;bio_mutex[type])</code>, 然后往某种类型的 job list 中 新加一个 job。接着主线程通知 bio 去处理这个 job，<code>pthread_cond_signal(&amp;bio_condvar[type])</code>。</p><p>该类型 job 的后台处理线程从阻塞中被唤醒，它会去加锁，但是由于在主线程中 <code>bio_mutex[type]</code> 这把锁还没有得到释放，因此会继续阻塞。</p><p>接着，主线程释放了锁 <code> pthread_mutex_unlock(&amp;bio_mutex[type])</code>，bio 线程进行加锁，这个由 <code>pthread_cond_wait</code>  完成的。然后 <code>continue</code> 进入下次循环，在取到 job 后 <code>job = ln-&gt;value</code> 进行解锁。执行了 job 之后，在进入下一次循环之前 <strong> 再次加锁</strong>。</p><h3 id="补充">补充</h3><pre><code class="language-c">int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);</code></pre><p>这个函数的理解很重要。</p><p>在条件不满足的时候, 调用该函数进入等待。 当条件满足的时候, 该函数会停止等待, 继续执行。</p><p>该函数的第二个参数是 <code>pthread_mutex_t</code> 类型，这是因为在条件判断的时候, 需要 <strong> 先进行加锁来防止出现错误 </strong>，在执行该函数前需要主动对这个变量执行加锁操作，进入这个函数以后， <strong> 其内部会对 mutex 进行解锁操作</strong>，而函数执行完以后(也就是停止阻塞以后)，又会重新加锁。</p><p>该函数也有带有超时时间的版本。</p><h3 id="总结">总结</h3><p>从上面可以看到，redis bio 其实是一个 C 语言多线程编程很好的例子，值得学习。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 基本数据结构之 dict</title>
    <link href="/d68bbf73.html"/>
    <url>/d68bbf73.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>字典，又称为符号表 (symbol table)、关联数组(associative array) 或者映射(map)，是一种用于保存键值对(key-value pair) 的抽象数据结构。</p></blockquote><p>dict 是一种非常常用的数据结构，因为 c 语言里没有内置这种数据结构，所以 redis 内部实现了自己的 dict  数据结构。</p><a id="more"></a><p>dict 在 redis 中被广泛使用，如 redis 的数据库就是使用 dict 来作为底层实现的，对数据库的增删改查操作也是构建在对 dict 的操作之上的。此外，dict 还是哈希键的底层实现之一。</p><p>redis 源码中关于 dict 的部分，主要在 <code>dict.h</code> 和 <code>dict.c</code> 这两个文件中。</p><h3 id="dict- 的定义">dict 的定义</h3><p>首先在 <code>dict.h</code> 中找到定义，主要分为以下三个部分：</p><pre><code class="language-c">typedef struct dict {    dictType *type;   // 类型特定函数    void *privdata;  // 私有数据，保存着 dictType 结构中函数的参数    dictht ht[2];  // 哈希表，2 个    long rehashidx; /* 标记 rehash 进度，没有的话为 -1 */    int iterators; /* number of iterators currently running */} dict;</code></pre><pre><code class="language-c">typedef struct dictht {    dictEntry **table;  // 哈希节点数组，一个个 hash 桶    unsigned long size;  // 哈希表大小    unsigned long sizemask; // 哈希表大小掩码，计算索引值，= size-1    unsigned long used;  // 该哈希表已有节点（ k-v 对 ）的数量} dictht;</code></pre><pre><code class="language-c">typedef struct dictEntry {    void *key;    union {        void *val;        uint64_t u64;        int64_t s64;        double d;    } v;    struct dictEntry *next; // 链表法解决 hash 冲突} dictEntry;</code></pre><p>将以上三个结构体使用如下图片进行表示，可能会更清楚一些。</p><p><img src="https://s1.ax1x.com/2018/09/08/iPRjfg.jpg" srcset="/img/loading.gif" alt="redis-dict"></p><p><code>dict</code> 结构包含两个哈希表 <code>dictht</code>，每一个哈希表都有很多个哈希桶 <code>dictEntry</code>，<code>table</code> 是一个指针数组类型变量。每一个哈希桶是一个链表，以 <strong> 链表法 </strong> 解决哈希冲突问题。</p><p>一般情况下，只使用 <code>ht[0]</code>，当发生 rehash 的时候才会用到 <code>ht[1]</code>，此时 <code>rehashidx</code> 变量会记录 rehash 目前的进度，不进行 rehash 时，值为 -1。</p><p><code>dictType</code> 结构体定义了一些操作 <code>dict</code> 时要用到的函数指针。</p><pre><code class="language-c">typedef struct dictType {unsigned int (*hashFunction)(const void *key);  // 计算哈希值的函数    void *(*keyDup)(void *privdata, const void *key); // 复制 key 的函数    void *(*valDup)(void *privdata, const void *obj); // 复制 val 的函数    int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 比较 key 的函数    void (*keyDestructor)(void *privdata, void *key); // 销毁 key 的析构函数    void (*valDestructor)(void *privdata, void *obj); // 销毁 val 的析构函数} dictType;</code></pre><p>定义了一些宏，可以更方便地使用这些函数指针，比如，</p><pre><code class="language-c">#define dictFreeVal(d, entry) \    if ((d)-&gt;type-&gt;valDestructor) \        (d)-&gt;type-&gt;valDestructor((d)-&gt;privdata, (entry)-&gt;v.val)</code></pre><p>另外，还定义了一个 dict 迭代器</p><pre><code class="language-c">typedef struct dictIterator {    dict *d; // 被迭代的 dict    long index; // 迭代器当前所指向的哈希表索引位置    // table 表示正迭代的哈希表号码，ht[0]或 ht[1]。safe 表示这个迭代器是否安全    int table, safe;    // entry 指向当前迭代的哈希表节点，nextEntry 则指向当前节点的下一个节点    dictEntry *entry, *nextEntry;    /* unsafe iterator fingerprint for misuse detection. */    long long fingerprint;} dictIterator;</code></pre><h3 id="哈希相关">哈希相关</h3><h4 id="哈希函数">哈希函数</h4><p>我们知道，当要往 hash 表中插入元素的时候，必须要先计算相应 key 的 hash 值。</p><p>在 redis 中定义了三种哈希函数。</p><p>【1】Thomas Wang’s 32 bit Mix Function</p><p>【2】djb 哈希算法</p><p>【3】MurmurHash2，最新版本为 MurmurHash3</p><p>当字典被用作数据库的底层实现时，或者哈希 key 的底层实现时， redis 使用 MurmurHash2 算法来计算 key 的哈希值。</p><p>hash 值使用 hash 函数进行计算，然后与 <code>dictht</code> 的 <code>sizemask</code> 取模，就得到了哈希桶的索引。</p><h4 id="哈希冲突">哈希冲突</h4><p>redis 使用链地址法解决哈希冲突。</p><p>因为  <code>dictEntry</code> 节点组成的链表没有指向链表表尾的指针，考虑到添加节点的成本，总是将新节点添加到链表的表头位置，使得复杂度从 <code>O(n)</code> 降低为 <code>O(1)</code>。</p><h3 id="rehash">rehash</h3><p>随着操作的不断执行，hash 表中保存的元素数量会动态变化，为了让哈希表的负载因子维持在一个合理的范围，需要对哈希表的大小多 <strong> 动态 </strong> 调整。</p><p>大小调整过程中就涉及到哈希桶的分拆或合并，这个过程叫做 rehash。</p><p>当负载因子过高时，产生 hash 冲突的几率就增大了，也就是说某些哈希桶中的链表会越来越长，这样时查找元素的时间复杂度趋于 <code>O(n)</code>，这个时候对 hash 表扩容。</p><p>否则，其中元素太小，浪费空间，就先释放，要用的话再申请。</p><h4 id="是否需要 -rehash">是否需要 rehash</h4><p>对于是否需要进行 rehash，有一个私有函数来尽进行判断。</p><pre><code class="language-c">static int _dictExpandIfNeeded(dict *d){    /* Incremental rehashing already in progress. Return. */    if (dictIsRehashing(d)) return DICT_OK;    // 如果 hash table 是看的，那么把它收缩成出初始化 size (= 4)    if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);    if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;        (dict_can_resize ||         d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio))    {return dictExpand(d, d-&gt;ht[0].used*2);    }    return DICT_OK;}</code></pre><p>以上函数自动判断的。</p><p>还有一个需要手动发起 rehash 的函数，用来对哈希表进行缩容操作。</p><pre><code class="language-c">int dictResize(dict *d){    int minimal;    // 当 dict_can_resize = 0 或者 dict 正在做 rehash 时    if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR;    minimal = d-&gt;ht[0].used;    if (minimal &lt; DICT_HT_INITIAL_SIZE) // 小于 4 的话按照 4 来算        minimal = DICT_HT_INITIAL_SIZE;    return dictExpand(d, minimal); // 用 minimal 调整字典 d 的大小}</code></pre><p><code>dict_can_resize</code> 这个变量做了标记，说明 server 在做 <code>BGSAVE</code> 命令或者 <code>BGREWRITEAOF</code>。</p><h4 id="如何 -rehash">如何 rehash</h4><h5 id="扩容操作">扩容操作</h5><p>在 <code>ht[0].size == 0</code>时，即空哈希表，这时候把哈希表缩容到 size 为初始值 <strong>4</strong>。</p><p>在<code>used &gt; size</code> 的情况下，即这个时候肯定出现了哈希冲突，</p><p>如果允许 rehash，进行哈希表扩容操作，size 为 第一个 <strong>&gt;=</strong> <code>ht[0].used*2</code></p><p>即使不允许，在 <code>used:size &gt; 5</code>的情况下也必须做强制 rehash。</p><p>这时，新的哈希表，即 <code>ht[1]</code> 大小为第一个 &gt;=  <code>ht[0].used*2</code>的 2 的 n 次幂。</p><h5 id="缩容操作">缩容操作</h5><p>即执行上面的 <code>dictResize</code>操作，这个需要 <strong> 手动触发</strong>。</p><p><code>ht[1]</code> 大小为第一个 &gt;=  <code>ht[0].used</code>的 2 的 n 次幂，最小不能小于 4。</p><p>根据计算得到的新哈希表的大小，为 <code>ht[1]</code>分配内存，将 <code>ht[0]</code> 上的数据都迁移到 <code>ht[1]</code>。</p><p>然后将原来 <code>ht[0]</code>的指针指向 <code>ht[1]</code>，释放旧的 <code>ht[0]</code> 内存，重置各个成员变量，留着下次备用。</p><h5 id="渐进式 -rehash">渐进式 rehash</h5><p>如果是一次性完成如上的 rehash 操作，那元素很多的话，可以预见，性能会很差。所以 redis 里采用了一个叫渐进式 rehash 的方案来做这件事情，把一次性要做的事情分为多步。</p><p>主要由 <code>_dictRehashStep</code> 和 <code>dictRehashMilliseconds</code> 两个函数负责。</p><pre><code class="language-c">static void _dictRehashStep(dict *d) {if (d-&gt;iterators == 0) dictRehash(d,1);// 没有迭代器，进行 1 步 rehash}</code></pre><p><code>_dictRehashStep</code> 为被动 rehash ，每次只迁移一个哈希桶。dict 在做其他操作时会查询一下是不是在做 rehash，是的话，就会调用该函数。</p><p>如下：<br><img src="https://s1.ax1x.com/2018/09/09/iPzIIS.jpg" srcset="/img/loading.gif" alt="dict-rehash"></p><pre><code class="language-c">int dictRehashMilliseconds(dict *d, int ms) {long long start = timeInMilliseconds();    int rehashes = 0;    while(dictRehash(d,100)) { // 直到 rehash 完或者时间到了        rehashes += 100;        if (timeInMilliseconds()-start &gt; ms) break;    }    return rehashes;}</code></pre><p><code>dictRehashMilliseconds</code> 在给定的 <strong> 毫秒 </strong> 时间内进行 rehash，每次步长为 100 个 hash 桶，返回值为 move 了多少个 哈希桶。它是在 redis 的 <code>serverCron</code> 里主动触发的，这是一个 1ms 的定时任务。</p><h4 id="函数实现">函数实现</h4><p><strong>注意</strong>：</p><ul><li>因为在 rehash 时，字典会同时使用两个哈希表，所以在这期间的所有查找、删除等操作，除了在 <code>ht[0]</code> 上进行，还需要在 <code>ht[1]</code> 上进行。</li><li>在执行添加操作时，新的节点会直接添加到 <code>ht[1]</code> 而不是 <code>ht[0]</code> ，这样保证 <code>ht[0]</code> 的节点数量在整个 rehash 过程中都只减不增。</li></ul><h5 id="创建 -dict">创建 dict</h5><pre><code class="language-c">// 创建一个新的 dict 结构dict *dictCreate(dictType *type, void *privDataPtr){dict *d = zmalloc(sizeof(*d)); // 分配内存    _dictInit(d,type,privDataPtr);    return d;}/* Initialize the hash table */int _dictInit(dict *d, dictType *type,        void *privDataPtr){_dictReset(&amp;d-&gt;ht[0]); // 两个 hashtable 的初始化    _dictReset(&amp;d-&gt;ht[1]);    d-&gt;type = type;    d-&gt;privdata = privDataPtr;    d-&gt;rehashidx = -1;  // 初始化为 -1    d-&gt;iterators = 0;    return DICT_OK;}</code></pre><p>创建一个 <code>dict</code>，主要就是分配内存，初始化变量。</p><h5 id="扩容 - 创建 hash-table">扩容 / 创建 hash table</h5><pre><code class="language-c">int dictExpand(dict *d, unsigned long size){    dictht n; // 新的 dictht，用于替换    unsigned long realsize = _dictNextPower(size);    // 当 dict 正在 rehash 或者 size 小于现在的 ht[0].used，说明这个 size 是不合法的，返回错误 DICT_ERR    // 要包含现在 dict 所有元素，那么 size 一定要 &gt;= ht[0].used    if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)        return DICT_ERR;    // 要 rehash 的 dictht 大小跟现在 dictht 大小相等，就没必要做 rehash 了，返回错误 DICT_ERR    if (realsize == d-&gt;ht[0].size) return DICT_ERR;    n.size = realsize;    n.sizemask = realsize-1;    n.table = zcalloc(realsize*sizeof(dictEntry*));    n.used = 0;    // 这是第一次初始化吗？如果真是这样，那这就不是一个 rehash    // 仅设置第一个 hash 表，以便接收 keys    if (d-&gt;ht[0].table == NULL) {d-&gt;ht[0] = n;        return DICT_OK;    }    // 非首次初始化，那就设置第二个 hash 表，设置 rehashidx 标记，    // 现在可以进行 rehash 了    d-&gt;ht[1] = n;    d-&gt;rehashidx = 0; // rehash 进度为 0    return DICT_OK;}</code></pre><h5 id="添加元素">添加元素</h5><pre><code class="language-c">int dictAdd(dict *d, void *key, void *val){dictEntry *entry = dictAddRaw(d,key);    if (!entry) return DICT_ERR;    dictSetVal(d, entry, val);    return DICT_OK;}</code></pre><p><code>dictAddRaw </code>函数只是增加了 key，而 value 需要 key 增加成功后再次设置。</p><pre><code class="language-c">dictEntry *dictAddRaw(dict *d, void *key){    int index;    dictEntry *entry;    dictht *ht;    // 检查是否在 rehash    if (dictIsRehashing(d)) _dictRehashStep(d);    /* 获得这个新元素需要加到哪个 hash 桶，     * 若返回 -1 表示已经存在这个 key 了，直接返回 NULL     */    if ((index = _dictKeyIndex(d, key)) == -1)        return NULL;    /* 为新的 key 分配内存并存到 ht 中     * 把新的 key 放到 hash 桶里 list 的第一个，假定在数据库系统中新加入的 key 会更频繁访问到，这会减少查询时间     * */    // dict 在做 rehash 的话，直接把新 key 加到 ht[1]，否则加到 ht[0]    ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];    entry = zmalloc(sizeof(*entry));    entry-&gt;next = ht-&gt;table[index];    ht-&gt;table[index] = entry;    ht-&gt;used++;    dictSetKey(d, entry, key); // 为 key 设置 value    return entry; // 返回新加入的 entry}</code></pre><h5 id="Replace- 元素">Replace 元素</h5><p>这里有两个函数 <code>dictReplace</code> 和 <code>dictReplaceRaw</code>。</p><pre><code class="language-c">int dictReplace(dict *d, void *key, void *val){    dictEntry *entry, auxentry;    // 要添加的 key 在 dict 中不存在，那么直接添加成功    if (dictAdd(d, key, val) == DICT_OK)        return 1;   // 运行到这里，说明键 key 已经存在，找到它    entry = dictFind(d, key);    // 设置新的 value，释放旧的。    auxentry = *entry;    dictSetVal(d, entry, val);    dictFreeVal(d, &amp;auxentry);    return 0;}</code></pre><pre><code class="language-c">dictEntry *dictReplaceRaw(dict *d, void *key) {dictEntry *entry = dictFind(d,key);    // 返回已经存在的 key ，或者新加的    return entry ? entry : dictAddRaw(d,key);}</code></pre><h5 id="删除元素">删除元素</h5><pre><code class="language-c">int dictDelete(dict *ht, const void *key) {return dictGenericDelete(ht,key,0);}int dictDeleteNoFree(dict *ht, const void *key) {return dictGenericDelete(ht,key,1);}</code></pre><p>上面两个函数的区别在于删除 key 的时候是否调用 key 和 value 的释放函数。而真正的删除函数是 <code>dictGenericDelete</code>。</p><pre><code class="language-c">static int dictGenericDelete(dict *d, const void *key, int nofree){    unsigned int h, idx;    dictEntry *he, *prevHe;    int table;     /* d-&gt;ht[0].table is NULL */    if (d-&gt;ht[0].size == 0) return DICT_ERR;    if (dictIsRehashing(d)) _dictRehashStep(d); // 执行渐进式 rehash    h = dictHashKey(d, key);    for (table = 0; table &lt;= 1; table++) {idx = h &amp; d-&gt;ht[table].sizemask;        he = d-&gt;ht[table].table[idx];        prevHe = NULL;        while(he) {if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) { // 找到这个 key                if (prevHe) // 是不是该 hash slot 的第一个元素                    prevHe-&gt;next = he-&gt;next;                else                    d-&gt;ht[table].table[idx] = he-&gt;next;                if (!nofree) {dictFreeKey(d, he);                    dictFreeVal(d, he);                }                zfree(he);                d-&gt;ht[table].used--;                return DICT_OK;            }            prevHe = he;            he = he-&gt;next;        }        if (!dictIsRehashing(d)) break;    }    return DICT_ERR; /* not found */}</code></pre><h5 id="遍历元素">遍历元素</h5><p><code>dictScan</code> 这个函数是 <code>dict</code> 结构最有特色的一个函数。用来遍历 <code>dict</code>，主要是要考虑扩缩容的情况。</p><pre><code class="language-c">unsigned long dictScan(dict *d,                       unsigned long v,                       dictScanFunction *fn,                       void *privdata){    dictht *t0, *t1;    const dictEntry *de;    unsigned long m0, m1;    if (dictSize(d) == 0) return 0;    if (!dictIsRehashing(d)) {// 不在 rehash，直接扫描 ht[0] 就好了        t0 = &amp;(d-&gt;ht[0]);        m0 = t0-&gt;sizemask;        /* Emit entries at cursor */        de = t0-&gt;table[v &amp; m0];        while (de) { // 扫描完这个 slot，因为可能是链表            fn(privdata, de);            de = de-&gt;next;        }    } else {// 正在 rehashing，就存在两个哈希表 ht[0]、ht[1]        t0 = &amp;d-&gt;ht[0];        t1 = &amp;d-&gt;ht[1];        // 确保 t0 比 t1 小        if (t0-&gt;size &gt; t1-&gt;size) {t0 = &amp;d-&gt;ht[1];            t1 = &amp;d-&gt;ht[0];        }        m0 = t0-&gt;sizemask;        m1 = t1-&gt;sizemask;        de = t0-&gt;table[v &amp; m0];// 扫描 t0 的某个 slot        while (de) {fn(privdata, de);            de = de-&gt;next;        }        // 迭代(大表)t1 中所有节点，循环迭代，会把小表没有覆盖的 slot 全部扫描一遍        // 同模的 slot        do {            /* Emit entries at cursor */            de = t1-&gt;table[v &amp; m1];            while (de) {fn(privdata, de);                de = de-&gt;next;            }            /* Increment bits not covered by the smaller mask */            // 新增加的 bits 位每次加一            v = (((v | m0) + 1) &amp; ~m0) | (v &amp; m0);        } while (v &amp; (m0 ^ m1)); // 直到新加的 bits 都遍处理完了    }    v |= ~m0;    /* Increment the reverse cursor */    v = rev(v);    v++;    v = rev(v);    return v;}</code></pre><p>redis 采用了一种高位进位的方式来遍历哈希桶，而不是传统的加 1。以 size 为 8 为例，遍历顺序是这样的：000 -&gt; 100 -&gt; 010 -&gt; 110 -&gt; 001 -&gt; 101 -&gt; 011 -&gt; 111。可以看到，每次都是最到位加 1，向低位去进位，正好跟我们平常的运算相反，因此，这也叫 <strong> 反向二进制位迭代</strong>。</p><p>具体原理可以参考 <a href="https://tech.meituan.com/Redis_Rehash_Practice_Optimization.html" target="_blank" rel="noopener">《美团针对 Redis Rehash 机制的探索和实践》</a>，同时该文章也指出了该算法的一个 bug，并提供的修复方案。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 中的事件</title>
    <link href="/85f7b0b4.html"/>
    <url>/85f7b0b4.html</url>
    
    <content type="html"><![CDATA[<p>每个 CS 模式程序，尤其是高并发的网络服务端程序都有自己的网络异步事件处理库，Redis 不例外。Redis 基于 <a href="https://my.oschina.net/mjRao/blog/666033" target="_blank" rel="noopener">Reactor 模型 </a> 封装了自己的事件驱动模型库。你可能会跟我有一样的疑问，为什么作者不使用已有的成熟的相关库，比如 Libevent 或 Libev？作者是<a href="https://groups.google.com/forum/#!topic/redis-db/tSgU6e8VuNA" target="_blank" rel="noopener"> 这样 </a> 跟别人讨论的，感兴趣的可以了解下。<br>下面从源码入手介绍下 Redis 中封装的 ae 库。</p><a id="more"></a><h3 id="Redis- 中的 -I-O- 多路复用">Redis 中的 I/O 多路复用</h3><p>Redis 的 I/O 多路复用函数库对常见的 select/epoll/evport/kqueue 等进行了封装，提高了易用性。每一个 I/O 多路复用函数库在 Redis 源码中都单独成一个个文件，因此你可以找到 ae_epoll.c 等文件，它们对外提供统一的 API，这样做有一个好处是，底层库可以互换。<br>Redis 在底层用哪个 I/O 多路复用函数库是在编译时决定的，源码中定义了如下的规则，</p><pre><code class="language-c">#ifdef HAVE_EVPORT#include &quot;ae_evport.c&quot;#else    #ifdef HAVE_EPOLL    #include &quot;ae_epoll.c&quot;    #else        #ifdef HAVE_KQUEUE        #include &quot;ae_kqueue.c&quot;        #else        #include &quot;ae_select.c&quot;s        #endif    #endif#endif</code></pre><p>该规则保证在编译时会自动选择系统中性能最高的 I/O 多路复用函数库作为其 I/O 多路复用程序的底层实现。绝大多数的 Redis 服务都跑在 linux 服务器上，因此用的是 epoll。<br>大家都知道，epoll 常用函数主要有以下 3 个：</p><pre><code class="language-c">#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);</code></pre><p>与之相对，在 ae_epoll.c 文件中对这三个函数进行了相应的封装（主要是配合 <code>aeEventLoop</code>）</p><pre><code class="language-c">// 获得 epfd 以及为 aeEventLoop 结构体创建 aeApiStatestatic int aeApiCreate(aeEventLoop *eventLoop) {aeApiState *state = zmalloc(sizeof(aeApiState));    if (!state) return -1;    state-&gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-&gt;setsize);    if (!state-&gt;events) {zfree(state);        return -1;    }    state-&gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */    if (state-&gt;epfd == -1) { // 出错释放        zfree(state-&gt;events);        zfree(state);        return -1;    }    eventLoop-&gt;apidata = state;    return 0;}</code></pre><pre><code class="language-c">// 为 fpfd 添加监控 fd 感兴趣的事件static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {    aeApiState *state = eventLoop-&gt;apidata;    struct epoll_event ee = {0}; /* avoid valgrind warning */    /* If the fd was already monitored for some event, we need a MOD     * operation. Otherwise we need an ADD operation. */    int op = eventLoop-&gt;events[fd].mask == AE_NONE ?            EPOLL_CTL_ADD : EPOLL_CTL_MOD;    ee.events = 0;    mask |= eventLoop-&gt;events[fd].mask; /* Merge old events */    if (mask &amp; AE_READABLE) ee.events |= EPOLLIN;    if (mask &amp; AE_WRITABLE) ee.events |= EPOLLOUT;    ee.data.fd = fd;    if (epoll_ctl(state-&gt;epfd,op,fd,&amp;ee) == -1) return -1;    return 0;}</code></pre><pre><code class="language-c">// epoll_waitstatic int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {    aeApiState *state = eventLoop-&gt;apidata; // 这里的 aeApiState 为 aeApiCreate 时创建的    int retval, numevents = 0;    retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize,            tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1);    if (retval &gt; 0) {        int j;        numevents = retval;        // 遍历产生的事件，加入 eventLoop-&gt;fired 数组        for (j = 0; j &lt; numevents; j++) {            int mask = 0;            struct epoll_event *e = state-&gt;events+j;            // 根据事件不同设置不同的 mask            if (e-&gt;events &amp; EPOLLIN) mask |= AE_READABLE;            if (e-&gt;events &amp; EPOLLOUT) mask |= AE_WRITABLE;            if (e-&gt;events &amp; EPOLLERR) mask |= AE_WRITABLE;            if (e-&gt;events &amp; EPOLLHUP) mask |= AE_WRITABLE;            eventLoop-&gt;fired[j].fd = e-&gt;data.fd;            eventLoop-&gt;fired[j].mask = mask;        }    }    return numevents;}</code></pre><p>看起来很简单，感兴趣的小伙伴可以看看 select 等其他底层库的封装。</p><h3 id="Redis- 中的事件">Redis 中的事件</h3><p>Redis 是事件驱动的程序，服务器需要处理文件事件 (file event) 和时间事件(time event)，其中各结构体关系如下：<br><img src="https://s1.ax1x.com/2018/10/28/icw25T.jpg" srcset="/img/loading.gif" width="800" /><br>可以看到事件处理的核心是 <code>aeEventLoop</code>，它的作用是负责保存待处理文件事件和时间事件的结构体。</p><p>那么，下面先介绍 Redis 中的两种事件。</p><h4 id="文件事件">文件事件</h4><p><strong>文件事件是 Redis 服务器对套接字操作的抽象</strong>。<br>服务器通过套接字与客户端进行连接，服务器与客户端的通信会产生相应的文件事件。<br>Redis 中使用 I/O 多路复用程序同时监听多个 socket，然后 socket 中做的不同操作关联不同的事件处理器，即采用不用的处理逻辑。<br>当客户端 connect server 时，即有新的连接到来，此时在服务器 listen socket fd 上产生 <code>ae.h/AE_READABLE</code> 事件，该事件由 <code>acceptTcpHandler</code> 函数进行处理。<br>当客户端有数据写到 socket 时，client fd 上产生<code>ae.h/AE_READABLE</code> 事件，该事件由 <code>readQueryFromClient</code> 函数进行处理。<br>当 sever 给 client 回复时，client fd 产生 <code>ae.h/AE_WRITABLE</code> 事件，该事件由 <code>sendReplyToClient</code> 函数进行处理。<br>而对于所有的文件事件，在事件处理器 <code>aeProcessEvents</code> 中都有如下处理逻辑：</p><pre><code class="language-c"> // 阻塞等待，返回就绪文件事件的个数numevents = aeApiPoll(eventLoop, tvp);for (j = 0; j &lt; numevents; j++) {aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];    int mask = eventLoop-&gt;fired[j].mask;    int fd = eventLoop-&gt;fired[j].fd;    int rfired = 0;    if (fe-&gt;mask &amp; mask &amp; AE_READABLE) { // read 处理        rfired = 1;        fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);    }    if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) { // write 处理        if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc)            fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);    }    processed++; // 处理的事件数 + 1}</code></pre><h4 id="事件处理与调度">事件处理与调度</h4><p>包含对文件事件和时间事件的处理，其实都收敛到 <code>aeProcessEvents</code> 这个函数。</p><p>在 <a href="https://draveness.me/redis-eventloop" target="_blank" rel="noopener"> 网上 </a> 找了一个图可以很好的说明这个过程<br><img src="https://s1.ax1x.com/2018/10/28/icwfGF.jpg" srcset="/img/loading.gif" width="650" /></p><p>在时间处理器中有这样一个逻辑:</p><pre><code class="language-c">// 找出最近要发生的那个时间事件shortest = aeSearchNearestTimer(eventLoop);... ... // 阻塞等待，返回就绪文件事件的个数numevents = aeApiPoll(eventLoop, tvp);</code></pre><p>将最近要发生的时间事件的时间作为 <code>aeApiPoll</code> 函数的最大阻塞时间，这既可以避免服务器对时间事件进行频繁的轮询（忙等待），也可以确保该函数不会阻塞过长时间。</p><p><strong>注意</strong>：<br>事件可能是并发产生的，但是到了时间处理器这里都变成串行处理了；<br>时间事件并不一定是按照预设的时间点发生，会有偏差。</p><h4 id="时间事件">时间事件</h4><p><strong>时间事件时服务器对一些定时或者周期任务的抽象</strong>。<br>分为两类，定时事件和周期事件。两类事件可以根据时间事件处理器 <code>processTimeEvents</code> 中时间事件处理函数 <code>timeProc</code> 绑定的具体函数返回结果来区分。如果返回值为 <code>AE_NOMORE</code>，则表示这是个一次性的时间事件，否则表明是个周期任务。<br>对此，在事件处理器 <code>aeProcessEvents</code> 如下处理逻辑：</p><pre><code class="language-c">if (flags &amp; AE_TIME_EVENTS) // 处理时间事件    processed += processTimeEvents(eventLoop);</code></pre><p>进到 <code>processTimeEvents</code>里去看，会遍历每一个时间事件，然后执行以下逻辑：</p><pre><code class="language-c">aeGetTime(&amp;now_sec, &amp;now_ms);if (now_sec &gt; te-&gt;when_sec ||    (now_sec == te-&gt;when_sec &amp;&amp; now_ms &gt;= te-&gt;when_ms))  // 时间事件过时，需要执行{    int retval;    id = te-&gt;id;    retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData);    processed++;    if (retval != AE_NOMORE) { // 周期任务        aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms);    } else { // 一次性时间事件，标记成 AE_DELETED_EVENT_ID，从 epfd 的监控中删掉        te-&gt;id = AE_DELETED_EVENT_ID;    }}</code></pre><p>从时间事件的结构体也可以看出，Redis 中将时间事件串成一个无序链表，说无序是因为该链表对各个时间事件的发生顺序是乱的。</p><blockquote><p>在目前版本中，正常模式下的 Redis 服务器只使用了 <code>serverCron</code> 一个时间事件，而在 benchmark 模式下，服务器也值使用了两个时间事件。在这种情况下，服务器几乎是将无序链表退化成一个指针来使用，因此不影响时间事件执行的性能。</p></blockquote><h3 id="Redis- 服务流程">Redis 服务流程</h3><p>将 Redis 源码主流程简化，其实就是下面这样，</p><pre><code class="language-c">int main(int argc, char **argv) {    ...    initServer();    ...    aeSetBeforeSleepProc(server.el,beforeSleep);    aeMain(server.el); // 陷入循环，等待外部事件发生    aeDeleteEventLoop(server.el);    return 0;}</code></pre><p>而在 <code>aeMain </code> 函数中则是一个大循环，该循环一直到 <code>eventLoop-&gt;stop</code> 被标记成非 0 才会停止，如下，</p><pre><code class="language-c">void aeMain(aeEventLoop *eventLoop) {    eventLoop-&gt;stop = 0;    while (!eventLoop-&gt;stop) {if (eventLoop-&gt;beforesleep != NULL)            eventLoop-&gt;beforesleep(eventLoop);        aeProcessEvents(eventLoop, AE_ALL_EVENTS); // 事件（文件 | 时间）处理函数    }}</code></pre><p>在初始化 <code>initServer</code> 函数中会创建一个 <code>aeEventLoop</code> 结构体，如下，</p><pre><code class="language-c">server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);</code></pre><p><code>maxclients</code> 为配置文件中配置的可接受最大连接数。</p><h3 id="参考">参考</h3><p>【1】《Redis 设计与实现》<br>【2】<a href="https://draveness.me/redis-eventloop" target="_blank" rel="noopener">https://draveness.me/redis-eventloop</a></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 基本数据结构之双向链表</title>
    <link href="/ba6bb8e7.html"/>
    <url>/ba6bb8e7.html</url>
    
    <content type="html"><![CDATA[<blockquote><p> 链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。</p></blockquote><p> 链表是一种非常常见的数据结构。由于 redis 使用的 C 语言并没有这种数据结构，因此，作者在 redis 对这一数据结构进行了实现。redis 的链表实现为双向链表，主要用在实现列表键、发布订阅、保存多客户端状态、服务器模块，订阅模块和保存输入命令等方面，使用较广。</p><a id="more"></a><p>redis 源码中关于 adlist 的部分，主要在 <code>adlist.h</code> 和 <code>adlist.c</code> 这两个文件中。</p><h3 id="adlist- 的定义">adlist 的定义 </h3><p> 首先在 <code>adlist.h</code> 中找到定义 </p><pre><code class="language-c">// list 节点typedef struct listNode {    // 前驱节点    struct listNode *prev;    // 后继节点    struct listNode *next;    // 节点值    void *value;} listNode;// redis 双链表实现typedef struct list {    listNode *head;                      // 表头指针    listNode *tail;                      // 表尾指针    void *(*dup)(void *ptr);             // 节点值复制函数    void (*free)(void *ptr);             // 节点值释放函数（函数指针）    int (*match)(void *ptr, void *key);  // 节点值对比函数    unsigned long len;                   // 链表包含的节点数量} list;</code></pre><p> 可以发现，这就是一个无环双向链表。<br><code>list</code> 结构中带有一个 <code>len</code> 的变量，可以将获取链表长度的时间复杂度从 O(n) 降到 O(1)。<br><code>head</code> 指针和 <code>tail</code> 指针让给我们可以快速的找到链表的头尾，时间复杂度都是 O(1)。<br>三个函数指针，让我们可以对链表有更灵活的操作，使用起来也更加方便。</p><p> 当需要进行链表迭代时，可以使用如下函数：</p><pre><code class="language-c">typedef struct listIter {    listNode *next; // 指向下一个节点    int direction;  // 迭代器，正向反向} listIter;</code></pre><p><code>direction</code> 决定了遍历的方向，可正向可反向。</p><h3 id="adlist- 宏定义">adlist 宏定义 </h3><p> 这部分定义了一些获取 <code>list</code> 结构的宏，简化操作。</p><pre><code class="language-c">#define listLength(l) ((l)-&gt;len)                    // 获取 list 中包含的 node 数量#define listFirst(l) ((l)-&gt;head)                    // 获取 list 头节点指针#define listLast(l) ((l)-&gt;tail)                     // 获取 list 尾节点指针#define listPrevNode(n) ((n)-&gt;prev)                 // 获取当前节点的前驱节点#define listNextNode(n) ((n)-&gt;next)                 // 获得当前节点的后继节点#define listNodeValue(n) ((n)-&gt;value)#define listSetDupMethod(l,m) ((l)-&gt;dup = (m))      // 指定节点复制函数#define listSetFreeMethod(l,m) ((l)-&gt;free = (m))    // 指定节点释放函数#define listSetMatchMethod(l,m) ((l)-&gt;match = (m))  // 指定节点的比较函数#define listGetDupMethod(l) ((l)-&gt;dup)   // 获得节点复制函数#define listGetFree(l) ((l)-&gt;free)#define listGetMatchMethod(l) ((l)-&gt;match)</code></pre><h3 id="adlist- 函数">adlist 函数 </h3><p> 这部分定义了一些双向链表的常用操作。</p><pre><code class="language-c">list *listCreate(void); // 创建一个不包含任何节点的新链表void listRelease(list *list); // 释放给定链表，以及链表中的所有节点// CRUD 操作list *listAddNodeHead(list *list, void *value);  // 头部插入节点list *listAddNodeTail(list *list, void *value);  // 尾部插入节点list *listInsertNode(list *list, listNode *old_node, void *value, int after); // 中间某个位置插入节点void listDelNode(list *list, listNode *node); // O(N) 删除指定节点listIter *listGetIterator(list *list, int direction); // 获取指定迭代器void listReleaseIterator(listIter *iter);   // 释放迭代器listNode *listNext(listIter *iter); // 迭代下一个节点list *listDup(list *orig); // 链表复制listNode *listSearchKey(list *list, void *key); // O(N) 按 key 找节点listNode *listIndex(list *list, long index);  // O(N)void listRewind(list *list, listIter *li); // 重置为正向迭代器void listRewindTail(list *list, listIter *li); // 重置为逆向迭代器void listRotate(list *list); // 链表旋转</code></pre><h4 id="创建 -adlist"> 创建 adlist</h4><pre><code class="language-c">list *listCreate(void){    struct list *list;    if ((list = zmalloc(sizeof(*list))) == NULL)        return NULL;    list-&gt;head = list-&gt;tail = NULL;    list-&gt;len = 0;    list-&gt;dup = NULL;    list-&gt;free = NULL;    list-&gt;match = NULL;    return list;}</code></pre><p> 创建一个空的 adlist 很简单，就是分配内存，初始化数据结构，而 <code>listRelease</code> 的释放链表过程与之相反，这个自不必多说。</p><h4 id="adlist- 的 -CRUD- 操作">adlist 的 CRUD 操作 </h4><p> 首先是插入数据，分三种情况：头部插入、中间插入和尾部插入。<br>(1) 头部插入 </p><pre><code class="language-c">// 头部插入值 valuelist *listAddNodeHead(list *list, void *value){    listNode *node;    if ((node = zmalloc(sizeof(*node))) == NULL) // 为新节点分配内存        return NULL;    node-&gt;value = value;    if (list-&gt;len == 0) { // 若之前的 list 为空，那么插入后就只有一个节点        list-&gt;head = list-&gt;tail = node;        node-&gt;prev = node-&gt;next = NULL;    } else {        node-&gt;prev = NULL;        node-&gt;next = list-&gt;head;        list-&gt;head-&gt;prev = node;        list-&gt;head = node; // 更新 list head 信息    }    list-&gt;len++; // 更新链表长度信息    return list;}</code></pre><p>（2）尾部插入节点类似，就不啰嗦了。<br>（3）中间插入 </p><pre><code class="language-c">// 在 list 指定节点 old_node 后（after=1）或前插入一个节点list *listInsertNode(list *list, listNode *old_node, void *value, int after) {    listNode *node;    if ((node = zmalloc(sizeof(*node))) == NULL) // 为新节点分配内存        return NULL;    node-&gt;value = value;    if (after) { // 后        // 处理 node 节点的前后指向        node-&gt;prev = old_node;        node-&gt;next = old_node-&gt;next;        if (list-&gt;tail == old_node) { // node 成了尾节点，更新 list 信息            list-&gt;tail = node;        }    } else { // 前        node-&gt;next = old_node;        node-&gt;prev = old_node-&gt;prev;        if (list-&gt;head == old_node) { // node 成了头节点，更新 list 信息            list-&gt;head = node;        }    }    // 处理 node 相邻两个节点的指向    if (node-&gt;prev != NULL) {node-&gt;prev-&gt;next = node;}    if (node-&gt;next != NULL) {node-&gt;next-&gt;prev = node;}    list-&gt;len++;    return list;}</code></pre><p> 然后是删除操作。</p><pre><code class="language-c">// 从 list 中删除 node 节点void listDelNode(list *list, listNode *node){if (node-&gt;prev) // 是否有前驱节点，即判断要删除的节点是否为头节点        node-&gt;prev-&gt;next = node-&gt;next;    else        list-&gt;head = node-&gt;next; // 更新 list 的头结点指向    if (node-&gt;next) // 是否有后继节点，即判断要删除的节点是否为尾节点        node-&gt;next-&gt;prev = node-&gt;prev;    else        list-&gt;tail = node-&gt;prev;    if (list-&gt;free) list-&gt;free(node-&gt;value);    zfree(node);    list-&gt;len--; // 更新节点数量信息}</code></pre><p> 最后是查找。</p><pre><code class="language-c">// 从 list 中查找 keylistNode *listSearchKey(list *list, void *key){    listIter iter;    listNode *node;    listRewind(list, &amp;iter); // 获得正向遍历器，并从头开始遍历    while((node = listNext(&amp;iter)) != NULL) {if (list-&gt;match) { // list 中有指定的比较器            if (list-&gt;match(node-&gt;value, key)) {return node;}        } else {if (key == node-&gt;value) {return node;}        }    }    return NULL;}</code></pre><pre><code class="language-c">// 获得 list 中第 index 个节点，index 为负数表示从尾部倒序往前找listNode *listIndex(list *list, long index) {    listNode *n;    if (index &lt; 0) { // 从尾部查找        index = (-index)-1;        n = list-&gt;tail;        while(index-- &amp;&amp; n) n = n-&gt;prev; // 往前遍历    } else {        n = list-&gt;head;        while(index-- &amp;&amp; n) n = n-&gt;next; // 往后遍历    }    return n;}</code></pre><h4 id="其他"> 其他 </h4><p> 迭代器实现如下：</p><pre><code class="language-c">listIter *listGetIterator(list *list, int direction){    listIter *iter;    if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL;    if (direction == AL_START_HEAD)        iter-&gt;next = list-&gt;head;    else        iter-&gt;next = list-&gt;tail;    iter-&gt;direction = direction; // 迭代器方向    return iter;}</code></pre><p> 另外，一个旋转 list 的操作，实现效果将 1 → 2 → 3 → 4 变成 4 → 1 → 2 → 3</p><pre><code class="language-c">void listRotate(list *list) {    listNode *tail = list-&gt;tail;// 取尾节点    if (listLength(list) &lt;= 1) return; // 1 个节点不需要 rotate    /* Detach current tail 分离尾部节点 */    list-&gt;tail = tail-&gt;prev;    list-&gt;tail-&gt;next = NULL;    /* Move it as head 转移到 head */    list-&gt;head-&gt;prev = tail;    tail-&gt;prev = NULL;    tail-&gt;next = list-&gt;head;    list-&gt;head = tail; // 更新 list 的新 head}</code></pre><h3 id="总结"> 总结 </h3><p>adlist 其实就是把双向链表的基本操作实现了一遍，看了一遍相当于复习了一遍（之前面试总问这些，哈哈），不过作者设计的很巧，值得学习。</p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>dstat 工具使用</title>
    <link href="/fe52c850.html"/>
    <url>/fe52c850.html</url>
    
    <content type="html"><![CDATA[<p><strong>Dstat</strong> 是一个多样化的资源统计工具。<a href="http://dag.wiee.rs/home-made/dstat/" target="_blank" rel="noopener">官网 </a> 上是这么说的，感受一下：</p><blockquote><p>Dstat is a versatile replacement for vmstat, iostat, netstat and ifstat. Dstat overcomes some of their limitations and adds some extra features, more counters and flexibility. Dstat is handy for monitoring systems during performance tuning tests, benchmarks or troubleshooting.<br>Dstat allows you to view all of your system resources in real-time, you can eg. compare disk utilization in combination with interrupts from your IDE controller, or compare the network bandwidth numbers directly with the disk throughput (in the same interval).</p></blockquote><a id="more"></a><p>dstat 将以列表的形式为你提供选项信息并清晰地告诉你是在何种幅度和单位显示输出。这样更好地避免了信息混乱和误报。更重要的是，它可以让你更容易编写插件来收集你想要的数据信息，以从未有过的方式进行扩展。</p><p>Dstat 的默认输出是专门为人们实时查看而设计的，不过你也可以将详细信息通过 CSV 输出到一个文件，并导入到 Gnumeric 或者 Excel 生成表格中。</p><h3 id="特点">特点</h3><ul><li>Combines <strong>vmstat</strong>, <strong>iostat</strong>, <strong>ifstat</strong>, <strong>netstat</strong> information and more</li><li>Shows stats in exactly the same timeframe</li><li>Enable/order counters as they make most sense during analysis/troubleshooting</li><li>Modular design</li><li>Written in <strong>python</strong> so easily extendable for the task at hand</li><li>Easy to extend, add your own counters (please contribute those)</li><li>Includes many external plugins to show how easy it is to add counters</li><li>Can summarize grouped block/network devices and give total numbers</li><li>Can show interrupts per device</li><li>Very accurate timeframes, no timeshifts when system is stressed</li><li>Shows exact units and limits conversion mistakes</li><li>Indicate different units with different colors</li><li>Show intermediate results when delay &gt; 1</li><li>Allows to export CSV output, which can be imported in Gnumeric and Excel to make graphs</li></ul><p>以上的特点是从官网扒下来的，可以参考一下。</p><h3 id="安装">安装</h3><p>centos 可以直接使用如下命令安装：</p><pre><code>yum install dstat</code></pre><h3 id="外部插件">外部插件</h3><pre><code class="language-shell">[root@pandora ~]# dstat --listinternal:aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, vm/usr/share/dstat:battery, battery-remain, cpufreq, dbus, disk-util, fan, freespace, gpfs, gpfs-ops, helloworld, innodb-buffer, innodb-io, innodb-ops, lustre, memcache-hits, mysql-io, mysql-keys, mysql5-cmds,mysql5-conn, mysql5-io, mysql5-keys, net-packets, nfs3, nfs3-ops, nfsd3, nfsd3-ops, ntp, postfix, power, proc-count, rpc, rpcd, sendmail, snooze, thermal, top-bio, top-cpu, top-cputime, top-cputime-avg,top-io, top-latency, top-latency-avg, top-mem, top-oom, utmp, vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, vz-ubc, wifi</code></pre><p>通过 <code>dstat --list</code> 可以查看 dstat 能使用的所有参数，其中上面 internal 是 dstat 本身自带的一些监控参数，下面 <code>/usr/share/dstat</code>中是 dstat 的插件，这些插件可以扩展 dstat 的功能，如可以监控电源（battery）、mysql 等。<br>下面这些插件并不是都可以直接使用的，有的还依赖其他包，如想监控 mysql，必须要装 python 连接 mysql 的一些包。</p><h3 id="用例">用例</h3><p>用法可以用 <code>-h</code> 选项看下，或者 <code>man dstat</code> 查一下。我执行了一下，大概是这样的：</p><pre><code class="language-shell">[root@pandora ~]# dstat -hUsage: dstat [-afv] [options..] [delay [count]]Versatile tool for generating system resource statisticsDstat options:  -c, --cpu              enable cpu stats     -C 0,3,total           include cpu0, cpu3 and total  -d, --disk             enable disk stats     -D total,hda           include hda and total  -g, --page             enable page stats  -i, --int              enable interrupt stats     -I 5,eth2              include int5 and interrupt used by eth2  -l, --load             enable load stats  -m, --mem              enable memory stats  -n, --net              enable network stats     -N eth1,total          include eth1 and total  -p, --proc             enable process stats  -r, --io               enable io stats (I/O requests completed)  -s, --swap             enable swap stats     -S swap1,total         include swap1 and total  -t, --time             enable time/date output  -T, --epoch            enable time counter (seconds since epoch)  -y, --sys              enable system stats  --aio                  enable aio stats  --fs, --filesystem     enable fs stats  --ipc                  enable ipc stats  --lock                 enable lock stats  --raw                  enable raw stats  --socket               enable socket stats  --tcp                  enable tcp stats  --udp                  enable udp stats  --unix                 enable unix stats  --vm                   enable vm stats  --plugin-name          enable plugins by plugin name (see manual)  --list                 list all available plugins  -a, --all              equals -cdngy (default)  -f, --full             automatically expand -C, -D, -I, -N and -S lists  -v, --vmstat           equals -pmgdsc -D total  --bw, --blackonwhite   change colors for white background terminal  --float                force float values on screen  --integer              force integer values on screen  --nocolor              disable colors (implies --noupdate)  --noheaders            disable repetitive headers  --noupdate             disable intermediate updates  --output file          write CSV output to filedelay is the delay in seconds between each update (default: 1)count is the number of updates to display before exiting (default: unlimited)</code></pre><p>直接执行 <code>dstat</code> 这个命令，默认选项是 <code>-cdngy</code>，1s 显示一条信息。可以在最后指定显示一条信息的时间间隔，如 <code>dstat 5</code> 是每 5s 显示一条，<code>dstat 5 10</code>表示每 5s 显示一条，一共显示 10 条。</p><p>一个可能的输出如下：</p><pre><code class="language-shell">[root@pandora ~]# dstat----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw  3   4  92   0   0   0| 135k 4182k|   0     0 |  52k   86k|  20k   50k  4   3  93   0   0   0|   0  3668k|5873B 5436B|   0   120k|  30k   51k  4   3  93   0   0   0|   0  3632k|6040B 4520B|   0   100k|  32k   55k  4   3  93   0   0   0|4096B 3832k|3274B 1574B|   0    72k|  30k   50k  4   3  93   0   0   0|   0  3644k|3404B 1654B|   0   120k|  33k   57k</code></pre><p>可以看到的统计项有以下几个：<br><code>-c</code> 选项。CPU 状态：从左到右依次是用户 / 系统 / 空闲部分的 cpu 占比，wait，硬 / 软中断次数。<br><code>-d</code> 选项。磁盘状态：磁盘的读写操作，这一栏显示磁盘的读、写总数。<br><code>-n</code> 选项。网络状态：网络设备发送和接受的数据。<br><code>-g</code> 选项。页面状态：系统的分页活动，分页指的是一种内存管理技术用于查找系统场景，一个较大的分页表明系统正在使用大量的交换空间，或者说内存非常分散，大多数情况下你都希望看到 page in（换入）和 page out（换出）的值是 0。<br><code>-y</code> 选项。系统统计：中断（int）和上下文切换（csw）数量。较高的值通常表示大量的进程造成拥塞，需要对 CPU 进行关注。</p><h3 id="常用选项">常用选项</h3><p><code>--socket</code> 显示常用的 socket 统计<br><code>--tcp</code> 显示常用的 TCP 统计<br><code>--mem</code> 显示内存使用率<br><code>--io</code> 显示 I/O 统计<br><code>--int</code> 显示终端统计</p><p><code>--disk-util</code> 显示某一时间磁盘的忙碌状况<br><code>--freespace</code> 显示当前磁盘空间使用率<br><code>--proc-count</code> 显示正在运行的程序数量<br><code>--top-bio</code> 指出块 I/O 最大的进程<br><code>--top-cpu</code> 图形化显示 CPU 占用最大的进程<br><code>--top-io</code> 显示正常 I/O 最大的进程<br><code>--top-mem</code> 显示占用最多内存的进程</p><p>一个可能的输出如下：</p><pre><code class="language-shell">[root@pandora ~]# dstat --tcp --io --top-cpu --top-io --mem --top-mem----tcp-sockets---- --io/total- -most-expensive- ----most-expensive---- ------memory-usage----- --most-expensive-lis act syn tim clo| read  writ|  cpu process   |     i/o process      | used  buff  cach  free|  memory process 12  29   0   0   0|4.93  46.2 |codis-config 0.0|sshd        102k   46k|38.7G  333M 60.4G  152G|java         183M 12  29   0   0   0|   0  27.0 |irqbalance   0.0|irqbalance   48k    0 |38.7G  333M 60.4G  152G|java         183M 12  29   0   0   0|   0  4.00 |codis-config 0.0|redis-serve  34k   47B|38.7G  333M 60.4G  152G|java         183M 12  29   0   0   0|   0  1.00 |bin/codis-con0.0|redis-serve  34k   54B|38.7G  333M 60.3G  152G|java         183M</code></pre>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shell</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>irqbalance 详解之一</title>
    <link href="/211b84d9.html"/>
    <url>/211b84d9.html</url>
    
    <content type="html"><![CDATA[<p>irqbalance 是什么？<a href="https://github.com/Irqbalance/irqbalance" target="_blank" rel="noopener">项目主页 </a> 上有以下描述：</p><blockquote><p>Irqbalance is a daemon to help balance the cpu load generated by interrupts across all of a systems cpus.</p></blockquote><a id="more"></a><p>它避免了单 cpu 负载过重情况的出现。用法如下：</p><pre><code>root@a7661ef9b2f8 test]# irqbalance -hirqbalance: option requires an argument -- 'h'irqbalance [--oneshot | -o] [--debug | -d] [--foreground | -f] [--hintpolicy= | -h [exact|subset|ignore]] [--banscript= | -b &lt;script&gt;][--powerthresh= | -p &lt;off&gt; | &lt;n&gt;] [--banirq= | -i &lt;n&gt;] [--policyscript= | -l &lt;script&gt;] [--pid= | -s &lt;file&gt;] [--deepestcache= | -c &lt;n&gt;]</code></pre><pre><code># 查看当前运行情况service irqbalance status# 终止服务service irqbalance stop</code></pre><hr><p>首先有一些前置知识需要说明，这涉及到 irqbalance cputree 的分层。</p><h3 id="前置知识">前置知识</h3><h4 id="中断">中断</h4><p>每个硬件设备都需要和 CPU 有某种形式的通信以便 CPU 及时知道发生了什么，这样 CPU 可能就会放下手中的事情去处理应急事件，硬件设备主动打扰 CPU 的现象就可称为硬件中断。就像正在一心一意的写代码时，突然钉钉“噔噔”地响起来，这时我们就知道有事情需要处理，这里的“噔噔”声就可以理解成一次中断。<br>CPU 和硬件沟通的方式中，还有一种叫做轮询（polling），就是让 CPU 定时对硬件状态进行查询然后做相应处理，这比较浪费 CPU，属于一种硬件被动的方式。相比下来，硬件主动的方式（中断）更有效一些。<br>那每个硬件设备都有中断，很简单啊，给它们分个唯一的号码，也就是 irq 号，在 <code>/proc/interrupts</code> 文件中的第一列可以看到所有的 irq。<br>只有 kernel 2.4 以后的版本才支持的把不同的硬件中断请求（IRQs）分配到特定的 CPU 上的绑定技术被称为 SMP IRQ Affinity，这个后面还会详细说。</p><h4 id="NUMA 架构">NUMA 架构</h4><p>简要介绍一下 NUMA 架构。<br>NUMA 架构出现前，CPU 频率一路欢脱越来越高，直至碰到物理极限的天花板，后转向核数越来越多的方向发展。</p><blockquote><p>如果每个 core 的工作性质都是 share-nothing（类似于 map-reduce 的 node 节点的作业属性），那么也许就不会有 NUMA。由于所有 CPU Core 都是通过共享一个北桥来读取内存，随着核数如何的发展，<strong>北桥</strong> 在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器（原本北桥中读取内存的部分）也做个拆分，平分到了每个 die 上。于是 NUMA 就出现了！<br>NUMA 架构中，内存访问有远近之分，只有当 CPU 访问自身直接 attach 内存对应的物理地址时，才会有较短的响应时间（Local Access）。而如果需要访问其他 CPU attach 的内存的数据时，就需要通过 inter-connect 通道访问，响应时间就相比之前变慢了（Remote Access），NUMA（Non-Uniform Memory Access）就此得名。    — 引自 <a href="http://cenalulu.github.io/linux/numa/" target="_blank" rel="noopener">http://cenalulu.github.io/linux/numa/</a></p></blockquote><p>图画下来大概是下面这个样子：<br><img src="https://s1.ax1x.com/2018/10/28/icwcV0.jpg" srcset="/img/loading.gif" width="600" /></p><p><code>numactl --hardware</code> 命令可以查看的那个机器的 numa 拓扑，比如这台机器：</p><pre><code>[root@d2b9eb755bb1 ~]# numactl --hardwareavailable: 2 nodes (0-1)node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 24 25 26 27 28 29 30 31 32 33 34 35node 0 size: 130946 MBnode 0 free: 9892 MBnode 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23 36 37 38 39 40 41 42 43 44 45 46 47node 1 size: 131072 MBnode 1 free: 35969 MBnode distances:node   0   1  0:  10  21  1:  21  10</code></pre><p>或者用这个脚本也行:</p><pre><code>[root@d2b9eb755bb1 ~]# for i in `ls /sys/devices/system/node | grep node`;do echo -ne &quot;$i\t&quot;;cat /sys/devices/system/node/$i/cpulist;donenode00-11,24-35node112-23,36-47</code></pre><p>或者用 <code>lscpu</code> 这个命令，</p><pre><code>[root@d2b9eb755bb1 ~]# lscpuArchitecture:          x86_64CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                48On-line CPU(s) list:   0-47Thread(s) per core:    2Core(s) per socket:    12Socket(s):             2NUMA node(s):          2Vendor ID:             GenuineIntelCPU family:            6Model:                 79Stepping:              1CPU MHz:               2197.264BogoMIPS:              4401.60Virtualization:        VT-xL1d cache:             32KL1i cache:             32KL2 cache:              256KL3 cache:              30720KNUMA node0 CPU(s):     0-11,24-35NUMA node1 CPU(s):     12-23,36-47</code></pre><h4 id="CPU- 相关">CPU 相关</h4><p>cpu cache 结构图如下：<br><img src="https://s1.ax1x.com/2018/10/28/icww8g.jpg" srcset="/img/loading.gif" width="650" /><br>从硬件的角度，上图的 L1 和 L2 Cache 都被两个 HT 共享，且在同一个物理 Core。而 L3 Cache 则在物理 CPU 里，被多个 Core 来共享。 而从 OS 内核角度，每个 HT 都是一个逻辑 CPU。<br>以 <strong>cpu0</strong> 为例，如下：</p><pre><code>[root@d2b9eb755bb1 ~]# tree -L 1 /sys/devices/system/cpu/cpu0/cache//sys/devices/system/cpu/cpu0/cache/├── index0   -&gt; L1 data 缓存├── index1   -&gt; L1 Instruction 缓存├── index2   -&gt; L2 缓存└── index3   -&gt; L3 缓存</code></pre><p>点到为止，想了解更多可以翻翻以前的课本。更多 cpu 信息可以从 <code>/proc/cpuinfo</code> 文件中获取到。</p><h4 id="irq- 亲缘绑定">irq 亲缘绑定</h4><p>下面基于实践简单说下这个事情。<br><code>/proc/interrupts</code> 文件中可以看到各个 cpu 上的中断情况。<br><code>/proc/irq/#/smp_affinity_list</code> 可以查看指定中断当前绑定的 CPU，当然也 可以看 <code>smp_affinity</code> 这个文件，它是一个 16 进制 bitmask，以逗号分隔，比如 <code>0000,00000020</code>表示该 irq 分给了 CPU5。</p><p>所以，通过如下脚本获得 <strong> 各网卡中断 </strong> 的当前 cpu 的整体情况（平时只对网卡中断感兴趣）：</p><pre><code>cat /proc/interrupts | grep eth0- | cut -d: -f1 | while read i; do echo -ne irq&quot;:$i\t bind_cpu: &quot;; cat /proc/irq/$i/smp_affinity_list; done | sort -n -t' ' -k3</code></pre><p>效果大约是这样的：</p><pre><code>irq:113 bind_cpu: 0irq:117 bind_cpu: 1irq:136 bind_cpu: 2irq:109 bind_cpu: 3irq:137 bind_cpu: 4irq:106 bind_cpu: 5irq:112 bind_cpu: 6irq:111 bind_cpu: 7irq:115 bind_cpu: 8irq:149 bind_cpu: 8irq:152 bind_cpu: 8irq:133 bind_cpu: 9irq:110 bind_cpu: 10irq:114 bind_cpu: 11irq:130 bind_cpu: 24irq:148 bind_cpu: 24irq:131 bind_cpu: 25irq:139 bind_cpu: 26irq:118 bind_cpu: 27irq:132 bind_cpu: 27irq:123 bind_cpu: 28irq:128 bind_cpu: 28irq:134 bind_cpu: 28irq:142 bind_cpu: 28irq:150 bind_cpu: 28irq:135 bind_cpu: 29irq:108 bind_cpu: 30irq:116 bind_cpu: 31irq:119 bind_cpu: 32irq:124 bind_cpu: 32irq:126 bind_cpu: 32irq:127 bind_cpu: 32irq:138 bind_cpu: 32irq:151 bind_cpu: 32irq:107 bind_cpu: 33irq:121 bind_cpu: 34irq:140 bind_cpu: 34irq:120 bind_cpu: 35irq:122 bind_cpu: 35irq:125 bind_cpu: 35irq:129 bind_cpu: 35irq:141 bind_cpu: 35irq:143 bind_cpu: 35irq:144 bind_cpu: 35irq:145 bind_cpu: 35irq:146 bind_cpu: 35irq:147 bind_cpu: 35irq:153 bind_cpu: 35</code></pre><p>可以看到，我这台机器有一半 cpu 是空闲的，已经绑定的 cpu 绑定的 irq 也不太均衡。<br>假如要更改的话，可以有如下类似的操作 <code>echo 3 &gt; /proc/irq/24/smp_affinity</code>。<br>这个也是后面 irqbalance 用来调整中断的方法。</p><h3 id="irqbalance- 代码分析">irqbalance 代码分析</h3><p>下面以 v1.07 为例来进行分析。</p><p>irqbalance 中把中断分成了 8 种 class, 4 种 type。</p><pre><code>/* * IRQ Classes */#define IRQ_OTHER       0#define IRQ_LEGACY      1#define IRQ_SCSI        2#define IRQ_VIDEO       3#define IRQ_ETH         4#define IRQ_GBETH       5#define IRQ_10GBETH     6#define IRQ_VIRT_EVENT  7/* * IRQ Types */#define IRQ_TYPE_LEGACY     0#define IRQ_TYPE_MSI        1#define IRQ_TYPE_MSIX       2#define IRQ_TYPE_VIRT_EVENT 3</code></pre><p>为啥是 8 种 class 呢？这个是依据 pci 设备初始化时注册的类型，可以通过以下脚本来查看</p><pre><code>[root@d2b9eb755bb1 ~]# for i in `ls /sys/bus/pci/devices/*/class`;do echo $((`cat $i` &gt;&gt; 16));done  | sort -nu | wc -l8</code></pre><p>以上的 class 对应 IRQ Classes 使用如下的数组：</p><pre><code>static short class_codes[MAX_CLASS] = {IRQ_OTHER,IRQ_SCSI,IRQ_ETH,IRQ_VIDEO,IRQ_OTHER,IRQ_OTHER,IRQ_LEGACY,IRQ_OTHER,IRQ_OTHER,IRQ_LEGACY,IRQ_OTHER,IRQ_OTHER,IRQ_LEGACY,IRQ_ETH,IRQ_SCSI,IRQ_OTHER,IRQ_OTHER,IRQ_OTHER,};</code></pre><p><code>MAX_CLASS = 0x12</code> 即 18。<br>不同 class 的中断平衡的时候作用域不同，有的在 PACKAGE，有的在 CACHE，有的在 CORE。这个关系对应依靠以下数组进行转换:</p><pre><code>int map_class_to_level[8] ={BALANCE_PACKAGE, BALANCE_CACHE, BALANCE_CORE, BALANCE_CORE, BALANCE_CORE, BALANCE_CORE, BALANCE_CORE, BALANCE_CORE};</code></pre><p>irqbalance 会根据 cpu 的结构由上到下建立了一个树形结构，最顶层是 numa_nodes，向下以此为 CPU packages、Cache domains 以及 CPU cores，自顶向下。</p><p>irqbalance 的主函数很简单，10s 一个周期，做以下事情：<br>【1】清除上次统计结果<br>【2】分析中断情况<br>【3】分析中断的负载情况<br>【4】计算如何平衡中断<br>【5】实施上面指定的方案</p><pre><code>// irqbalance.cint main(int argc, char** argv) {    // ...    // ...    while (keep_going) {sleep_approx(SLEEP_INTERVAL); // 10s        clear_work_stats(); parse_proc_interrupts(); parse_proc_stat(); // ... // ...calculate_placement();activate_mappings();// ...    }    // ...}</code></pre><p>中断最终是运行在某一个 cpu 上的，所以有的中断虽然分配在 cache、package 层次上，但是最终还是在 cpu 上运行，所有每个 cpu 执行中断数大概等于所有父节点的中断数一级一级平均下来。然后用该 cpu 的负载除以该 cpu 平均处理的中断数，得到单位中断所占用的负载，那么每个中断的负载就等于该中断在单位时间内新增的个数乘以单位中断所占用的负载。那问题来了，如何计算负载的呢？<br>答案是通过<code>/proc/stat</code> 文件的 <strong>irq + softirq</strong> 获得的，以 cpu0 为例，一个可能的数据如下：</p><pre><code>cpu0 200118431 1258 112897097 1062445972 321829 0 1048436 0 0 0</code></pre><p>以上的数组表示从系统启动开始累计到当前时刻的 <strong>jiffies</strong>数(jiffies 是内核中的一个全局变量，用来记录自系统启动一来产生的节拍数，在 linux 中，一个节拍大致可理解为操作系统进程调度的最小时间片，不同 linux 内核可能值有不同，通常在 1ms 到 10ms 之间)。<br>以上各字段的含义如下表：</p><table><thead><tr><th style="text-align:left">数值</th><th style="text-align:left">参数</th><th style="text-align:right">含义</th></tr></thead><tbody><tr><td style="text-align:left">200118431</td><td style="text-align:left">user</td><td style="text-align:right">处于用户态的运行时间，不包含 nice 值为负进程。</td></tr><tr><td style="text-align:left">1258</td><td style="text-align:left">nice</td><td style="text-align:right">nice 值为负的进程所占用的 CPU 时间</td></tr><tr><td style="text-align:left">112897097</td><td style="text-align:left">system</td><td style="text-align:right">处于核心态的运行时间</td></tr><tr><td style="text-align:left">1062445972</td><td style="text-align:left">idle</td><td style="text-align:right">除 IO 等待时间以外的其它等待时间</td></tr><tr><td style="text-align:left">321829</td><td style="text-align:left">iowait</td><td style="text-align:right">IO 等待时间(since 2.5.41)</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">irq</td><td style="text-align:right">硬中断时间</td></tr><tr><td style="text-align:left">1048436</td><td style="text-align:left">softirq</td><td style="text-align:right">软中断时间</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">steal</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">guest</td><td style="text-align:right">-</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">guest_nice</td><td style="text-align:right">-</td></tr></tbody></table><p>具体可以看 <a href="http://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="noopener">/proc 目录详解</a>。<br>所以，<code>cpu-&gt;last_load = (irq_load + softirq_load)</code>。<br>每个 CORE 的负载是附在上面的中断的负载的总和，<br>每个 DOMAIN 是包含的 CORE 的总和，<br>每个 PACKAGE 包含的 DOMAIN 的总和，就像树层次一样的计算。</p><p>关于如何平衡上面得到的 load 值呢？下一篇再做讲解。</p><p><strong>To be continued…</strong></p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shell</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从 tcpdump 抓包看 TCP/IP 协议</title>
    <link href="/1f742d6d.html"/>
    <url>/1f742d6d.html</url>
    
    <content type="html"><![CDATA[<p>因为最近要解析 TCP 报文中 option 段的一块数据，所以不得不详细了解下 TCP/IP 报文。虽然之前看过，很长时间没这么细致地用过，导致了健忘，借着这个机会，通过 tcpdump 抓包分析，详细捋一遍 TCP/IP 报文。</p><a id="more"></a><h2 id="报文获取">报文获取</h2><p>如果那样干巴巴地讲这个东西比较晕，而且网上的文章一大堆，没有什么创新。我选择换一个角度来切入 TCP/IP 协议。首先通过 tcpdump 准备报文。<br>【1】我在 <code>192.168.1.22</code> 这台机器的 <code>10000</code> 端口启一个 <code>redis</code> 服务。<br>【2】通过 tcpdump 这个工具来抓取数据包，命令如下：</p><pre><code class="language-shell">tcpdump -w /tmp/logs -i eth0 port 10000 -s0</code></pre><p>【3】在 <code>192.168.1.26</code> 这台机器上访问 <code>192.168.1.22:10000</code> 这个 redis 实例，可以用 <code>redis-cli</code> 客户端，也可以用 <code>telnet</code>，发送一个 <code>ping</code>, 得到对端回复 <code>pong</code>。<br>【4】停止抓包，用 tcpdump 读取这个数据包（<code>-x</code> 以 16 进制形式展示，便于后面分析）</p><pre><code class="language-shell">tcpdump -r /tmp/logs -n -nn -x| vim -</code></pre><p>其中有一个数据包是这样的，这也是这篇文章要分析的:</p><pre><code class="language-other">10:54:54.270967 IP 192.168.1.26.61096 &gt; 192.168.1.22.10000: Flags [P.], seq 1041414875:1041414889, ack 658186233, win 115, options [nop,nop,TS val 2377448931 ecr 2741547141], length 14        0x0000: [4560 0042   7567 0000  3d06 6F3C C0A8 011A        0x0010:  C0A8 0116] {eea8 2710  3e12 badb 273b 1ff9        0x0020:  8018 0073   64b0 0000  0101 080a 8db4 fde3        0x0030:  a368 b085}  2a31 0d0a  2434 0d0a 7069 6e67        0x0040:  0d0a</code></pre><p><strong>注意：</strong><br>【1】之前在文章 <a href="https://vonalex.github.io/2017/08/05/%E5%B8%B8%E7%94%A8shell/"> 常用 shell</a> 中介绍过抓包神器 <strong>tcpdump</strong>，还不会的小伙伴可以偷瞄一眼。<br>【2】上面报文数据中的 <code>[</code>、<code>]</code>、<code>{</code> 和 <code>}</code> 是为了方便区分数据，我自己加上的。<code>[]</code>包围的部分为本报文中的 IP 头，<code>{}</code>包围的部分为本报文中的 TCP 头。</p><h2 id="报文分析">报文分析</h2><p>IP 报文整体结构如下，因为抓到的数据包是请求 <code>redis</code> 服务，因此在传输层为 TCP 协议。<br><img src="https://s1.ax1x.com/2018/10/28/icwsrn.jpg" srcset="/img/loading.gif" width="650"/></p><h3 id="IP- 层解析">IP 层解析</h3><p>解析数据包之前，先把 IP 协议拿出来，如下：<br><img src="https://s1.ax1x.com/2018/10/28/icwgaV.jpg" srcset="/img/loading.gif" width="650"/><br>可以看到，IP 报文头部采用 <code> 固定长度 (20B) + 可变长度</code> 构成，下面的 TCP 头部也是这样。<br>然后下面对着抓到的数据包进行分析：<br>【1】<code>0x4</code> 4bit， <strong>ip 协议版本</strong><br><code>0x4</code> 表示 IPv4。<br>【2】<code>0x5</code> 4bit，<strong>ip 首部长度(IHL)</strong><br>该字段表示单位是 32bits (4 字节) ，所以这个 ip 包的头部有 <code>5*4=20B</code>，这就可以推出，该 IP 报文头没有可选字段。4bit 可以表示最大的数为 0xF，因此，IP 头部的最大长度为 <code>15*4=60B</code>。该报文的 IP 头部我已经在报文中标注出来了。<br>【3】<code>0x60</code> 8bit，<strong>服务类型 TOS</strong><br>该段数据组成为 3bit 优先权字段(现已被忽略) + 4bit TOS 字段 + 1bit 保留字段(须为 0)。<br>4bit TOS 字段分别表示最小时延、最大吞吐量、最高可用性和最小费用。只能置其中 1bit，全为 0 表示一般服务。<strong>现在大多数的 TCP/IP 实现都不支持 TOS 特性</strong> 。可以看到，本报文 TOS 字段为全 0。<br>【4】<code>0x0042</code> 16bit， <strong>IP 报文总长度</strong><br>单位字节，换算下来，该数据报的长度为 66 字节，数一下上面的报文，恰好 66B。<br>从占位数来算， IP 数据报最长为 <code>2^16=65535B</code>，但大部分网络的链路层 MTU（最大传输单元）没有这么大，一些上层协议或主机也不会接受这么大的，故超长 IP 数据报在传输时会被分片。<br>【5】<code>0x7567</code> 16bit，<strong>标识</strong><br>唯一的标识主机发送的每一个数据报。通常每发送一个报文，它的值 +1。当 IP 报文分片时，该标识字段值被复制到所有数据分片的标识字段中，使得这些分片在达到最终目的地时可以依照标识字段的内容重新组成原先的数据。<br>【6】<code>0x0000</code> 3bit <strong>标志 </strong> + 13bit <strong> 片偏移</strong><br>3bit 标志对应 R、DF、MF。目前只有后两位有效，DF 位：为 1 表示不分片，为 0 表示分片。MF：为 1 表示“更多的片”，为 0 表示这是最后一片。<br>13bit 片位移：本分片在原先数据报文中相对首位的偏移位。<strong>（需要再乘以 8）</strong><br>【7】<code>0x3d</code> 8bit <strong>生存时间 TTL</strong><br>IP 报文所允许通过的路由器的最大数量。每经过一个路由器，TTL 减 1，当为 0 时，路由器将该数据报丢弃。TTL 字段是由发送端初始设置一个 8 bit 字段. 推荐的初始值由分配数字 RFC 指定。发送 ICMP 回显应答时经常把 TTL 设为最大值 255。TTL 可以防止数据报陷入路由循环。本报文该值为 61。<br>【8】<code>0x06</code> 8bit <strong>协议</strong><br>指出 IP 报文携带的数据使用的是哪种协议，以便目的主机的 IP 层能知道要将数据报上交到哪个进程。TCP 的协议号为 6，UDP 的协议号为 17。ICMP 的协议号为 1，IGMP 的协议号为 2。该 IP 报文携带的数据使用 TCP 协议，得到了验证。<br>【9】<code>0x6F3C</code> 16bit <strong>IP 首部校验和</strong><br>由发送端填充。以本报文为例，先说这个值是怎么计算出来的。</p><pre><code class="language-oth"># 将校验和字段 16bit 值抹去变为 `0x0000`，然后将首部 20 字节值相加0x4560 + 0x0042 + 0x7567 + 0x0000 + 0x3d06 + 0x0000 + 0xC0A8 + 0x011A + 0xC0A8 +0x0116 = 0x27B95# 将上述结果的进位 2 与低 16bit 相加0x7B95 + 0x2 = 0x7B97# 0x7B97 按位取反~(0x7B97) = 0x8468</code></pre><p>结果 <code>0x8468</code> 即为该字段值！<br>接收端验证的时候，进行以下计算</p><pre><code class="language-o't"># 20B 首部值相加0x27B95 + 0x8468 = 0x2FFFD# 将上述结果的进位 2 与低 16bit 相加0xFFFD + 0x2 = 0xFFFF# 0xFFFF 按位取反~(0xFFFF) = 0  &lt;-- 正确</code></pre><p>【10】<code>0xC0A8011A</code> 32bit 源地址<br>可以通过一下 python 程序将 hex 转换成我们熟悉的点分 IP 表示法</p><pre><code class="language-python">&gt;&gt;&gt; import socket&gt;&gt;&gt; import struct&gt;&gt;&gt; int_ip=int(&quot;0xC0A8011A&quot;,16)&gt;&gt;&gt; socket.inet_ntoa(struct.pack('I',socket.htonl(int_ip)))'192.168.1.26'</code></pre><p>本报文中的 src addr 为 <code>192.168.1.26</code>，恰好就是发起请求的 IP。<br>【11】<code>0xC0A80116</code> 32bit 目的地址<br>经过计算为  <code>192.168.1.22</code>，恰好就是启 redis 服务那台机器的 IP。</p><hr><p>由于该报文首部长度为 20B，因此没有 <strong> 可变长部分</strong>。</p><h3 id="传输层解析">传输层解析</h3><p>本报文携带的数据使用的 TCP 协议，因此下面开始分析 TCP 协议。<br>与上面的 IP 报文一样， TCP 报文头也才用采用 <code> 固定长度 (20B) + 可变长度</code> 的形式。<br>首先还是看 TCP 协议的格式，如下：<br><img src="https://s1.ax1x.com/2018/10/28/icwba6.jpg" srcset="/img/loading.gif" width="800"/><br><strong>注：</strong> TCP 的头部必须是 4 字节的倍数, 而大多数选项不是 4 字节倍数, 不足的用 <code>NOP</code> 填充。<br>【1】<code>0xeea8</code> 16bit，<strong>源端口</strong><br>解析得到 61096，这与 tcpdump 读包显示的是一致的。16bit 决定了端口号的最大值为 65535.<br>【2】<code>0x2710</code> 16bit，<strong>目的端口</strong><br>解析得到 10000。<br>【3】<code>0x273b1ff9</code> 32bit，<strong>序号</strong><br>解析得到 1041414875，这与上面 tcpdump 显示的 <strong>seq</strong> 段是一致的。<br>【4】<code>0x273b1ff9</code> 32bit，<strong>确认号</strong><br>解析得到 658186233，这与上面 tcpdump 显示的 <strong>ack</strong> 段是一致的。<br>【5】<code>0x8</code> 4bit，<strong>TCP 报文首部长度</strong><br>也叫 offset，其实也就是数据从哪里开始。<code>8 * 4 = 32B</code>, 因此该 TCP 报文的可选部分长度为 <code>32 - 20 = 12B</code>，这个资源还是很紧张的！ 同 IP 头部类似，最大长度为 <code>60B</code>。<br>【6】<code>0b000000</code> 6bit, <strong>保留位</strong><br>保留为今后使用，但目前应置为 0。<br>【7】<code>0b011000</code> 6bit，<strong>TCP 标志位</strong><br>上图可以看到，从左到右依次是紧急 URG、确认 ACK、推送 PSH、复位 RST、同步 SYN 、终止 FIN。<br>从抓包可以看出，该报文是带了 ack 的，所以 ACK 标志位置为 1。关于标志位的知识这里就不展开了。<br>【8】<code>0x0073</code> 16bit，<strong>滑动窗口大小</strong><br>解析得到十进制 115，跟 tcpdump 解析的 <strong>win</strong> 字段一致。<br>【9】<code>0x64b0</code> 16bit，<strong>校验和</strong><br>由发送端填充，接收端对 TCP 报文段执行 CRC 算法，以检验 TCP 报文段在传输过程中是否损坏，如果损坏这丢弃。<br>检验范围包括首部和数据两部分，这也是 TCP 可靠传输的一个重要保障。<br>【10】<code>0x0000</code> 16bit，<strong>紧急指针</strong><br>仅在 URG = 1 时才有意义，它指出本报文段中的紧急数据的字节数。<br>当 URG = 1 时，发送方 TCP 就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。</p><hr><p>下面是 TCP 可选项，其格式如下：<br><img src="https://s1.ax1x.com/2018/10/28/icwqIK.jpg" srcset="/img/loading.gif" width="550"/><br>常见的可选项如下图：<br><img src="https://s1.ax1x.com/2018/10/28/icwHVx.jpg" srcset="/img/loading.gif" width="650"/><br>【11】<code>0x01</code><br>NOP 填充，没有 Length 和 Value 字段， 用于将 TCP Header 的长度补齐至 32bit 的倍数。<br>【12】<code>0x01</code><br>同上。<br>【13】<code>0x080a</code><br>可选项类型为时间戳，len 为 10B，value 为<code>0x8db4 0xfde3 0xa368 0xb085</code>，加上 <code>0x080a</code>，恰好 10B!<br>启用 Timestamp  Option 后，该字段包含 2 个 32bit 的 Timestamp（TSval 和 TSecr）。<br>【14】<code>0x8db4 0xfde3</code><br>解析后得到 2377448931，恰好与 tcpdump 解析到的 TS 字段的 <strong>val</strong>一致！<br>【15】<code>0xa368 0xb085</code><br>解析后得到 2741547141，恰好与 tcpdump 解析到的 TS 字段的 <strong>ecr</strong>一致！</p><h3 id="数据部分解析">数据部分解析</h3><p>上面分析得知，该 IP 报文长度为 66B，IP 头长度为 20B，TCP 头部长度为 32B，因此得到数据的长度为 <code>66 - 20 - 32 = 14B</code>，这与 tcpdump 解析到的 <strong>len</strong> 字段一致！下面来分析这个具体的数据。<br>这里涉及到 redis 协议，不知道的小伙伴可以查看这篇文档<a href="http://www.redis.cn/topics/protocol.html" target="_blank" rel="noopener">redis 协议说明</a>。<br>在抓包时，用客户端向 redis 服务端发送了一个 <code>ping</code> 命令，转换成 redis 协议如下：</p><pre><code>*1\r\n$4\r\nping\r\n</code></pre><p>下面看抓包数据解析，这需要对照 ascii 码表来看，在 linux 下可以用 <code>man 7 ascii</code> 这个命令来获得，或者在这里查看<a href="https://blog.csdn.net/innobase/article/details/51671996" target="_blank" rel="noopener">ascii 码表</a>。</p><pre><code>0x2a31         -&gt; *10x0d0a         -&gt; \r\n0x2434         -&gt; $40x0d0a         -&gt; \r\n0x7069 0x6e67  -&gt; ping0x0d0a         -&gt; \r\n</code></pre><p>好了，这个 IP 包的解析就到此为止了，照着 TCP/IP 协议分析了一遍, 发现协议也就那么回事儿，没有想象的那么难，不要害怕协议！</p><hr><h3 id="tcpdump- 补充">tcpdump 补充</h3><p>既然详细说到 TCP/IP 协议，那补充一下 tcpdump filter 的几点用法。<br>filter 可以简单地分为三类：<code>type</code>, <code>dir</code> 和 <code>proto</code>。</p><p>type 区分报文的类型，主要由 host（主机）, net（网络，支持 CIDR） 和 port(支持范围，如 portrange 21-23) 组成。<br>dir 区分方向，主要由 src 和 dst 组成。<br>proto 区分协议支持 tcp、udp 、icmp 等。</p><p>下面说几个 filter 表达式。<br><code>proto[x:y]</code> start at offset x into the proto header and read y <strong>bytes</strong><br><code>[x]</code> abbreviation for <code>[x:1]</code><br><strong>注意</strong>：单位是字节，不是位！</p><p>举几个栗子：<br>【1】<strong>打印 80 端口，有数据的 tcp 包</strong></p><pre><code class="language-shell"> tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)'</code></pre><p><code>ip[2:2]</code> 从 ip 报文的第 3 个字节开始读 2 个字节，这个恰好就是 ip 包的总长度，单位是字节<br><code>ip[0]&amp;0xf</code> 取的是 ip 报文第 1 个字节的低 4 位，<code>&lt;&lt; 2</code>（乘以 4），为 ip 头部长度，单位是字节<br><code>tcp[12]&amp;0xf0</code> 取的是 tcp 报文第 13 个字节的高 4 位，<code>&gt;&gt; 2</code> 其实等价于 <code>&gt;&gt; 4</code> 然后 <code>&lt;&lt; 2</code>，为 tcp 头部长度，单位是字节。<br>所以 <code>((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2))</code> 表示的数据长度。<br>【2】<strong>打印 80 端口，长度超过 576 的 ip 包</strong></p><pre><code class="language-shell"> tcpdump 'port 80 and ip[2:2] &gt; 576'</code></pre><p>【3】<strong>打印特定 TCP Flag 的数据包</strong><br>TCP Flags 在 tcpdump 抓取的报文中的体现：<br><code>[S]</code>：SYN（开始连接）<br><code>[.]</code>: 没有 Flag<br><code>[P]</code>: PSH（推送数据）<br><code>[F]</code>: FIN （结束连接）<br><code>[R]</code>: RST（重置连接）<br><code>[S.]</code> SYN-ACK，就是 SYN 报文的应答报文。</p><pre><code class="language-shell">tcpdump 'tcp[13] &amp; 16!=0'# 等价于tcpdump 'tcp[tcpflags] == tcp-ack'</code></pre><p>打印出所有的 ACK 包。</p><pre><code class="language-shell">tcpdump 'tcp[13] &amp; 4!=0'# 等价于tcpdump 'tcp[tcpflags] == tcp-rst'</code></pre><p>打印出所有的 RST 包，即包含 <code>[R]</code> 标志的包。</p><p>更多 tcpdump filter 可以查看 <a href="http://www.tcpdump.org/manpages/pcap-filter.7.html" target="_blank" rel="noopener">PCAP-FILTER</a> 或者 <code>man tcpdump</code>！</p><hr><h2 id="参考">参考</h2><ol><li><a href="https://blog.csdn.net/blakegao/article/details/19419237" target="_blank" rel="noopener">常用的 TCP Option</a></li><li><a href="https://blog.csdn.net/mary19920410/article/details/59035804" target="_blank" rel="noopener">IP 报文格式详解</a></li><li><a href="https://jerryc8080.gitbooks.io/understand-tcp-and-udp/chapter2.html" target="_blank" rel="noopener">TCP 报文结构</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tcp/ip</tag>
      
      <tag>tupdump</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vscode 体验记</title>
    <link href="/ef96f204.html"/>
    <url>/ef96f204.html</url>
    
    <content type="html"><![CDATA[<p>之前开发一直用 <strong>jetbrains</strong> 家的产品，产品是不错，也的确不错。可日复一日，那启动速度实在有点…那啥，不过这也可以理解，毕竟软件做的那么复杂那么强大嘛。于是就开始着手寻找替代品，之前也配置过 <strong>sublime</strong>，也写过 <a href="https://vonalex.github.io/2016/05/12/sublime-text3%E9%85%8D%E7%BD%AE%5Bpython%E7%AF%87%5D/"> 文章</a>，可不知道为啥总也喜欢不起来。<br>后来，毫不费力地找到了 <strong>vscode</strong> 这款神奇的软件，作为一个喜欢倒腾各种（手机 / 电脑）软件的人，好软件当然要搞一搞。<br>下面介绍下这款每天使用时间最长的软件 vscode。</p><a id="more"></a><blockquote><p>VSCode 是微软推出的一款轻量编辑器，采取了和 VS 相同的 UI 界面。</p></blockquote><p>官方网站上是这么说的：</p><blockquote><p>Visual Studio Code is a lightweight but powerful source code editor which runs on your desktop and is available for Windows, macOS and Linux. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages (such as C++, C#, Java, Python, PHP, Go) and runtimes (such as .NET and Unity).</p></blockquote><p>使用这个软件的一个重要原因是轻量级，类似于 sublime，插件丰富，关键它是 <strong> 免费的</strong>！<br><strong>微软出品, 品质保证!</strong> 嗯，事实证明，你大爷永远是你大爷！<br>呐，使用过一段时间下来呢，发现的确很不错，这里对使用过程中的一些配置以及我日常用到的插件做一下梳理(有点多)。让你知道，我用过之后是这个样子，你用过也是这个样子，<strong>Duang<sub>Duang</sub></strong> 奸笑脸…</p><h2 id="安装">安装</h2><p>在 <a href="https://code.visualstudio.com/" target="_blank" rel="noopener"> 官网 </a> 下载这个软件，可以选择相应的平台版本进行下载，对，它是跨平台支持的！<br>官方文档可以看 <a href="https://code.visualstudio.com/docs" target="_blank" rel="noopener"> 这里</a>, 可以解决日常遇到的大部分问题。<br>它的外观大概是这个样子，hmm…蛮不错的吧？<br><img src="https://s1.ax1x.com/2018/10/28/icwXGD.jpg" srcset="/img/loading.gif" alt="vscode-ui"></p><h2 id="常用插件">常用插件</h2><p>这里只罗列一些我常用到的插件，因为不是做前端工作，虽然前端方面也有一些很优秀的插件，但是因为我暂时用不到，因此没有做介绍。<br><strong>注意:</strong> 以下插件都可以在 vscode 自带的扩展商店中找到。</p><h3 id="Material-Icon-Theme">Material Icon Theme</h3><p>这个是我最喜欢的一款图标主题，切换到这个主题后，图标大概是这样的<br><img src="https://s1.ax1x.com/2018/10/28/icwOPO.jpg" srcset="/img/loading.gif" alt="icwOPO.jpg"><br>文件夹颜色、关联图标也是可以根据参数调整，这里看 <a href="https://marketplace.visualstudio.com/items?itemName=PKief.material-icon-theme" target="_blank" rel="noopener"> 插件文档</a>，不过我觉得默认配置就行了，别浪费时间折腾了。</p><h3 id="One-Dark-Pro">One Dark Pro</h3><p>配置完了图标主题以后，再来个代码颜色主题（对某些人来说，这很重要），我墙裂推荐的就是这款 <strong>One Dark Pro</strong> 啦，Atom 的这款颜色主题真是漂亮，从几百万的下载量来看，我的审美还是符合大众审美的…emm… 大概就是上图这个样子（上图是 cpp 渲染效果），总之我是很满意的。</p><hr><p>OK！折腾完门脸儿，下面切入正题！</p><h3 id="Go">Go</h3><p>作为一个 golang 程序员怎么能少的了 golang 支持插件，隆重推出这款微软官方出的插件。<br>插件文档可以看这个 <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.Go" target="_blank" rel="noopener">Go for Visual Studio Code</a>。<br>该插件依赖一些 go 工具来完成跳转和格式化等，第一次使用需要手动安装（<strong>可能需要番·羽·土·啬</strong>）。</p><pre><code>go get -u -v github.com/nsf/gocodego get -u -v github.com/rogpeppe/godefgo get -u -v github.com/golang/lint/golintgo get -u -v github.com/lukehoban/go-outlinego get -u -v sourcegraph.com/sqs/goreturnsgo get -u -v golang.org/x/tools/cmd/gorenamego get -u -v github.com/tpng/gopkgsgo get -u -v github.com/newhook/go-symbolsgo get -u -v golang.org/x/tools/cmd/guru</code></pre><p>配置的话，默认配置基本就可以，<strong>前提是没装已经在系统中配置好了 go</strong>，在配置页面搜索 <code>go</code>，查看所有相关的配置项。</p><h3 id="C-C">C/C++</h3><p>微软出品的 c/c++ 插件，支持函数跳转、查看声明、语法检测和格式化等各种功能，体验不错。</p><h3 id="Python">Python</h3><p>微软出品的 python 支持插件，上千万的下载量！插件文档可以看看 <a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python" target="_blank" rel="noopener"> 这里</a>。</p><hr><h3 id="Git-History">Git History</h3><p>这个插件做了件什么事儿呢？就是优化默认集成的 git log 和 diff 等，将更多的内容可视化，更加直观，操作体验不输于 <strong>github</strong>。<br>用起来很方便！！一个不容错过的 vscode 插件。更多信息请查看 <a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.githistory" target="_blank" rel="noopener"> 插件文档</a>。</p><h3 id="GitLens-—-Git-supercharged">GitLens — Git supercharged</h3><p>官网是这样介绍的，感受一下。</p><blockquote><p>GitLens supercharges the Git capabilities built into Visual Studio Code. It helps you to visualize code authorship at a glance via Git blame annotations and code lens, seamlessly navigate and explore Git repositories, gain valuable insights via powerful comparison commands, and so much more.</p></blockquote><p>装上以后，是这个样子，每一行 code 的作者、提交时间、commit log 等信息，一目了然。</p><hr><h3 id="Code-Outline">Code Outline</h3><p>这个插件做的是会把代码中的函数、变量、结构体定义等都提出来显示，（vscode 控制面板下输入 <strong>@</strong> 符号也可以实现），这个插件效果大概是这样：<br><img src="https://s1.ax1x.com/2018/10/28/icwybq.jpg" srcset="/img/loading.gif" alt="Outline"><br>主流语言都支持了！</p><h3 id="Bracket-Pair-Colorizer">Bracket Pair Colorizer</h3><p>括弧匹配，很直观。<br>还有些颜色配置的，可以看下 <a href="https://marketplace.visualstudio.com/items?itemName=CoenraadS.bracket-pair-colorizer" target="_blank" rel="noopener"> 插件文档</a>，看兴趣自己配置下吧，默认就可以。</p><h3 id="Guides">Guides</h3><p>这个插件是搞缩进线的…emm…自我感觉也不错。<br><img src="https://s1.ax1x.com/2018/10/28/icw02Q.jpg" srcset="/img/loading.gif" width="800"/></p><h3 id="TODO-Highlight">TODO Highlight</h3><p>这种插件是少不了的, 不同的颜色区分 <strong>TODO</strong> 和 <strong>FIXME</strong>，还可以在控制面板列出各项 <strong>TODO</strong>，多的不说，可以看下 <a href="https://marketplace.visualstudio.com/items?itemName=wayou.vscode-todo-highlight" target="_blank" rel="noopener"> 插件文档</a>。</p><h3 id="change-case">change-case</h3><h3 id="Code-Runner">Code Runner</h3><p>这个插件可以跑简单的脚本。<br>还有一些各种各样的配置，可以在 <a href="https://marketplace.visualstudio.com/items?itemName=formulahendry.code-runner" target="_blank" rel="noopener"> 插件文档 </a> 查看。</p><h3 id="Settings-Sync">Settings Sync</h3><p>最后一个插件！<br>你可能会想，我配置了这么多插件，换了电脑再来一遍的话，岂不是浪费时间？…emm…很有道理，那么隆重推出这款插件 <strong>Settings Sync</strong>，它可以同步插件配置，只需要配置一次，以后就不用再麻烦了。配置这个插件的话跟着 <a href="https://marketplace.visualstudio.com/items?itemName=Shan.code-settings-sync" target="_blank" rel="noopener"> 插件文档 </a> 走一遍，很容易搞定的。</p><h2 id="常用配置项">常用配置项</h2><pre><code class="language-json:vscode-config">{    &quot;editor.fontSize&quot;: 14,    &quot;editor.lineHeight&quot;: 22,    &quot;editor.cursorBlinking&quot;: &quot;smooth&quot;,    &quot;workbench.colorTheme&quot;: &quot;One Dark Pro Vivid&quot;,    &quot;workbench.iconTheme&quot;: &quot;material-icon-theme&quot;,    &quot;workbench.editor.enablePreview&quot;: false,    &quot;gitlens.advanced.messages&quot;: {&quot;suppressShowKeyBindingsNotice&quot;: true},    &quot;gitlens.historyExplorer.enabled&quot;: false,    &quot;editor.fontFamily&quot;: &quot;Fira Code, Menlo, Monaco, Courier New, monospace&quot;,    &quot;editor.quickSuggestions&quot;: {        &quot;other&quot;: true,        &quot;comments&quot;: true,        &quot;strings&quot;: true    },    &quot;guides.normal.color.dark&quot;: &quot;rgba(91, 91, 91, 0.6)&quot;,    &quot;guides.normal.color.light&quot;: &quot;rgba(220, 220, 220, 0.7)&quot;,    &quot;guides.active.color.dark&quot;: &quot;rgba(210, 110, 210, 0.6)&quot;,    &quot;guides.active.color.light&quot;: &quot;rgba(200, 100, 100, 0.7)&quot;,    &quot;guides.active.style&quot;: &quot;dashed&quot;,    &quot;guides.normal.style&quot;: &quot;dashed&quot;,    &quot;guides.stack.style&quot;: &quot;dashed&quot;,    &quot;guides.enabled&quot;: true,    &quot;files.trimTrailingWhitespace&quot;: true,    &quot;files.trimFinalNewlines&quot;: true,    &quot;[cpp]&quot;: {&quot;editor.autoIndent&quot;: true},    &quot;editor.renderIndentGuides&quot;: false,    &quot;python.autoComplete.addBrackets&quot;: true,    &quot;python.pythonPath&quot;: &quot;/usr/local/bin/python&quot;,    &quot;python.linting.enabled&quot;: true,    &quot;material-icon-theme.folders.color&quot;: &quot;#42a5f5&quot;,    &quot;editor.tabSize&quot;: 4,    &quot;editor.renderWhitespace&quot;: &quot;all&quot;,}</code></pre><p>以上各项的含义不解释了，vscode 的配置非常人性化，为啥这么说？你试试就知道了…<br>还有一个事情是字体推荐 <strong>Fira Code</strong>，你值得拥有！</p><h2 id="常用快捷键">常用快捷键</h2><p>以下快捷键针对 mac ，且只是部分常用快捷键</p><h3 id="全局">全局</h3><table><thead><tr><th>快捷键</th><th>含义</th></tr></thead><tbody><tr><td>Command + Shift + P / F1</td><td>显示命令面板</td></tr><tr><td>Command + P</td><td>快速打开</td></tr><tr><td>Command + Shift + N</td><td>打开新窗口</td></tr><tr><td>Command + W</td><td>关闭窗口</td></tr></tbody></table><h3 id="基本">基本</h3><table><thead><tr><th>快捷键</th><th>含义</th></tr></thead><tbody><tr><td>Command + X 剪切</td><td>（未选中文本的情况下，剪切光标所在行）</td></tr><tr><td>Command + C 复制</td><td>（未选中文本的情况下，复制光标所在行）</td></tr><tr><td>Command + I</td><td>选中当前行</td></tr><tr><td>Option + Up/Down</td><td>向上 / 下移动行</td></tr><tr><td>Option + Shift + Up/Down</td><td>向上 / 下复制行</td></tr><tr><td><strong>Command + Shift + K</strong></td><td>删除行</td></tr><tr><td>Command + Enter</td><td>下一行插入</td></tr><tr><td>Command + Shift + Enter</td><td>上一行插入</td></tr><tr><td>Command + Shift + \</td><td>跳转到匹配的括号</td></tr><tr><td>Command + [/]</td><td>减少 / 增加缩进</td></tr><tr><td>Command + /</td><td>添加、移除行注释</td></tr></tbody></table><h3 id="其他">其他</h3><table><thead><tr><th>快捷键</th><th>含义</th></tr></thead><tbody><tr><td>Option + 点击</td><td>插入多个光标</td></tr><tr><td>Command + F</td><td>查找</td></tr><tr><td>Command + D</td><td>向下选中相同内容</td></tr><tr><td>Command + T</td><td>显示所有光标所在的符号  【速度有点慢】</td></tr><tr><td>Ctrl + G</td><td>跳转至某行</td></tr><tr><td>Ctrl + -</td><td>后退</td></tr><tr><td>Ctrl + Shift + -</td><td>前进</td></tr><tr><td>Command + \</td><td>编辑器分屏</td></tr><tr><td>Command + 1</td><td>切换到第一分组</td></tr><tr><td>Command + Shift + v</td><td>Markdown 预览窗口</td></tr><tr><td>Ctrl + `</td><td>显示终端</td></tr><tr><td>cmd+k z</td><td>进入 zen 模式，esc 退出</td></tr></tbody></table><hr><p>更多 vscode 使用技巧，可以查看 <a href="https://github.com/Microsoft/vscode-tips-and-tricks/blob/master/README.md" target="_blank" rel="noopener">vscode-tips-and-tricks</a>。<br><strong>补充一个问题</strong>，VS Code 下将 tab 缩进修改为空格缩进:<br><code>command + shift + p</code> ，然后输入 indent usingspace 并可以修改 sapce 大小，将 tab 替换为 space 的大小可以修改设置里的 tabSize 参数</p>]]></content>
    
    
    <categories>
      
      <category>tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vscode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>golang 包导入的一些问题</title>
    <link href="/3dbe6014.html"/>
    <url>/3dbe6014.html</url>
    
    <content type="html"><![CDATA[<p>对 golang 包导入以及包管理方面的学习中遇到的问题做记录。</p><a id="more"></a><h2 id="import">import</h2><p>Go 使用包（package）作为基本单元来组织源代码，所有语法可见性均定义在 package 这个级别。同一 package 下面，可以有非常多的不同文件，只要每个文件属于相同的 package name。<br>每个源码文件的第一行必定要通过如下语法定义属于哪个 package，</p><pre><code>package xxx</code></pre><p>然后就是导入本源码文件所使用的标准包或第三方包，即</p><pre><code>import (    &quot;a/b/c&quot;    &quot;fmt&quot;)</code></pre><p>标准库会从 <strong>GO 的安装目录 </strong> 下查找，第三方库会从开发者定义的 <code>$GOPATH</code> 下查找。当都找不到时，编译器就会报错。在使用第三方包的时候，当源码和 <code>.a</code> 均已安装的情况下，编译器链接的是 <strong> 源码</strong>。</p><p><strong>注意：</strong> 上面语句中 <code>a/b/c</code> 最后的 <code>c</code> 为目录名，<strong>不是 package name</strong>。</p><p>在对文件中的方法进行调用时，使用如下格式:</p><pre><code>package.Methodxxx()</code></pre><p>同一文件夹下的多个文件的 package 一般定义为该文件夹的名字，但是也有例外，比如上面的栗子中，c 文件下的所有文件的 package 定义为 fux，那么在调用这个文件夹下文件的方法时，只能使用 <code>fux.Methodxxx()</code>, 而不是 <code>c..Methodxxx()</code></p><blockquote><p>一个非 main 包在编译后会生成一个.a 文件（在临时目录下生成，除非使用 go install 安装到 <code>$GOROOT</code> 或 <code>$GOPATH</code>下，否则你看不到 <strong>.a</strong>），用于后续可执行程序链接使用。</p></blockquote><h2 id="vendor">vendor</h2><p>Go 在 1.5 的版本加入的 vendor 的支持来做包管理。1.5 版本要设置 <code>GO15VENDOREXPERIMENT=&quot;1&quot;</code> 来支持这个特性，1.6 版本将其作为默认参数配置。下面对于包含 vendor 目录的包导入路径规则大致如下。</p><pre><code>├── d    ├── mypkg    |     └── main.go    └── vendor          └── q              ├── q.go</code></pre><p>当上述目录结构，在 <code>main.go</code> 中 <code>import q</code>时，后首先从 <strong>vendor</strong> 目录下查找，若找不到，会从 <strong>$GOPATH</strong> 目录下查找，再找不到的话，编译器就报错了。</p><h2 id="参考">参考</h2><p>【1】<a href="http://tonybai.com/2015/07/31/understand-go15-vendor/" target="_blank" rel="noopener">理解 Go 1.5 vendor</a><br>【2】<a href="http://tonybai.com/2015/03/09/understanding-import-packages/" target="_blank" rel="noopener">理解 Golang 包导入</a></p>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis 基本数据结构之 SDS</title>
    <link href="/75a172a4.html"/>
    <url>/75a172a4.html</url>
    
    <content type="html"><![CDATA[<p>本文以 redis 3.2.8 版本来介绍 redis 源码。</p><p>字符串是 Redis 最基本的数据结构，首先键都是字符串类型的，而且其他几种数据结构也都是在字符串类型的基础之上构建的，因此，我认为从字符串入手来探究 Redis 的数据结构是相对合理的。</p><a id="more"></a><p>redis 没有直接使用 C 语言中传统的字符串表示，而是自己实现了一套名为简单动态字符串（simple dynamic string, SDS）的抽象类型，将其作为 redis 的默认字符串使用。实际上 redis 并没有完全抛弃 C 字符串，只是在这之上进行了进一步封装，使其获得更好的特性，比如二进制安全、动态扩展内存等，这也使得 SDS 可以兼容 C 字符串的 API。</p><p>redis 源码中关于 sds 的部分，主要在 <code>sds.h</code> 和 <code>sds.c</code> 这两个文件中。</p><h3 id="SDS- 的定义">SDS 的定义</h3><p>首先在 <code>sds.h</code> 中找到了 sds 的定义</p><pre><code class="language-c">typedef char *sds;</code></pre><p>这跟 C 字符串是一样的，但是真的这么简单吗？往下看，会有新的发现：</p><pre><code class="language-c">// 暂时未用到struct __attribute__ ((__packed__)) sdshdr5 {    unsigned char flags;    char buf[];};struct __attribute__ ((__packed__)) sdshdr8 {    uint8_t len;    uint8_t alloc;    unsigned char flags;    char buf[];};struct __attribute__ ((__packed__)) sdshdr16 {    uint16_t len;    uint16_t alloc;    unsigned char flags;    char buf[];};struct __attribute__ ((__packed__)) sdshdr32 {    uint32_t len;    uint32_t alloc;    unsigned char flags;    char buf[];};struct __attribute__ ((__packed__)) sdshdr64 {    uint64_t len;    uint64_t alloc;    unsigned char flags;    char buf[];};</code></pre><p>到此，大概明白了，sds 采用一段连续的内存空间来存储动态字符串，即 <strong>header + str</strong> 的形式。<br><code>__attribute__ ((packed))</code> 是为了让编译器以紧凑模式来分配内存。不对 struct 中的字段进行内存对齐，以此保证 header 和 sds 的数据部分紧紧的相邻，否则，不能按照固定的偏移来获取 flags 字段。<br>当定义了 <code>sds* s</code> 后，使用 <code>s[-1]</code> 就可以获得 flag 的值，这样就知道了这个 sds 属于哪种类型。</p><p>为了满足存储不同长度字符串的需求（为了节省内存），在宏定义中定义了五种 header（0~4）。</p><p>下面解释一下 header 中各个字段的含义：</p><ul><li><strong>len</strong>: 字符串真正的长度（不包含空终止字符）</li><li><strong>alloc</strong>: 字符串的最大容量，不包含 header 和最后的 ‘\0’，初始时与 len 值一致</li><li><strong>flags</strong>: 低三位表示 header 类型</li><li><strong>buf</strong>: 柔性数组，表示一个长度动态的字符串</li></ul><p>柔性数组，只能定义在一个结构体的 <strong> 最后一个字段 </strong> 上。它在这里只是起到一个标记的作用，表示在 flags 字段后面是一个字符数组，或者说，它指明了紧跟在 flags 字段后面的这个字符数组在结构体中的偏移位置。<br>程序在为 header 分配内存的时候，<strong>buf[]</strong> 并不占用内存空间。如果计算 <code>sizeof(struct sdshdr16)</code>的值，<strong>那么结果是 5 个字节，其中没有 buf 字段</strong>.</p><p><strong>注 </strong>：关于柔性数组的介绍，可以参考这篇博客 <a href="http://blog.csdn.net/u013165704/article/details/53733412" target="_blank" rel="noopener"> 结构体中使用柔性数组</a>。<br>下面画了一个内存简易图可以帮助理解：</p><center><img src="https://s1.ax1x.com/2018/10/28/icwIM9.jpg" srcset="/img/loading.gif" width="600"/></center><h2 id="SDS- 宏定义">SDS 宏定义</h2><pre><code class="language-c">// sds 类型#define SDS_TYPE_5 0#define SDS_TYPE_8 1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4// 类型掩码，与 flag 相与，可以得到低三位#define SDS_TYPE_MASK 7// 类型占用的比特位数#define SDS_TYPE_BITS 3// 获得 sds header 头指针#define SDS_HDR_VAR(T, s) struct sdshdr##T *sh = (void *)((s) - (sizeof(struct sdshdr##T)));#define SDS_HDR(T, s) ((struct sdshdr##T *)((s) - (sizeof(struct sdshdr##T))))// SDS_TYPE_5 类型的 sds，低三位表示 sds type， 高五位表示 sds len#define SDS_TYPE_5_LEN(f) ((f) &gt;&gt; SDS_TYPE_BITS)</code></pre><h2 id="SDS- 函数">SDS 函数</h2><h3 id="创建 -sds">创建 sds</h3><pre><code class="language-c">sds sdsnewlen(const void *init, size_t initlen) {    void *sh;    sds s;    char type = sdsReqType(initlen); // 根据 initlen 判断需要以哪种类型的 sds 来存储 init    /* Empty strings are usually created in order to append. Use type 8     * since type 5 is not good at this. */    if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8;    int hdrlen = sdsHdrSize(type); // 所选择的 sds 类型的 header 长度    unsigned char *fp; /* flags pointer. */    sh = s_malloc(hdrlen+initlen+1); // 分配 sds 需要的内存：header + str + 1，以 \0 结尾    if (!init)        memset(sh, 0, hdrlen+initlen+1); // 初始化 sds    if (sh == NULL) return NULL;    s = (char*)sh+hdrlen; // s 指向 buf 首元素    fp = ((unsigned char*)s)-1; // fp 指向 flag    switch(type) {// 设置 sds 的 header 各参数        case SDS_TYPE_5: {*fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); // sds5, 第三位为 type，高五位是 len            break;        }        case SDS_TYPE_8: {SDS_HDR_VAR(8,s);            sh-&gt;len = initlen; // len 与 alloc 起始值相同            sh-&gt;alloc = initlen;            *fp = type;            break;        }        case SDS_TYPE_16: {SDS_HDR_VAR(16,s);            sh-&gt;len = initlen;            sh-&gt;alloc = initlen;            *fp = type;            break;        }        case SDS_TYPE_32: {SDS_HDR_VAR(32,s);            sh-&gt;len = initlen;            sh-&gt;alloc = initlen;            *fp = type;            break;        }        case SDS_TYPE_64: {SDS_HDR_VAR(64,s);            sh-&gt;len = initlen;            sh-&gt;alloc = initlen;            *fp = type;            break;        }    }    if (initlen &amp;&amp; init)        memcpy(s, init, initlen); // copy    s[initlen] = '\0';// 结束    return s;}</code></pre><h3 id="释放 -sds">释放 sds</h3><pre><code class="language-c">#define s_free zfreevoid sdsfree(sds s) {if (s == NULL)        return;    s_free((char *)s - sdsHdrSize(s[-1]));}</code></pre><h3 id="扩展 -sds- 容量">扩展 sds 容量</h3><pre><code class="language-c">sds sdsMakeRoomFor(sds s, size_t addlen) {    void *sh, *newsh;    size_t avail = sdsavail(s); // 当前 sds 剩余空间    size_t len, newlen;    char type, oldtype = s[-1] &amp; SDS_TYPE_MASK;    int hdrlen;    /* Return ASAP if there is enough space left. */    if (avail &gt;= addlen) // 需要增加的空间当前的 sds 足以满足，不需要调整 sds        return s;    len = sdslen(s);    sh = (char *)s - sdsHdrSize(oldtype); // header 头指针    newlen = (len + addlen);              // 新的 sds 需要的长度    /* sds 规定：如果扩展后的字符串总长度小于 1M 则新字符串长度加倍     * 否则，新长度为扩展后的总长度加上 1M     * 这样做的目的是减少 Redis 内存分配的次数，同时尽量节省空间 */    if (newlen &lt; SDS_MAX_PREALLOC)        newlen *= 2;    else        newlen += SDS_MAX_PREALLOC;    type = sdsReqType(newlen);    /* Don't use type 5: the user is appending to the string and type 5 is     * not able to remember empty space, so sdsMakeRoomFor() must be called     * at every appending operation. */    if (type == SDS_TYPE_5)        type = SDS_TYPE_8;    hdrlen = sdsHdrSize(type);    if (oldtype == type) {// 新旧 sds 的类型一致，调用 realloc 函数扩充内存        newsh = s_realloc(sh, hdrlen + newlen + 1); // realloc 对 malloc 申请的内存进行大小的调整        if (newsh == NULL)            return NULL;        s = (char *)newsh + hdrlen; // s 指向 buf    }    else {        /* 如果类型调整了，header 的大小就需要调整           这时就需要移动 buf[]部分，所以不能使用 realloc */        newsh = s_malloc(hdrlen + newlen + 1);        if (newsh == NULL)            return NULL;        memcpy((char *)newsh + hdrlen, s, len + 1); // 拷贝        s_free(sh); // 释放之前的 sh 占用的内存        s = (char *)newsh + hdrlen;        s[-1] = type; // 设置 flag        sdssetlen(s, len); // 设置 sds 的 len 字段    }    sdssetalloc(s, newlen); // 设置 sds 的 alloc 字段    return s;}</code></pre><p>另外，redis 提供 <code>sds sdsRemoveFreeSpace(sds s);</code> 函数来回收 sds 空余空间。<br>redis 还提供了很多其他的函数，来方便 sds 的操作，这个可以自行查看 源码</p><h2 id="参考">参考</h2><p>【1】<a href="https://zhuanlan.zhihu.com/p/24202316" target="_blank" rel="noopener">Redis 源码剖析–动态字符串 SDS</a><br>【2】<a href="http://blog.csdn.net/fusan2004/article/details/51817878" target="_blank" rel="noopener">redis 之 sds</a></p>]]></content>
    
    
    <categories>
      
      <category>源码系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux 常用到的文件同步方法</title>
    <link href="/e8a575f7.html"/>
    <url>/e8a575f7.html</url>
    
    <content type="html"><![CDATA[<p>下面总结了一些日常可以用到的 <strong> 文件同步 </strong> 的方法，以方便参考使用。</p><a id="more"></a><h2 id="sftp">sftp</h2><blockquote><p>SFTP ，即 SSH 文件传输协议（ SSH File Transfer Protocol ），或者说是安全文件传输协议（ Secure File Transfer Protocol ）。SFTP 是一个独立的 SSH 封装协议包，通过安全连接以相似的方式工作。它的优势在于可以利用安全的连接传输文件，还能遍历本地和远程系统上的文件系统。在大多数情况下，优先选择 SFTP 而不是 FTP ，原因在于 SFTP 最基本的安全特性和能利用 SSH 连接的能力。FTP 是一种不安全的协议，应当只有在特定的情况下或者你信任的网络中使用。</p></blockquote><p>sftp 这个命令在 linux 上及 mac 上被默认安装了。</p><h3 id="用法">用法</h3><pre><code class="language-shell"># 建立一个 SSH 连接打开一个 SFTP 会话，默认 port 为 22sftp username@remote_hostname_or_IP -p prot# 建立连接后执行 help, 可以看看 sftp 支持哪些命令help# 操作远端服务器pwd/ls/cd# 操作本地lpwd/lls/lcd# 离开quit# 下载文件 a.txt, 以 b.txt 重命名，若没有的话，下载到本地后，依然以 a.txt 的名字存在get a.txt b.txt# 下载 rmtDir 文件夹，以 reDir 名字存在，若没有重新命名，那以源文件夹名字存在get -r rmtDir reDir# 将当前目录下的 a.txt 文件上传到远端服务器的目录下, 以 b.txt 的名字存在，若没有重命名依然是 a.txtput a.txt b.txt# 将本地的 localDir 文件夹下的内容，长传到远端 rmtDir 目录下（这个目录必须存在）put -r localDir/. rmtDir</code></pre><h2 id="nc">nc</h2><blockquote><p>NetCat，在网络工具中有“瑞士军刀”美誉，其有 Windows 和 Linux 的版本。因为它短小精悍（1.84 版本也不过 25k，旧版本或缩减版甚至更小）、功能实用，被设计为一个简单、可靠的网络工具，可通过 TCP 或 UDP 协议传输读写数据。同时，它还是一个网络应用 Debug 分析器，因为它可以根据需要创建各种不同类型的网络连接。通常的 Linux 发行版中都带有 NetCat（简称 nc），但不同的版本，其参数的使用略有差异。</p></blockquote><p>这里只说明 nc 在 <strong> 传输文件 </strong> 方面的应用。</p><h3 id="用法 -v2">用法</h3><p>下面两条命令实现的功能是，将本地的 localfile 上传到 remote_ip，并且以 targetfile 命名。</p><pre><code class="language-sh"># 在远端nc -l port &gt; targetfile# 在本地nc remote_ip remote_port &lt; localfile</code></pre><p>另外，nc 可以做 <strong> 端口扫描 </strong> 工具，命令为</p><pre><code class="language-shell"># -w&lt; 超时秒数 &gt;，扫描 21 到 22 端口， -z 端口扫描模式即零 I/O 模式nc -v -z -w 2 `hostname -i` 21-22</code></pre><h2 id="scp">scp</h2><blockquote><p>scp 是 secure copy 的简写，用于在 Linux 下进行远程拷贝文件的命令，和它类似的命令有 cp，不过 cp 只是在本机进行拷贝不能跨服务器，而且 scp 传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system 时，用 scp 可以帮你把文件移出来。另外，scp 还非常不占资源，不会提高多少系统负荷，在这一点上，rsync 就远远不及它了。虽然 rsync 比 scp 会快一点，但当小文件众多的情况下，rsync 会导致硬盘 I/O 非常高，而 scp 基本不影响系统正常使用。</p></blockquote><h3 id="用法 -v3">用法</h3><pre><code class="language-shell"># 将本地文件 copy 到 remotescp local_file remote_username@remote_ip:remote_folder# 拷贝文件夹scp -r local_folder remote_username@remote_ip:remote_folder# 反过来可以从 remote 到 local</code></pre><h2 id="rsync">rsync</h2><blockquote><p>rsync 命令是一个远程数据同步工具，可通过 LAN/WAN 快速同步多台主机间的文件。rsync 使用所谓的“rsync 算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。</p></blockquote><p>具体配置可以参考文章：<a href="http://www.blogjava.net/Alpha/archive/2011/06/30/353439.html" target="_blank" rel="noopener">linux rsync 同步设置详细指南</a></p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gdb 日常使用</title>
    <link href="/14ffc71.html"/>
    <url>/14ffc71.html</url>
    
    <content type="html"><![CDATA[<p>gdb 是一个由 GNU 开源组织发布的、UNIX/LINUX 操作系统下的、基于命令行的、功能强大的程序调试工具。当然了，一般都是使用 gdb 调试 c/cpp 程序。</p><a id="more"></a><p> 一般来说，GDB 主要帮忙你完成下面四个方面的功能：</p><ol><li> 启动你的程序，可以按照你的自定义的要求随心所欲的运行程序。</li><li> 可让被调试的程序在你所指定的调置的断点处停住。（断点可以是条件表达式）</li><li> 当程序被停住时，可以检查此时你的程序中所发生的事。</li><li> 动态的改变你程序的执行环境。</li></ol><p>gdb 功能很强大，因此命令也很多，但是并不见得都能用得到，对于日常使用来说，知道一些常用的就够用了。</p><h2 id="准备工作"> 准备工作 </h2><p> 代码在编译时要加上 <code>-g</code> 选项，生成的可执行文件才能用 gdb 进行源码级调试。<br>比如，<code>gcc -g main.c -o main</code>。<br><code>-g</code> 选项的作用是在可执行文件中加入源代码的信息，比如可执行文件中第几条机器指令对应源代码的第几行，但并不是把整个源文件嵌入到可执行文件中，所以在调试时必须保证 gdb 能找到源文件。</p><h2 id="参数说明"> 参数说明 </h2><h3 id="list-l">list/l</h3><p><strong>list linenum</strong>，打印出以 linenum 行为中心的上下几行源码。<br><strong>list func</strong>，打印以函数 func 定义所在行为中心的上下几行代码。<br><strong>list</strong>, 打印当前行后面的源程序，每次 10 行。</p><h3 id="run-r">run/r</h3><p> 运行程序至第一个断点处停止。</p><h3 id="break-b">break/b</h3><p><strong>break linenum</strong>，在第 linenum 处设置一个断点。<br><strong>break func</strong>，在 func 函数入口处设置一个断点。</p><h3 id="d">d</h3><p><strong>d 断点 num</strong>，删除第 num 个断点。</p><h3 id="step-s">step/s</h3><p> 执行一行源程序代码，如果此行代码中有函数调用，则进入该函数。</p><h3 id="next-n">next/n</h3><p> 与 step 相反，n 表示不进入函数内容，继续执行。</p><h3 id="print-p">print/p</h3><p><strong>print 变量名 </strong>，打印出变量值。</p><h3 id="backtrace-bt">backtrace/bt</h3><p> 查看各级函数调用及参数。</p><h3 id="frame-f">frame/f</h3><p><strong>frame 帧编号 </strong>，选择栈帧。</p><h3 id="set">set</h3><p><strong>set var 变量 = 值 </strong>，修改某变量的值。<br>或者用 <code>print</code> 指令也能达到目的。</p><h3 id="finish">finish</h3><p> 让程序一直运行到从当前函数返回为止。</p><h3 id="info-i">info/i</h3><p><strong>info break</strong>，查看所有已经设置的断点信息。<br><strong>info locals</strong>，查看当前栈帧局部变量的值。</p><h3 id="shell">shell</h3><p> 不离开 gdb 就执行 UNIX shell 命令 </p><h3 id="help-h">help/h</h3><p> 获取帮助信息。</p><h3 id="quit-q">quit/q</h3><p> 离开 gdb。</p><p><strong> 注意: 上述命令几乎都可以使用首字母来简写长命令。</strong></p><h2 id="调试 -coredump- 文件"> 调试 coredump 文件 </h2><p><strong>gdb 可执行文件 产生的 coredump 文件 </strong>，比如，<code>gdb test core.3533</code>。</p><h2 id="参考"> 参考 </h2><ol><li><a href="http://blog.csdn.net/21cnbao/article/details/7385161" target="_blank" rel="noopener">Linux gdb 调试器用法全面解析 </a></li><li><a href="http://blog.csdn.net/gatieme/article/details/51671430" target="_blank" rel="noopener"> 使用 gdb 调试程序完全教程 </a></li></ol>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gdb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用 shell</title>
    <link href="/d64f6d6a.html"/>
    <url>/d64f6d6a.html</url>
    
    <content type="html"><![CDATA[<p>对一些经常用到的 shell 命令做简要的总结，方便日后查阅。</p><a id="more"></a><h3 id="tcpdump">tcpdump</h3><p><strong>tcpdump</strong> 命令用来保存和记录网络流量，即抓包工具。你可以用它来观察网络上发生了什么，并可用来解决各种各样的问题，包括和网络通信无关的问题。</p><p>Tcpdump 中的关键字主要有以下几种<br>1. 关于类型的关键字主要包括：host、net、port。如果没有指定类型，缺省的类型是 host.<br>2. 关于确定传输方向的关键字主要包括：src、dst、dst or src、 dst and src。如果没有指明方向关键字，则缺省是 src or dst 关键字<br>3. 关于协议的关键字，主要包括 ip、arp、rarp、tcp、udp、icmp 等类型。如果没有指定任何协议，则 tcpdump 将会监听所有协议的信息包。<br>4. 其他重要的关键字：gateway, broadcast, less, greater。<br>5. 三种逻辑运算: 取非运算是’not ’ ，’! ‘；与运算是’and’，’&amp;&amp;’; 或运算 是’or’，‘││’。多条件时可以用括号，但是要用转义。</p><p>** 注意：** 该工具使用 <strong>sudo</strong> 权限去执行！</p><h4 id="常用参数解析">常用参数解析</h4><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>-w</td><td>指定抓取到的数据包的保存位置</td></tr><tr><td>-i</td><td>指定抓取哪个网口的数据包，默认是 eth0</td></tr><tr><td>-s</td><td>指定从一个包中截取的字节数。0 表示包不截断，抓完整的数据包</td></tr><tr><td>-S</td><td>将 tcp 的序列号以绝对值形式输出，而不是相对值</td></tr><tr><td>-n</td><td>指定将每个监听到数据包中的域名转换成 IP 地址后显示，不把网络地址转换成名字</td></tr><tr><td>-nn</td><td>指定将每个监听到的数据包中的域名转换成 IP、端口从应用名称转换成端口号后显示</td></tr><tr><td>-c</td><td>指定要抓取多少数据包，默认会一直抓取，直到 ctrl+c</td></tr><tr><td>-v</td><td>输出一个稍微详细的信息，例如在 ip 包中可以包括 ttl 和服务类型的信息</td></tr><tr><td>-vv</td><td>输出详细的报文信息</td></tr><tr><td>-A</td><td>以 ASCII 格式打印出所有分组，并将链路层的头最小化</td></tr><tr><td>-e</td><td>打印出数据链路层的头部信息，包括源 mac 和目的 mac，以及网络层的协议</td></tr><tr><td>-X</td><td>把协议头和包内容都原原本本的显示出来（tcpdump 会以 16 进制和 ASCII 的形式显示）</td></tr><tr><td>-r</td><td>从指定的文件中读取包(这些包一般通过 -w 选项产生)</td></tr></tbody></table><p>更多详细参数可以参考<a href="http://www.ha97.com/4550.html" target="_blank" rel="noopener">Linux 抓包工具 tcpdump 详解</a></p><h4 id="举个栗子">举个栗子</h4><pre><code>tcpdump -w /tmp/data -s0 -i eth0 port 3000 and host 127.0.0.1</code></pre><p>截获流经 eth0 网口，3000 端口，并且主机地址为 127.0.0.1 收到的和发出的所有的完整（不截断）数据包，并将这些数据包保存在 /tmp/data 文件中。</p><pre><code>tcpdump 'host 210.27.48.1 and (210.27.48.2 or 210.27.48.3)'</code></pre><p>截获主机 210.27.48.1 和主机 210.27.48.2 或 210.27.48.3 的通信数据包。</p><pre><code>tcpdump ip host 210.27.48.1 and ! 210.27.48.2</code></pre><p>获取主机 210.27.48.1 除了和主机 210.27.48.2 之外所有主机通信的 ip 包</p><h4 id="数据包解析">数据包解析</h4><p>抓到的数据包都会有一个类型标识：</p><ul><li>[S] – SYN (开始连接)</li><li>[S.] - SYN-ACK 数据包</li><li>[.] – 没有标记</li><li>[P] – PSH (数据推送)</li><li>[F] – FIN (结束连接)</li><li>[R] – RST (重启连接)</li></ul><p>其他很容易弄懂，暂不解释。</p><h3 id="strace">strace</h3><p><strong>strace</strong> 常用来跟踪进程执行时的系统调用和所接收的信号。 在 Linux 世界，进程不能直接访问硬件设备，当进程需要访问硬件设备 (比如读取磁盘文件，接收网络数据等等) 时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace 可以跟踪到一个进程产生的系统调用, 包括参数，返回值，执行消耗的时间。</p><h4 id="常用参数解析 -v2">常用参数解析</h4><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>-o filename</td><td>将 strace 的输出写入文件 filename</td></tr><tr><td>-p pid</td><td>跟踪指定的进程 pid</td></tr><tr><td>-f</td><td>跟踪由 fork 调用所产生的子进程</td></tr><tr><td>-ff</td><td>如果提供 -o filename, 则所有进程的跟踪结果输出到相应的 filename.pid 中,pid 是各进程的进程号</td></tr><tr><td>-tt</td><td>在输出中的每一行前加上时间信息, 微秒级</td></tr><tr><td>-T</td><td>显示每一调用所耗的时间</td></tr><tr><td>-s strsize</td><td>指定输出的字符串的最大长度. 默认为 32. 文件名一直全部输出</td></tr></tbody></table><h3 id="lsof">lsof</h3><blockquote><p>lsof（list open files）是一个查看当前系统文件的工具。在 linux 环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。</p></blockquote><h4 id="常用参数解析 -v3">常用参数解析</h4><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>-p&lt; 进程号 &gt;</td><td>列出指定进程号所打开的文件</td></tr><tr><td>-i&lt; 条件 &gt;</td><td>列出符合条件的进程。（4、6、协议、: 端口、 @ip ）</td></tr><tr><td>-n</td><td>不把网络地址转换成名字</td></tr><tr><td>-P</td><td>不转换端口号，用数字表示</td></tr><tr><td>-c&lt; 进程名 &gt;</td><td>列出指定进程所打开的文件</td></tr><tr><td>-u user</td><td>某个用户打开的文件</td></tr><tr><td>-d&lt; 文件号 &gt;</td><td>列出占用该文件号的进程</td></tr><tr><td>-g gid</td><td>某个用户组打开的文件</td></tr></tbody></table><h4 id="输出解析">输出解析</h4><ul><li>COMMAND：进程的名称</li><li>PID：进程标识符</li><li>PPID：父进程标识符（需要指定 -R 参数）</li><li>USER：进程所有者</li><li>PGID：进程所属组</li><li>FD：文件描述符，应用程序通过文件描述符识别该文件。如 cwd、txt 等</li><li>TYPE：文件类型，如 DIR、REG 等</li><li>DEVICE：指定磁盘的名称</li><li>SIZE：文件的大小</li><li>NODE：索引节点（文件在磁盘上的标识）</li><li>NAME：打开文件的确切名称</li></ul><p>一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u 等<br>（1）u：表示该文件被打开并处于读取 / 写入模式<br>（2）r：表示该文件被打开并处于只读模式<br>（3）w：表示该文件被打开并处于只写模式<br>（4）空格：表示该文件的状态模式为 unknow，且没有锁定<br>（5）-：表示该文件的状态模式为 unknow，且被锁定</p><p>更多参数解析请参考<a href="http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/lsof.html" target="_blank" rel="noopener">lsof 一切皆文件</a></p><h4 id="举个栗子 -v2">举个栗子</h4><pre><code class="language-shell">lsof /bin/bash -u username</code></pre><p>列出与 <code>/bin/bash</code> 文件相关的，且 <code>username</code> 用户打开的进程</p><pre><code class="language-shell">lsof -p 1223 -i tcp:8000 -n -P</code></pre><p>列出 1223 进程在 8000 端口打开的 tcp 连接，地址和端口保留数字，不做转换</p><pre><code class="language-shell">lsof -d 2-3</code></pre><p>根据文件描述列出对应的文件信息</p><h3 id="pidof">pidof</h3><p>pidof 用于找出正在运行的程序的进程 PID（用空格分割），程序可以是一个二进制执行程序，也可以是一个 shell 脚本。</p><p>-s 参数只列出一个</p><h3 id="tr">tr</h3><p>tr 用来从标准输入中通过替换或删除操作进行字符转换.</p><h4 id="常用参数">常用参数</h4><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>-d</td><td>删除所有属于第一字符集的字符</td></tr><tr><td>-s</td><td>把连续重复的字符以单独一个字符表示</td></tr></tbody></table><h4 id="举个栗子 -v3">举个栗子</h4><pre><code class="language-shell">echo &quot;HELLO WORLD&quot; | tr 'A-Z' 'a-z'</code></pre><p>将大写字母转换成小写字母</p><pre><code class="language-shell">echo &quot;hello 123 world 456&quot; | tr -d '0-9'</code></pre><p>从字符串中删除数字</p><pre><code class="language-shell">echo &quot;hello world&quot; | tr &quot; &quot; ,</code></pre><p>空格换成逗号</p><p><span style="font-size:20px;"><strong>To be continued…</strong></span></p><h3 id="参考">参考</h3><ol><li><a href="http://blog.csdn.net/hzhsan/article/details/43445787" target="_blank" rel="noopener">tcpdump 参数解析及使用详解</a></li><li><a href="http://blog.jobbole.com/91631/" target="_blank" rel="noopener">一份快速实用的 tcpdump 命令参考手册</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shell</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>golang 中的 json 处理</title>
    <link href="/fef1a660.html"/>
    <url>/fef1a660.html</url>
    
    <content type="html"><![CDATA[<p><strong>JSON</strong>（Javascript Object Notation）已经成为了一种非常流行的数据交换格式，golang 自然不会忽视对 json 的支持，golang 自带的标准库就可以方便的处理 json。另外，推荐一种号称 <strong> 全世界最快的 JSON 解析器</strong> – <code>jsoniter</code>。</p><a id="more"></a><h2 id="简介">简介</h2><p>json 中提供的处理 json 的标准包是 <code>encoding/json</code>, 主要使用的是以下两个方法：</p><pre><code class="language-go">// 序列化func Marshal(v interface{}) ([]byte, error)// 反序列化func Unmarshal(data []byte, v interface{}) error</code></pre><p>序列化前后的数据结构有以下的对应关系：</p><pre><code class="language-go">bool, for JSON booleansfloat64, for JSON numbersstring, for JSON strings[]interface{}, for JSON arraysmap[string]interface{}, for JSON objectsnil for JSON null</code></pre><h2 id="Unmarshal">Unmarshal</h2><p>这是一个反序列化的过程，将 JSON 串重新组装成结构体。</p><h3 id="已知解析类型">已知解析类型</h3><p><i class="fa fa-code" aria-hidden="true"></i>示例代码如下：</p><pre><code class="language-go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)type Animal struct {    Name  string    Order string}func main() {var jsonBlob = []byte(`[{&quot;Name&quot;: &quot;Platypus&quot;, &quot;Order&quot;: &quot;Monotremata&quot;},        {&quot;Name&quot;: &quot;Quoll&quot;,    &quot;Order&quot;: &quot;Dasyuromorphia&quot;}    ]`)    var animals []Animal    err := json.Unmarshal(jsonBlob, &amp;animals)    if err != nil {fmt.Println(&quot;error:&quot;, err)    }    fmt.Printf(&quot;%+v&quot;, animals)}</code></pre><p>运行后，输出结果：<code>[{Name:Platypus Order:Monotremata} {Name:Quoll Order:Dasyuromorphia}]</code><br>可以看出，结构体字段名与 JSON 里的 KEY 一一对应.<br>例如 JSON 中的 KEY 是 <strong>Name</strong>，那么怎么找对应的字段呢？</p><ul><li>首先查找 tag 含有 Name 的可导出的 struct 字段(首字母大写)</li><li>其次查找字段名是 Name 的导出字段</li><li>最后查找类似 NAME 或者 NAmE 等这样的除了首字母之外其他大小写不敏感的导出字段</li></ul><p><i class="fa fa-exclamation-triangle" aria-hidden="true"></i> <strong>能够被赋值的字段必须是可导出字段！！</strong></p><blockquote><p>同时 JSON 解析的时候只会解析能找得到的字段，找不到的字段会被忽略，这样的一个 <strong> 好处 </strong> 是：当你接收到一个很大的 JSON 数据结构而你却只想获取其中的部分数据的时候，你只需将你想要的数据对应的字段名大写，即可轻松解决这个问题。</p></blockquote><h3 id="未知解析类型">未知解析类型</h3><p>前面说的是，已知要解析的类型，比如说，当看到 JSON arrays 时定义一个 golang 数组进行接收数据， 看到 JSON objects 时定义一个 map 来接收数据，那么这个时候怎么办？答案是使用 interface{} 进行接收，然后配合 <strong>type assert</strong> 进行解析，比如：</p><pre><code class="language-go">var f interface{}b := []byte(`{&quot;Name&quot;:&quot;Wednesday&quot;,&quot;Age&quot;:6,&quot;Parents&quot;:[&quot;Gomez&quot;,&quot;Morticia&quot;]}`)json.Unmarshal(b, &amp;f)for k, v := range f.(map[string]interface{}) {switch vv := v.(type) {    case string:        fmt.Println(k, &quot;is string&quot;, vv)    case int:        fmt.Println(k, &quot;is int &quot;, vv)    case float64:        fmt.Println(k, &quot;is float64 &quot;, vv)    case []interface{}:        fmt.Println(k, &quot;is array:&quot;)        for i, j := range vv {fmt.Println(i, j)        }    }}</code></pre><h2 id="Marshal">Marshal</h2><p>这是序列化的过程，将结构体序列化成一个 JSON 串。<br><i class="fa fa-code" aria-hidden="true"></i>示例代码如下：</p><pre><code class="language-go">package mainimport (    &quot;encoding/json&quot;    &quot;fmt&quot;)type Animal struct {    Name  string `json:&quot;name&quot;`    Order string `json:&quot;order&quot;`}func main() {var animals []Animal    animals = append(animals, Animal{Name: &quot;Platypus&quot;, Order: &quot;Monotremata&quot;})    animals = append(animals, Animal{Name: &quot;Quoll&quot;, Order: &quot;Dasyuromorphia&quot;})    jsonStr, err := json.Marshal(animals)    if err != nil {fmt.Println(&quot;error:&quot;, err)    }    fmt.Println(string(jsonStr))}</code></pre><p>运行后，输出结果：</p><p><code>[{&quot;name&quot;:&quot;Platypus&quot;,&quot;order&quot;:&quot;Monotremata&quot;},{&quot;name&quot;:&quot;Quoll&quot;,&quot;order&quot;:&quot;Dasyuromorphia&quot;}]</code></p><p>可以发现，序列化得到的 json 串的 key 名字跟结构体 json tag 后指定的名字一样.<br>当结构体字段后无 json tag 时，得到的 json 串的 key 名与字段名一致。<br><strong>json tag</strong> 有很多值可以取，同时有着不同的含义，比如：</p><ul><li>tag 是 “-”，表示该字段不会输出到 JSON.</li><li>tag 中带有自定义名称，那么这个自定义名称会出现在 JSON 的字段名中，比如上面小写字母开头的 <code>name</code>.</li><li>tag 中带有 <strong>“omitempty”</strong> 选项，那么如果该字段值为空，就不会输出到 JSON 串中.</li><li>如果字段类型是 bool, string, int, int64 等，而 tag 中带有 **&quot;,string&quot;** 选项，那么该字段在输出到 JSON 时，会把该字段对应的值转换成 JSON 字符串.</li></ul><h2 id="推荐的 -json- 解析库">推荐的 json 解析库</h2><blockquote><p>jsoniter（json-iterator）是一款快且灵活的 JSON 解析器，同时提供 Java 和 Go 两个版本。从 dsljson 和 jsonparser 借鉴了大量代码。</p></blockquote><p>jsoniter 的 Golang 版本可以比标准库（encoding/json）快 6 倍之多, 而且这个性能是在不使用代码生成的前提下获得的。</p><p>可以使用 <code>go get github.com/json-iterator/go</code> 进行获取，完全兼容标准库的 <code>Marshal</code> 和 <code>Unmarshal</code>方法。<br>使用时导入 <code>github.com/json-iterator/go</code> 代替标准库，基本用法如下：</p><pre><code class="language-go">jsoniter.Marshal(&amp;data)jsoniter.Unmarshal(input, &amp;data)</code></pre><h2 id="参考">参考</h2><ol><li><a href="https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/07.2.md" target="_blank" rel="noopener">JSON 处理</a></li><li><a href="http://jsoniter.com/index.cn.html" target="_blank" rel="noopener">json iterator</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux 命令之 curl</title>
    <link href="/d904ea3d.html"/>
    <url>/d904ea3d.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>curl 命令是一个利用 URL 规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称 curl 为下载工具。它支持包括 HTTP、HTTPS、ftp 等众多协议，还支持 POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl 可以助一臂之力。</p></blockquote><a id="more"></a><h2 id="常用选项"> 常用选项 </h2><h3 id="抓取页面信息"><strong> 抓取页面信息 </strong></h3><p><code>-o</code> 将文件保存为命令行中指定的文件名的文件中 <br><code>-O</code> 使用 URL 中默认的文件名保存文件到本地 </p><pre><code class="language-shell"> # 将文件下载到本地并命名为 mygettext.htmlcurl -o mygettext.html http://www.gnu.org/software/gettext/manual/gettext.html# 将文件保存到本地并命名为 gettext.html，后面的 url 可以写正则curl -O http://www.gnu.org/software/gettext/manual/gettext.html# -O -O 可以同时下载多个文件# 不加这个选项会直接打印到标准输出</code></pre><h3 id="网页重定向"> 网页重定向 </h3><p> 有些网页，比如 <code>www.sina.com</code>, 发生了跳转，直接 curl 的话无法获得网页源码，这时需要加 <code>-L</code> 选项 </p><pre><code class="language-shell"># 遇到重定向时，使用该选项可以将请求重定向到新的地址上curl -L www.sina.com</code></pre><h3 id="断点续传"> 断点续传 </h3><p> 当 curl 网页时中途终端，可以使用 <code>-C</code> 选项来接着已经完成的下载，已经下载过的文件不会被重新下载。</p><pre><code class="language-shell"># 当文件在下载完成之前结束该进程$ curl -O http://www.gnu.org/software/gettext/manual/gettext.html##############             20.1%$ curl -C -O http://www.gnu.org/software/gettext/manual/gettext.html###############            21.1%</code></pre><h3 id="获得请求信息或通信过程"> 获得请求信息或通信过程 </h3><p><code>-i</code> 显示 http response 的头信息，连同网页代码一起。<br><code>-I/--head</code> 只显示 response 头部信息。<br><code>-v</code> 显示一次 http 通信的整个过程，包括端口连接和 http request 头信息。<br>或者使用下面的命令获得更详细的通信过程：<br><code>curl --trace output.txt www.sina.com</code></p><h3 id="发送表单信息"> 发送表单信息 </h3><p> 对于 <strong>GET</strong> 方法，由于参数数据在 url 上，因此，可以直接 curl，这也是 curl 默认方法。<br>对于其他方法，则需要使用 <code>-X</code> 选项进行指定，如 POST、DELETE 等。</p><pre><code class="language-shell">$ curl -X POST --data &quot;data=xxx&quot; example.com</code></pre><p><code>--data</code> 等同于 <code>-d</code>，有以下几种用法：</p><pre><code class="language-shell">-d @file # 将提交的参数放在文件里-d &quot;string&quot; # 多参数形式为 xxx&amp;xxx--data &quot;string&quot;--data-ascii &quot;string&quot;--data-binary &quot;string&quot;--data-urlencode &quot;string # 含有特殊符号的需要进行 url 编码</code></pre><h3 id="伪造头部信息"> 伪造头部信息 </h3><p><code>-e/--referer &lt;url&gt;</code> 选项可以伪造来源网址。</p><pre><code class="language-shell"># 假装是从 http://www.google.com 页面跳转到目的页面的$ curl --referer http://www.google.com http://man.linuxde.net</code></pre><p><code>-A/--user-agent &lt;string&gt;</code> 选项可以伪造 UA。</p><pre><code class="language-shell">curl URL -A &quot;Mozilla/5.0&quot;</code></pre><p><code>-H/--header</code> 自定义头部信息 </p><pre><code class="language-shell">curl -H &quot;Host:man.linuxde.net&quot; -H &quot;accept-language:zh-cn&quot; &lt;url&gt;</code></pre><p><code>-x/--proxy &lt;host[:port]&gt;</code> 设置代理 </p><h3 id="设置 -cookie"> 设置 cookie</h3><p><code>-b/--cookie &lt;name=val/file&gt;</code> 选项用来设置 cookie 或者从指定文件中读取 cookie 信息发起 http 请求。</p><pre><code class="language-shell">$ curl --cookie &quot;name=xxx;pass=xxx&quot; www.example.com</code></pre><p><code>-c/--cookie-jar &lt;file&gt;</code> 选项可以将 cookies 保存到指定文件。</p><h3 id="用户认证"> 用户认证 </h3><p><code>-u/--user &lt;user[:password]&gt;</code> 进行 http/ftp 的认证 </p><blockquote><p> 下载文件 </p></blockquote><p>$ curl -u name:password <a href="http://www.example.com" target="_blank" rel="noopener">www.example.com</a></p><blockquote></blockquote><p>$ curl -O <a href="ftp://name:passwd@ip" target="_blank" rel="noopener">ftp://name:passwd@ip</a>:port/demo/curtain/bbstudy_files/style.css</p><blockquote><p> 上传文件 </p></blockquote><p>$ curl -T test.sql <a href="ftp://name:passwd@ip" target="_blank" rel="noopener">ftp://name:passwd@ip</a>:port/demo/curtain/bbstudy_files/</p><h3 id="限速与限额"> 限速与限额 </h3><p><code>--limit-rate &lt;rate&gt; </code> 选项设置传输速度 </p><pre><code class="language-shell">curl URL --limit-rate 50k</code></pre><p><code>--max-filesize &lt;bytes&gt;</code> 选项设置最大下载的文件总量 </p><pre><code class="language-shell">curl URL --max-filesize bytes</code></pre><h2 id="参考"> 参考 </h2><p>【1】 <a href="http://aiezu.com/article/linux_curl_command.html" target="_blank" rel="noopener">Linux curl 命令详解 </a><br>【2】<a href="http://blog.51yip.com/linux/1049.html" target="_blank" rel="noopener">linux curl 命令详解，以及实例 </a><br>【3】<a href="http://www.ruanyifeng.com/blog/2011/09/curl.html" target="_blank" rel="noopener">curl 网站开发指南 </a></p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shell</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>golang 标准库之 flag 包</title>
    <link href="/1e9de668.html"/>
    <url>/1e9de668.html</url>
    
    <content type="html"><![CDATA[<p>命令行参数常用来为命令行程序指定选项。比如在 <code>wc -l </code> 命令中 <code>-l</code> 就是命令行参数。</p><p>golang 提供了 flag 包来支持基本的命令行参数解析。</p><a id="more"></a><h3 id="命令行语法">命令行语法</h3><p>命令行语法如下：</p><pre><code class="language-go">-flag-flag=x-flag x  // non-boolean flags only</code></pre><h3 id="基本用法">基本用法</h3><h4 id="定义 -flag- 参数">定义 flag 参数</h4><p><strong>方法一</strong>：<br>通过 <code>flag.Xxx()</code> 方法返回一个相应的指针，举几个栗子：</p><pre><code class="language-go">wordPtr := flag.String(&quot;word&quot;, &quot;foo&quot;, &quot;a string&quot;)numbPtr := flag.Int(&quot;numb&quot;, 42, &quot;an int&quot;)boolPtr := flag.Bool(&quot;fork&quot;, false, &quot;a bool&quot;)</code></pre><p>使用形式为 <code>flag.Type(name, defValue, usage)</code></p><p><strong>方法二</strong>：<br>通过 <code>flag.XxxVar()</code> 方法将 flag 绑定到一个变量，该种方式返回值类型，举个栗子：</p><pre><code class="language-go">var svar stringflag.StringVar(&amp;svar, &quot;svar&quot;, &quot;bar&quot;, &quot;a string var&quot;)</code></pre><p>使用形式为 <code>flag.TypeVar(&amp;flagvar, name, defValue, usage)</code><br><strong>方法三</strong>：<br>通过 <code>flag.Var()</code> 绑定自定义类型，自定义类型需要实现 <code>Value</code> 接口 (<code>Receives</code> 必须为指针)，</p><pre><code class="language-go">type Value interface {String() string        Set(string) error}</code></pre><p>使用方式是 <code>flag.Var(&amp;flagvar, name, usage)</code></p><h4 id="解析">解析</h4><p>调用 <code>flag.Parse()</code> 解析命令行参数到定义的 flag</p><h4 id="其他">其他</h4><p>还可通过 <code>flag.Args()</code>, <code>flag.Arg(i)</code> 来获取非 flag 命令行参数</p><h4 id="栗子">栗子</h4><pre><code class="language-go">package mainimport &quot;flag&quot;import &quot;fmt&quot;import &quot;strconv&quot;type percentage float32func (p *percentage) Set(s string) error {v, err := strconv.ParseFloat(s, 32)    *p = percentage(v)    return err}func (p *percentage) String() string { return fmt.Sprintf(&quot;%f&quot;, *p) }func main() {namePtr := flag.String(&quot;name&quot;, &quot;lyh&quot;, &quot;user's name&quot;)    agePtr := flag.Int(&quot;age&quot;, 22, &quot;user's age&quot;)    vipPtr := flag.Bool(&quot;vip&quot;, true, &quot;is a vip user&quot;)    var email string    flag.StringVar(&amp;email, &quot;email&quot;, &quot;lyhopq@gmail.com&quot;, &quot;user's email&quot;)    var pop percentage    flag.Var(&amp;pop, &quot;pop&quot;, &quot;popularity&quot;)    flag.Parse()    others := flag.Args()    fmt.Println(&quot;name:&quot;, *namePtr)    fmt.Println(&quot;age:&quot;, *agePtr)    fmt.Println(&quot;vip:&quot;, *vipPtr)    fmt.Println(&quot;pop:&quot;, pop)    fmt.Println(&quot;email:&quot;, email)    fmt.Println(&quot;other:&quot;, others)}$ ./command-line-flagsname: lyhage: 22vip: trueemail: lyhopq@gmail.comother: []$ ./command-line-flags -name golang -age 4 -vip=true -pop 99 简洁 高并发 等等name: golangage: 4vip: truepop: 99email: lyhopq@gmail.comother: [简洁 高并发 等等]$ ./command-line-flags -hUsage of ./command-line-flags: -age=22: user's age -email=&quot;lyhopq@gmail.com&quot;: user's email -name=&quot;lyh&quot;: user's name -pop=0.0: popularity -vip=true: is a vip user</code></pre><h3 id="参考">参考</h3><ol><li><a href="http://faberliu.github.io/2014/11/12/Golang-flag%E5%8C%85%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3-%E4%B8%80/" target="_blank" rel="noopener">Golang flag 包使用详解(一)</a></li><li><a href="https://gobyexample.com/command-line-flags" target="_blank" rel="noopener">Go by Example: Command-Line Flags</a></li><li><a href="https://www.teakki.com/p/57df64d9da84a0c4533815ee" target="_blank" rel="noopener">Go 语言中使用 flag 包对命令行进行参数解析的方法</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>golang 工具之 present</title>
    <link href="/1cbd4f22.html"/>
    <url>/1cbd4f22.html</url>
    
    <content type="html"><![CDATA[<p>Golang Present 是 Golang 社群开发出來的一个简单工具，通过简单的语法可以制作 ppt（语法近似于 Markdown)。</p><a id="more"></a><h2 id="简介">简介</h2><p>Golang 相关的技术幻灯片有多种格式，以 .ppt, .pdf 和 .slide 为主。<br>.slide 格式是随着 golang 诞生而出现的一种 present 格式，Go 核心开发成员似乎十分喜欢以这种格式分享 Go 语言。在 Golang 官方，几乎所有技术会议的 <a href="https://talks.golang.org/" target="_blank" rel="noopener">talk 幻灯片 </a> 均是以 <strong>.slide</strong> 形式提供的。<strong>.slide</strong> 文件通过 web 服务来进行查看，有一个名为 <code>present</code> 的工具可以在本地查看 <strong>.slide</strong> 文件。</p><h2 id="安装">安装</h2><pre><code class="language-go">// 下载go get -u golang.org/x/tools/cmd/present// 安装go install golang.org/x/tools/cmd/present</code></pre><h2 id="使用">使用</h2><p>在工作目录下, 执行 <code>present</code> 命令，启动一个服务器。<br>比如，我的工作目录是 <code>$GOPATH/src/github.com/golang/talks</code>, 启动服务后，出现下面的提示：</p><pre><code class="language-other">2017/05/13 22:21:21 Open your web browser and visit http://127.0.0.1:3999</code></pre><p>这表明服务启动成功，然后就可以写 slide 文件了。<br>present 文件的语法可以在 <a href="https://godoc.org/golang.org/x/tools/present" target="_blank" rel="noopener"><strong>go doc</strong></a> 中查看</p><p>** 题外话：** 由于某种原因的存在，有些代码使用 <code>go get</code> 无法获取到，这里比较推荐两个网站可能会比较好的解决这个痛点。</p><ul><li><a href="http://golangtc.com/download/package" target="_blank" rel="noopener">golang 中国 </a> 提供的服务</li><li><a href="https://gopm.io/" target="_blank" rel="noopener">go 语言包管理</a> 提供的服务</li></ul><h2 id="参考">参考</h2><p><a href="http://studygolang.com/articles/4703" target="_blank" rel="noopener">Golang 技术幻灯片的查看方法</a><br><a href="http://www.th7.cn/Program/go/201612/1027068.shtml" target="_blank" rel="noopener">[Golang] 來用 Golang Present 製造 Golang 專屬投影片</a></p>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>go 依赖管理 govendor</title>
    <link href="/b5574948.html"/>
    <url>/b5574948.html</url>
    
    <content type="html"><![CDATA[<p>Golang 官方并没有推荐最佳的包管理方案。到了 1.5 版本时代，官方引入包管理的设计，加了 vendor 目录来支持本地包管理依赖。官方 wiki 推荐了多种支持这种特性的包管理工具，如：Godep、gv、gvt、glide、govendor 等。</p><a id="more"></a><p> 下面简要介绍一个我在项目中用到的 – <strong>govendor</strong>。<br>该工具将项目依赖的外部包拷贝到项目下的 vendor 目录下，并通过 vendor.json 文件来记录依赖包的版本，方便用户使用相对稳定的依赖。<br>对于 govendor 来说，依赖包主要有以下多种类型:</p><table><thead><tr><th> 状态 </th><th> 缩写状态 </th><th> 含义 </th></tr></thead><tbody><tr><td>+local</td><td>l</td><td> 本地包，即项目自身的包组织 </td></tr><tr><td>+external</td><td>e</td><td> 外部包，即被 $GOPATH 管理，但不在 vendor 目录下 </td></tr><tr><td>+vendor</td><td>v</td><td> 已被 govendor 管理，即在 vendor 目录下 </td></tr><tr><td>+std</td><td>s</td><td> 标准库中的包 </td></tr><tr><td>+unused</td><td>u</td><td> 未使用的包，即包在 vendor 目录下，但项目并没有用到 </td></tr><tr><td>+missing</td><td>m</td><td> 代码引用了依赖包，但该包并没有找到 </td></tr><tr><td>+program</td><td>p</td><td> 主程序包，意味着可以编译为执行文件 </td></tr><tr><td>+outside</td><td></td><td> 外部包和缺失的包 </td></tr><tr><td>+all</td><td></td><td> 所有的包 </td></tr></tbody></table><h2 id="Installation">Installation</h2><pre><code class="language-go">go get -u github.com/kardianos/govendor</code></pre><p> 命令行执行 <code>govendor</code>，若出现以下信息，则说明安装成功。</p><pre><code class="language-go">➜  ~ govendorgovendor (v1.0.8): record dependencies and copy into vendor folder    -govendor-licenses    Show govendor's licenses.    -version              Show govendor version......</code></pre><p><strong>Warning：</strong> 需要把 <code>$GOPATH/bin/</code> 加到 <code>PATH</code> 中。</p><h2 id="Quickstart">Quickstart</h2><pre><code class="language-go"># Setup your project.cd &quot;my project in GOPATH&quot;# 初始化 vendor 目录, project 下出现 vendor 目录govendor init# Add existing GOPATH files to vendor.govendor add +external# 删掉那些在 vendor 目录中，但是代码中没有使用的包govendor remove +unused# 去掉 github.com/k0kubun/pp 这个包govendor remove github.com/k0kubun/pp# View your work.govendor list# Look at what is using a packagegovendor list -v fmt# Specify a specific version or revision to fetchgovendor fetch golang.org/x/net/context@a4bbce9fcae005b22ae5443f6af064d80a6f5a55# Get latest v1.*.* tag or branch.govendor fetch golang.org/x/net/context@v1# Get the tag or branch named &quot;v1&quot;.govendor fetch golang.org/x/net/context@=v1# Update a package to latest, given any prior version constraintgovendor fetch golang.org/x/net/context# Format your repository onlygovendor fmt +local# Build everything in your repository onlygovendor install +local# Test your repository onlygovendor test +local</code></pre><h2 id="Sub-commands">Sub-commands</h2><pre><code class="language-go">init     创建 vendor 文件夹和 vendor.json 文件list     列出已经存在的依赖包add      从 $GOPATH 中添加依赖包，会加到 vendor.jsonupdate   从 $GOPATH 升级依赖包remove   从 vendor 文件夹删除依赖status   列出本地丢失的、过期的和修改的 packagefetch   从远端库增加新的，或者更新 vendor 文件中的依赖包sync    本地存在 vendor.json 时候拉取依赖包，匹配所记录的版本migrate  Move packages from a legacy tool to the vendor folder with metadata.get     类似 go get，但是会把依赖包拷贝到 vendor 目录license  List discovered licenses for the given status or import paths.shell    Run a &quot;shell&quot; to make multiple sub-commands more efficient for large projects.go tool commands that are wrapped:      `+&lt;status&gt;` package selection may be used with them    fmt, build, install, clean, test, vet, generate, tool</code></pre><p><strong>warning</strong></p><ul><li>The project must be within a <code>$GOPATH/src</code>.</li><li>If using go1.5, ensure you set <code>GO15VENDOREXPERIMENT=1</code>.</li></ul><h2 id="参考"> 参考 </h2><p><a href="https://github.com/kardianos/govendor" target="_blank" rel="noopener">govendor github</a><br><a href="http://blog.csdn.net/yeasy/article/details/65935864" target="_blank" rel="noopener">go 依赖管理利器 – govendor</a></p>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>小白学 golang</title>
    <link href="/d94122d2.html"/>
    <url>/d94122d2.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>Go 是 Google 开发的一种编译型，可并行化，并具有垃圾回收功能的编程语言。它具有脚本化的语法，支持多种编程范式。Go 最给力的地方就是原生的并发编程支持。<br>当然，缺点也是有的，语法糖没有 Python 和 Ruby 多，目前运行速度不及 C，但这正在改善。</p></blockquote><a id="more"></a><p>Go 的安装包可以在 <a href="https://golang.org/" target="_blank" rel="noopener"> 官方网站 </a> 上下载, 不过需要梯子。所以，这里有一个 <a href="http://www.golangtc.com/" target="_blank" rel="noopener">golang 中国网站 </a> 提供了下载。</p><p>​</p><h2 id="几个环境变量">几个环境变量</h2><p><code>GOROOT</code> =&gt; Go 的当前安装目录，一般为 <code>/usr/local/go</code><br><code>GOPATH</code> =&gt; Go 的工作区的集合，以冒号做分割<br><code>GOBIN</code> =&gt; 存放 Go 的可执行文件的目录<br>在修改 <code>PATH</code> 环境变量时，把 <code>$GOROOT/bin:$GOBIN</code> 最后加上。</p><h2 id="工作区目录结构">工作区目录结构</h2><p>项目工作区的文件目录树如下：</p><pre><code class="language-go">├── bin 存放当前工作区中 go 程序的可执行文件├── pkg/ 平台相关目录 存放归档文件（以.a 为后缀）└── src 放源码文件</code></pre><p><strong>注意：</strong><br>当环境变量 GOBIN 已有效设置时，这个目录就没意义了；<br>当 GOPATH 中包含多个工作区路径时，必须设置 GOBIN，否则无法成功安装 go 程序的可执行文件。</p><h2 id="源码文件分类">源码文件分类</h2><p>Go 源码文件以 <code>.go</code> 为后缀。<br>分为三类：命令源码文件、库源码文件和测试源码文件。</p><p><strong>命令源码文件</strong>：声明自己属于 <code>main</code> 代码包，包含无参数声明和结果声明的 <code>main</code> 函数。被安装后，相应的可执行文件被存放到 GOBIN 指定的目录下，或者是当前工作区的 bin 目录下。<br>它其实是 Go 程序的入口。<br><strong>库源码文件 </strong>：不具备上面两条性质的源码文件。被安装后，相应的归档文件被存放到<code> 当前工作区目录 /pkg/ 平台相关目录 /</code>下。<br><strong>测试源码文件</strong>：不具备 2 个特征，但是以 <code>_test.go</code> 为后缀。</p><h2 id="常用命令">常用命令</h2><pre><code>go run 接收一个命令源码文件或者若干个库源码文件为参数    -a 强制编译相关代码，无论是否最新    -n 打印编译过程所需运行的命令，但不真正运行    -x 打印编译过程所需运行的命令，运行    -p n 并行编译    -v 列出被编译的代码包名    -work 显示编译时创建的临时目录名，不删除</code></pre><pre><code class="language-go">go build 编译    -a</code></pre><p>编译库源码文件，没有任何结果，编译命令源码文件，则会出现可执行文件</p><pre><code class="language-go">go install 编译并安装</code></pre><p>安装代码包会在 <code> 当前工作区 /pkg/ 相关平台 /</code>下生成归档文件。</p><pre><code class="language-go">go get 从远程仓库下载并安装代码   -d 只下载，不安装   -fix 下载后先修正，再编译安装   -u 更新已有的代码包及其依赖包</code></pre>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java 第三方包学习之 jsoup</title>
    <link href="/ad4c6b9.html"/>
    <url>/ad4c6b9.html</url>
    
    <content type="html"><![CDATA[<p>使用 python 写爬虫的人，应该都听过 beautifulsoup4 这个包，用来解析 HTML 很方便。现在介绍一个类似于 beautifulsoup4 的 java 第三方库，功能类似。jsoup 是一个解析 HTML 的第三方 java 库，它提供了一套非常方便的 API，可使用 DOM，CSS 以及类 jQuery 的操作方法来取出和操作数据。</p><a id="more"></a><h2 id="简介">简介</h2><p>jsoup 是一个解析 HTML 的第三方 java 库，它提供了一套非常方便的 API，可使用 DOM，CSS 以及类 jQuery 的操作方法来取出和操作数据。<br><strong>jsoup 这个包类似与 python 中流行的 HTML 解析包 Beautifulsoup4。</strong><br>jsoup 实现了 WHATWG HTML5 规范，能够与现代浏览器解析成相同的 DOM。其解析器能够尽最大可能从你提供的 HTML 文档来创建一个干净的解析结果，无论 HTML 的格式是否完整。比如它可以处理：没有关闭的标签，比如：</p><pre><code class="language-html">&lt;p&gt;Lorem &lt;p&gt;Ipsum parses to &lt;p&gt;Lorem&lt;/p&gt; &lt;p&gt;Ipsum&lt;/p&gt;</code></pre><p>隐式标签，创建可靠的文档结构（html 标签包含 head 和 body，在 head 只出现恰当的元素）。<br><strong>官网地址 </strong><a href="https://jsoup.org/" target="_blank" rel="noopener"> 在这里 </a>， 对应的中文文档<a href="http://www.open-open.com/jsoup/parsing-a-document.htm" target="_blank" rel="noopener"> 在这里 </a>，以及 jar 包的<a href="https://jsoup.org/download" target="_blank" rel="noopener"> 下载地址</a>。</p><h2 id="一个文档的对象模型">一个文档的对象模型</h2><ul><li>文档由多个 <strong>Elements</strong> 和<strong>TextNodes</strong>组成 ;</li><li>其继承结构如下：<strong>Document</strong>继承 <strong>Element</strong> 继承 <strong>Node</strong>, <strong>TextNode</strong> 继承 <strong>Node</strong>.</li><li>一个 Element 包含一个子节点集合，并拥有一个父 Element。他们还提供了一个唯一的子元素过滤列表。</li></ul><h2 id="获取 -Document- 对象">获取 Document 对象</h2><p>jsoup 可以从包括字符串、URL 地址以及本地文件来加载 HTML 文档，并生成 Document 对象实例。</p><pre><code class="language-java">// (1)从字符串中获取String html = &quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;First parse&lt;/title&gt;&lt;/head&gt;&quot;  + &quot;&lt;body&gt;&lt;p&gt;Parsed HTML into a doc.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&quot;;Document doc1 = Jsoup.parse(html);// (2)从 URL 直接加载 HTML 文档// get 方法Document doc2 = Jsoup.connect(&quot;http://www.163.com&quot;).get();// post 方法Document doc = Jsoup.connect(&quot;http://example.com&quot;)  .data(&quot;query&quot;, &quot;Java&quot;)  .userAgent(&quot;Mozilla&quot;)  .cookie(&quot;auth&quot;, &quot;token&quot;)  .timeout(3000)  .post();  // (3)从文件中加载 HTML 文档File input = new File(&quot;D:/test.html&quot;);Document doc = Jsoup.parse(input,&quot;UTF-8&quot;,&quot;http://www.163.com/&quot;);</code></pre><p>常用到的方法如下：</p><pre><code class="language-java">public static Connection connect(String url)public static Document parse(String html, String baseUri)public static Document parse(URL url,  int timeoutMillis) throws IOExceptionpublic static Document parse(File in,  String charsetName) throws IOExceptionpublic static Document parse(InputStream in, String charsetName,  String baseUrl)  throws IOException</code></pre><p><strong>parse</strong> 方法能够将输入的 HTML 解析为一个新的文档 (Document），只要解析的不是空字符串，就能返回一个结构合理的文档，其中包含(至少) 一个 head 和一个 body 元素。<br>上面的参数 <strong>baseUri</strong>的作用是，如果要解析的 html 中存在 <strong> 相对路径 </strong>，那么就根据这个参数变成<strong> 绝对路径</strong>, 如果不需要可以传入一个空字符串。</p><p>** 注：** 通过 connect 方法来获得 html 源码，有的时候会遇到乱码的问题，这个时候该怎么办么？方法里有一个 parse 方法，传入参数 InputStream、charsetName 以及 baseUrl，所有可以这样解决：</p><pre><code class="language-java">String url = &quot;http://xxxxxxx&quot;;Document document = Jsoup.parse(new URL(url).openStream(), &quot;GBK&quot;, url);// 以 gbk 编码为栗。</code></pre><p><strong>Jsoup 的强项是解析 html，当然了，它能处理一些简单情况，遇到复杂的情形还是使用 httpClient 这个包吧，你值得拥有！</strong></p><h2 id="解析并提取 -HTML- 元素">解析并提取 HTML 元素</h2><h3 id="使用传统的操作 DOM 的方式">使用传统的操作 DOM 的方式</h3><p>举个栗子</p><pre><code class="language-java">Element content = doc.getElementById(&quot;content&quot;);Elements links = content.getElementsByTag(&quot;a&quot;);Elements mx = content.getElementsByClass(&quot;help&quot;);</code></pre><p><strong>注</strong>：doc 为 Document 对象。<br>还有写常用的方法，比如</p><pre><code class="language-java">public Elements getElementsByAttributeValue(String key,  String value)public Element attr(String attributeKey,  String attributeValue)public Elements getAllElements()// 获得孩子节点中所有的文本拼接public String text()// 获得节点的内部 htmlpublic String html()</code></pre><p>Document 对象还有一个方法</p><pre><code class="language-java">// 获取标题public String title()// 获得某节点的 html，这个方法继承自 Node 类，所以 Element 类也有该方法public String outerHtml()</code></pre><h3 id="选择器">选择器</h3><p>在元素检索方面，jsoup 的选择器简直无所不能。<br>jsoup 选择器很多，这里仅仅举出几个栗子，</p><pre><code class="language-java">Elements links = doc.select(&quot;a[href]&quot;); // 具有 href 属性的 a 标签Elements pngs = doc.select(&quot;img[src$=.png]&quot;);// src 属性以.png 结尾的 img 标签Element masthead = doc.select(&quot;div.masthead&quot;).first();// class 属性为 masthead 的 div 标签中的第一个Elements resultLinks = doc.select(&quot;h3.r &gt; a&quot;); // class 属性为 r 的 h3 标签的直接子 a 标签Elements resultLinks = doc.select(img[src~=(?i)\.(png|jpe?g)])</code></pre><p>Selector 选择器概述</p><pre><code class="language-oth">tagname: 通过标签查找元素，比如：ans|tag: 通过标签在命名空间查找元素，比如：可以用 fb|name 语法来查找 &lt;fb:name&gt; 元素#id: 通过 ID 查找元素，比如：#logo.class: 通过 class 名称查找元素，比如：.masthead[attribute]: 利用属性查找元素，比如：[href][^attr]: 利用属性名前缀来查找元素，比如：可以用[^data-] 来查找带有 HTML5 Dataset 属性的元素[attr=value]: 利用属性值来查找元素，比如：[width=500][attr^=value], [attr$=value], [attr*=value]: 利用匹配属性值开头、结尾或包含属性值来查找元素，比如：[href*=/path/][attr~=regex]: 利用属性值匹配正则表达式来查找元素，比如： img[src~=(?i)\.(png|jpe?g)]*: 这个符号将匹配所有元素</code></pre><p>Selector 选择器组合使用</p><p><code>el#id</code> 元素 +ID，比如： div#logo<br><code>el.class</code> 元素 +class，比如： div.masthead<br><code>el[attr]</code> 元素 +class，比如： a[href]<br><code>任意组合</code> 比如：a[href].highlight<br><code>ancestor child</code> 查找某个元素下子元素，比如：可以用.body p 查找在 &quot;body&quot; 元素下的所有 p 元素<br><code>parent &gt; child</code> 查找某个父元素下的直接子元素，比如：可以用 div.content &gt; p 查找 p 元素，也可以用 body &gt; * 查找 body 标签下所有直接子元素<br><code>siblingA + siblingB</code> 查找在 A 元素之前第一个同级元素 B，比如：div.head + div<br><code>siblingA ~ siblingX</code> 查找 A 元素之前的同级 X 元素，比如：h1 ~ p<br><code>el, el, el</code> 多个选择器组合，查找匹配任一选择器的唯一元素，例如：div.masthead, div.logo</p><p>伪选择器 selectors</p><p><code>:lt(n)</code> 查找哪些元素的同级索引值（它的位置在 DOM 树中是相对于它的父节点）小于 n，比如：td:lt(3) 表示小于三列的元素<br><code>:gt(n)</code>查找哪些元素的同级索引值大于 n，比如： div p:gt(2)表示哪些 div 中有包含 2 个以上的 p 元素<br><code>:eq(n)</code> 查找哪些元素的同级索引值与 n 相等，比如：form input:eq(1)表示包含一个 input 标签的 Form 元素<br><code>:has(seletor)</code> 查找匹配选择器包含元素的元素，比如：div:has§表示哪些 div 包含了 p 元素<br><code>:not(selector)</code> 查找与选择器不匹配的元素，比如： div:not(.logo) 表示不包含 class=logo 元素的所有 div 列表<br><code>:contains(text)</code> 查找包含给定文本的元素，搜索不区分大不写，比如： p:contains(jsoup)<br><code>:containsOwn(text)</code> 查找直接包含给定文本的元素<br><code>:matches(regex)</code> 查找哪些元素的文本匹配指定的正则表达式，比如：div:matches((?i)login)<br><code>:matchesOwn(regex)</code> 查找自身包含文本匹配指定正则表达式的元素</p><p><strong>注：</strong> 上述伪选择器索引是从 0 开始的，也就是说第一个元素索引值为 0，第二个元素 index 为 1 等。<br>对于 Elements 的来历，看这里</p><pre><code class="language-java">public class Elements extends ArrayList&lt;Element&gt;</code></pre><p>另外，可以查看 <a href="https://jsoup.org/apidocs/org/jsoup/select/Selector.html" target="_blank" rel="noopener">Selector API</a> 参考来了解更详细的内容<br>可以看出，jsoup 使用跟 jQuery 一模一样的选择器对元素进行检索，以上的检索方法如果换成是其他的 HTML 解释器，至少都需要很多行代码，而 jsoup 只需要一行代码即可完成。</p><h2 id="修改获取数据">修改获取数据</h2><pre><code class="language-java"> // 为所有链接增加 rel=nofollow 属性doc.select(&quot;div.comments a&quot;).attr(&quot;rel&quot;, &quot;nofollow&quot;); // 为所有链接增加 class=mylinkclass 属性doc.select(&quot;div.comments a&quot;).addClass(&quot;mylinkclass&quot;);// 删除所有图片的 onclick 属性doc.select(&quot;img&quot;).removeAttr(&quot;onclick&quot;);// 清空所有文本输入框中的文本doc.select(&quot;input[type=text]&quot;).val(&quot;&quot;);// 获得 rel 属性的值doc.select(&quot;div.comments a&quot;).attr(&quot;rel&quot;);</code></pre><h2 id="参考">参考</h2><ol><li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-jsouphtml/" target="_blank" rel="noopener">使用 jsoup 对 HTML 文档进行解析和操作</a></li><li><a href="https://jsoup.org/apidocs/" target="_blank" rel="noopener">jsoup 1.9.2 API</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python 标准库之 pickle 模块</title>
    <link href="/9cd13682.html"/>
    <url>/9cd13682.html</url>
    
    <content type="html"><![CDATA[<p>对象存在于程序运行时的内存中，当程序不再运行时或断电关机时，这些对象便不再存在。我现在想把对象保存下来，方便以后使用，这就是持久化技术。</p><a id="more"></a><p>利用 python 标准库中的的 pickle 模块可以将对象转换为一种可以传输或存储的格式。</p><blockquote><p>如果希望透明地存储 python 对象，而不丢失其身份和类型等信息，则需要某种形式的对象序列化：它是一个将任意复杂的对象转成对象的文本或二进制表示的过程。</p></blockquote><h2 id="主要方法">主要方法</h2><p>pickle 模块中有两个主要函数，它们是 <code>dump()</code> 和<code>load()</code>。</p><h3 id="dump- 方法">dump()方法</h3><p>该方法的作用是实现 python 对象的序列化，将 obj 保存到 file 中。<br>具体语法如下：</p><pre><code class="language-python">pickle.dump(obj, file[, protocol])</code></pre><p><strong>obj</strong>：要持久化保存的对象；<br><strong>file</strong>： 将对象序列化后保存到的类文件对象。<br>它必须有一个可以接受单字符串作为入参的 write() 方法。这个对象可以是一个以写模式打开的文件对象或者一个 StringIO 对象，或者其他任意满足条件的接口；<br><strong>protocol</strong>: 可选的参数，默认为 0。0 表示所序列化的对象使用可打印的 ASCII 码表示；1 或 True 表示使用老式的二进制协议；2 表示使用 python2.3 版本引入的新二进制协议，比以前的高效；负值表示将使用可用的最高协议版本。<br>如果 <strong>protocol&gt;=1</strong>，那么文件对象需要以二进制形式打开。</p><h3 id="dumps">dumps()</h3><p>具体语法为：</p><pre><code class="language-python">pickle.dumps(obj[, protocol])</code></pre><p>返回一个字符串，而不是存入文件中。</p><h3 id="load">load()</h3><p>该方法用于反序列化，即将序列化的对象重新恢复成 python 对象。<br>具体语法如下：</p><pre><code class="language-python">pickle.load(file)</code></pre><p>这个 file 必须是一个拥有一个能接收单整数为参数的 <code>read()</code> 方法以及一个不接收任何参数的 <code>readline() </code>方法，并且这两个方法的返回值都应该是字符串。这可以是一个打开为读的文件对象、StringIO 对象或其他任何满足条件的对象。</p><h3 id="loads">loads()</h3><pre><code class="language-python">pickle.loads(string)</code></pre><p>从字符串中恢复对象。</p><h3 id="Pickler">Pickler()</h3><pre><code class="language-python">class pickle.Pickler(file[, protocol])</code></pre><p>可以使用该对象调用 dunmp 和 load 等方法。</p><h3 id="clear-memo">clear_memo()</h3><p>对于相同的对象，如果不使用 clear_memo()方法，那么 python 只会 pickle 一次</p><h2 id="cPickle- 模块">cPickle 模块</h2><blockquote><p>cPickle 是 pickle 的优化版， cPickle 是 C 编写的因此它可以比 pickle 快 1000 倍。但是它不支持使用子类化的 Pickler()和 Unpickler()类，因为在 cPickle 中，这些都是不是类的功能。大多数应用程序不需要此功能，并可以受益于 cPickle 的改进性能。除此之外，这两个模块的接口是几乎完全相同。</p></blockquote><h2 id="用例">用例</h2><pre><code class="language-python">In [2]: try:   ...:     import cPickle as pickle   ...: except:   ...:     import pickle   ...:In [3]: info = [1, 2, 3, 'hello']In [4]: data1 = pickle.dumps(info)In [5]: print data1(lp1I1aI2aI3aS'hello'p2a.In [6]: data2 = pickle.loads(data1)In [7]: print data2[1, 2, 3, 'hello']In [8]: type(data1)Out[8]: str</code></pre>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java 第三方包学习之 lombok</title>
    <link href="/38f80316.html"/>
    <url>/38f80316.html</url>
    
    <content type="html"><![CDATA[<p>**Laziness is a virtue！** 每当写 pojo 类时，都会重复写一些 setter/getter/toString 等大量的模版代码，无聊繁琐又不得不做，这会让这个类变得又臭又长，却没有多少东西。不久前发现有一个 java 第三方库可以一定程度上帮助我们从体力劳动中解救出来，它就是 lombok。它提供了一些简单的注解，并以此来消除 java 中臃肿的模版代码。本文对于一些常用到的注解做了一个简要的记录，希望有更多的人 enjoy it！</p><a id="more"></a><h2 id="Lombok 是什么">Lombok 是什么</h2><p>Lombok 是一个旨在减少代码开发工作的 Java 库。它提供了一些简单的注解，并以此来消除 java 中臃肿的模版代码，比如 pojo 中最常见的 setter/getter 方法， 比如 toString 方法， 比如 equals 方法等等，还可以帮助我们关闭流，即使 JDK7 中已经有了 TWR 特性，但这个包很值得一试。<br>通过几个简单的注解，将模版代码在编译时写入程序。使用 eclipse 可以在 Outline 窗口看到生成的方法，但是在源码里是干净的，</p><h2 id="安装">安装</h2><p>首先去 lombok 的 <a href="http://projectlombok.org/" target="_blank" rel="noopener"> 官网 </a> 下载一个 jar 包。<br>只是把 jar 包下载下来并导入工程中，不会发现 IDE 不识别它的注解，那怎么办？</p><h3 id="对于 eclipse">对于 eclipse</h3><p>将 lombok.jar 复制到 eclipse.ini 所在的目录下，然后编辑 eclipse.ini 文件， 在它的最后面插入以下两行并保存：</p><pre><code class="language-othe">­Xbootclasspath/a:lombok.jar­javaagent:lombok.jar</code></pre><p>接着重启 eclipse 就可以愉快地使用这个库了。</p><h3 id="对于 -IDEA">对于 IDEA</h3><p>在 IntelliJ 的插件中心可以找到它。</p><h2 id="QuickStart">QuickStart</h2><p>Lombok 提供的注解不多，但都好用，简要说一下常用的几个。</p><h3 id="Setter-Getter">@Setter/@Getter</h3><p>这两个注解修饰成员变量，可用于生成 setter/gettter 模版代码。<br>举个栗子：</p><pre><code class="language-java">import lombok.AccessLevel;import lombok.Getter;import lombok.Setter;public class Student {    @Setter @Getter private String name;    @Getter(AccessLevel.PROTECTED) private int age;// 可以指定访问权限    @Setter @Getter private String[] hobbies;}</code></pre><p>将字节码文件反编译后可以看到下面这段代码</p><pre><code class="language-java">public class Student {  private String name;  private int age;  private String[] hobbies;  public String getName() { return this.name;}  public void setName(String name) {this.name = name;}  protected int getAge() { return this.age;}  public String[] getHobbies() {return this.hobbies;}  public void setHobbies(String[] hobbies) {this.hobbies = hobbies;}}</code></pre><h3 id="ToString">@ToString</h3><pre><code class="language-java">import lombok.ToString;@ToString(exclude=&quot;id&quot;)public class ToStringExample {    private int id;    private String name;    private String[] tags;}</code></pre><p>编译后</p><pre><code class="language-java">import java.util.Arrays;public class ToStringExample {public String toString() {return &quot;ToStringExample(name=&quot; + this.name + &quot;, tags=&quot; + Arrays.deepToString(this.tags) + &quot;)&quot;;    }  private int id;  private String name;  private String[] tags;}</code></pre><p>我们发现，对于数组，在写 toString 方法时使用了 Arrays 类的 静态方法 deepToString。<br>来看 eclipse 自动生成的 toString 方法：</p><pre><code class="language-java">@Overridepublic String toString() {    return &quot;ToStringExample [name=&quot; + name + &quot;, tags=&quot;        + Arrays.toString(tags) + &quot;]&quot;;}</code></pre><p>eclipse 中对于数组采用的是 Arrays.toString()。<br><strong>区别</strong>：这两个方法的区别是这样的，对于多维数组，使用 toString 只能打印出内部数组的名字，这时需要使用 deepToString 方法，它能将内部数组的内容全部打印出来。</p><h4 id="exclude- 参数">exclude 参数</h4><p>可以指定哪些属性不出现在 toString 方法中， 比如 <strong>exclude={“id”, “name”}</strong></p><h4 id="doNotUseGetters- 参数">doNotUseGetters 参数</h4><p>当类中有成员变量的 getter 方法时，生成 toString 方法会使用这些 getter 方法，比如</p><pre><code class="language-java">public String toString() {return &quot;ToStringExample(name=&quot; + getName() + &quot;, tags=&quot; + Arrays.deepToString(getTags()) + &quot;)&quot;;    }</code></pre><p>但是将该参数设置为 true 时（默认为 false），生成 toString 方法时就不会使用 getter 方法，而是直接使用这些成员变量，比如</p><pre><code class="language-java">public String toString() {return &quot;ToStringExample(name=&quot; + this.name + &quot;, tags=&quot; + Arrays.deepToString(this.tags) + &quot;)&quot;;    }</code></pre><h4 id="includeFieldNames 参数">includeFieldNames 参数</h4><p>原本是以 <strong>fieldName = fieldValue</strong> 的格式来生成 toString 方法的，但是将该参数设置为 false 后（默认是 true），就不会显示 fieldName 了，而只是生成 fieldValue， 比如</p><pre><code class="language-java">public String toString() {return &quot;ToStringExample(&quot; + getId() + &quot;, &quot; + getName() + &quot;, &quot; + Arrays.deepToString(getTags()) + &quot;)&quot;;  }</code></pre><h4 id="callSuper- 参数">callSuper 参数</h4><p>若类 A 是类 B 的子类，那么在 A 类重写 toString 时，若把该参数设置为 true，会加入下面这段代码，即也会把父类 B 的 toString 也写入。</p><pre><code class="language-java">super=&quot; + super.toString()</code></pre><h3 id="NonNull">@NonNull</h3><p>检查传入对象是否为 Null，若为 null，则抛出 NullPointerException 异常。<br>举个栗子</p><pre><code class="language-java">import lombok.NonNull;public class NonNullExample extends Student{    private String name;    public NonNullExample(@NonNull Student student) {this.name = student.getName();    }}</code></pre><p>编译后代码</p><pre><code class="language-java">import lombok.NonNull;public class NonNullExample extends Student {    private String name;    public NonNullExample(@NonNull Student student) {if (student == null)            throw new NullPointerException(&quot;student&quot;);        this.name = student.getName();}}</code></pre><h3 id="EqualsAndHashCode">@EqualsAndHashCode</h3><p>用在类上，用于生成 equals 和 hashcode 方法。<br>举个栗子</p><pre><code class="language-java">@EqualsAndHashCode(exclude={&quot;id&quot;})public class EqualsAndHashCodeExample {     private transient int transientVar = 10;     private String name;     private double score;     private String[] tags;     private int id;}</code></pre><p>编译后代码</p><pre><code class="language-java">import java.util.Arrays;public class EqualsAndHashCodeExample {public int hashCode() {        int PRIME = 59;        int result = 1;        Object $name = this.name;        result = result * 59 + ($name == null ? 43 : $name.hashCode());        long $score = Double.doubleToLongBits(this.score);        result = result * 59 + (int)($score ^ $score &gt;&gt;&gt; 32);        result = result * 59 + Arrays.deepHashCode(this.tags);        return result;    }    protected boolean canEqual(Object other) {return other instanceof EqualsAndHashCodeExample;}    public boolean equals(Object o) {if (o == this)  return true;        if (!(o instanceof EqualsAndHashCodeExample)) return false;        EqualsAndHashCodeExample other = (EqualsAndHashCodeExample)o;        if (!other.canEqual(this)) return false;        Object this$name = this.name;        Object other$name = other.name;        if (this$name == null ? other$name != null : !this$name.equals(other$name))                     return false;        if (Double.compare(this.score, other.score) != 0)            return false;        return Arrays.deepEquals(this.tags, other.tags);    }    private transient int transientVar = 10;    private String name;    private double score;    private String[] tags;    private int id;}</code></pre><p>可以看出 transient 修饰的变量，不会参与。</p><h4 id="参数">参数</h4><p>参数 of 用来指定参与的变量，其他的跟 <strong>@ToString</strong> 注解类似。</p><h3 id="Data">@Data</h3><p>该注解用于修饰类，会自动生成 getter/setter 方法, 以及重写 equals(), hashcode()和 toString()方法。</p><h3 id="Cleanup">@Cleanup</h3><p>该注解可以用来自动管理资源，用在局部变量之前，在当前变量范围内即将执行完毕退出之前会自动清理资源， 自动生成 try­finally 这样的代码来 <strong> 关闭流</strong>。<br>举个栗子，</p><pre><code class="language-java">import lombok.Cleanup;import java.io.*;public class CleanupExample {public static void main(String[] args) throws IOException {@Cleanup InputStream in = new FileInputStream(args[0]);      @Cleanup OutputStream out = new FileOutputStream(args[1]);        byte[] b = new byte[10000];        while (true) {int r = in.read(b);        if (r == -1) break;        out.write(b, 0, r);       }     }  }</code></pre><h3 id="NoArgsConstructor-RequiredArgsConstructor-AllArgsConstructor">@NoArgsConstructor/@RequiredArgsConstructor/@AllArgsConstructor</h3><p>这三个注解修饰在类上。<br>@NoArgsConstructor 用于生成一个无参构造方法。<br>@RequiredArgsConstructor 会生成一个包含了被 @NotNull 标识的变量的构造方法。同样可以设置生成构造方法的权限，使用 <strong>access</strong>参数进行设置。若指定 staticNam<br>e = “of”参数，同时还会生成一个返回类对象的静态工厂方法，生成的构造方法是私有的。<br>@AllArgsConstructor 会生成一个包含所有变量， 同时如果变量使用了 **@NotNull**，会进行是否为空的校验。<br>举个栗子，</p><pre><code class="language-java">import lombok.*;@RequiredArgsConstructor(staticName = &quot;of&quot;)@AllArgsConstructor(access = AccessLevel.PROTECTED)public class ConstructorExample {    private int x;    private int y;    @NonNull private String desc;    @NoArgsConstructor    public class NoArgsExample{private String field;}}</code></pre><p>这与下面这段代码是等价的，</p><pre><code class="language-java">import java.beans.ConstructorProperties;public class ConstructorExample {public static ConstructorExample of(@lombok.NonNull String desc) {return new ConstructorExample(desc);    }    private ConstructorExample(@lombok.NonNull String desc) {if (desc == null) throw new NullPointerException(&quot;desc&quot;);        this.desc = desc;    }    @ConstructorProperties({&quot;x&quot;, &quot;y&quot;, &quot;desc&quot;})    protected ConstructorExample(int x, int y, @lombok.NonNull String desc) {if (desc == null) throw new NullPointerException(&quot;desc&quot;);        this.x = x;        this.y = y;        this.desc = desc;    }    private int x;    private int y;    @lombok.NonNull    private String desc;    public class NoArgsExample    {        private String field;        public NoArgsExample() {}    }}</code></pre><h3 id="Value">@Value</h3><p>该注解用于修饰类，是 **@Data<strong>的不可变形式， 相当于为成员变量添加</strong>final** 声明， 只提供 getter 方法， 而不提供 setter 方法，<br>然后还有 equals/hashCode/toString 方法，以及一个包含所有参数的构造方法。</p><h3 id="Builder">@Builder</h3><p>用在类、构造器、方法上，为你提供复杂的 builder APIs，让你可以像如下方式调用 Person.builder().name(“A<br>dam Savage”).city(“San Francisco”).job(“Mythbusters”).job(“Unchained Reaction”).build()。<br>举个栗子，</p><pre><code class="language-java">import lombok.Builder;import java.util.Set;@Builderpublic class BuilderExample {    private String name;    private int age;}</code></pre><p>反编译代码如下：</p><pre><code class="language-java">package tutorial.lombok;public class BuilderExample{    public static class BuilderExampleBuilder    {        private String name;        private int age;        public BuilderExampleBuilder name(String name)        {            this.name = name;            return this;        }        public BuilderExampleBuilder age(int age)        {            this.age = age;            return this;        }        public BuilderExample build()        {return new BuilderExample(name, age);        }        public String toString()        {return (new StringBuilder()).append(&quot;BuilderExample.BuilderExampleBuilder(name=&quot;).append(name).append(&quot;, age=&quot;).append(age).append(&quot;)&quot;).toString();}        BuilderExampleBuilder()        {}}    private String name;    private int age;    BuilderExample(String name, int age)    {        this.name = name;        this.age = age;    }    public static BuilderExampleBuilder builder()    {return new BuilderExampleBuilder();    }}</code></pre><p>注意：使用 @Singular 注解的集合属性名必须使用 s 结尾, lombok 会将属性名结尾的 s 去掉, 剩余的名字会作为方法名, 向这个集合中添加元素。<br>@Builder 的参数 builderClassName 设置生成的 builder 方法名，buildMethodName 设置 build 方法名，builderMethodName 设置 builderMethod 方法名。<br>比如,<strong>@Builder(builderClassName = “GBuilder”, buildMethodName = “buildG”, builderMethodName = &quot;GBuilder&quot;</strong></p><h3 id="SneakyThrows">@SneakyThrows</h3><p>自动抛受检异常， 而无需显式在方法上使用 throws 语句。</p><h3 id="Synchronized">@Synchronized</h3><p>用在方法上，将方法声明为同步的，并自动加锁，而锁对象是一个私有的属性 LOCK，而 java 中的 synchronized 关键字锁对象是 this，锁在 this 或者自己的类对象上存在副作用，就是你不能阻止非受控代码去锁 this 或者类对象，这可能会导致竞争条件或者其它线程错误。<br>举个栗子，</p><pre><code class="language-java">import lombok. Synchronized;public class SynchronizedExample {private final Object readLock = new Object() ;    @Synchronized    public static void hello() {System. out. println(&quot;world&quot;) ;    }    @Synchronized(&quot;readLock&quot;)    public void foo() {System. out. println(&quot;bar&quot;) ;    }}</code></pre><p>反编译代码如下：</p><pre><code class="language-java">public class SynchronizedExample {private static final Object $LOCK = new Object[0] ;    private final Object readLock = new Object() ;    public static void hello() {synchronized($LOCK) {System. out. println(&quot;world&quot;) ;        }    }    public int answerToLife() {synchronized($lock) {return 42;}    }    public void foo() {synchronized(readLock) {System. out. println(&quot;bar&quot;) ;        }    }}</code></pre><h3 id="Getter-lazy-true">@Getter(lazy=true)</h3><p>可以替代经典的 Double Check Lock 样板代码。<br>举个栗子，</p><pre><code class="language-java">import lombok.Getter;public class GetterLazyExample {@Getter(lazy=true) private final double[] cached = expensive();    private double[] expensive() {double[] result = new double[1000000];        for (int i = 0; i &lt; result.length; i++) {result[i] = Math.asin(i);        }        return result;    }}</code></pre><p>反编译代码如下，</p><pre><code class="language-java">import java.util.concurrent.atomic.AtomicReference;public class GetterLazyExample{private final AtomicReference cached = new AtomicReference();    public GetterLazyExample()    { }    private double[] expensive()    {double result[] = new double[0xf4240];        for (int i = 0; i &lt; result.length; i++)            result[i] = Math.asin(i);        return result;    }    public double[] getCached()    {Object value = cached.get();        if (value == null)            synchronized (cached)            {value = cached.get();                if (value == null)                {double actualValue[] = expensive();                    value = actualValue != null ? ((Object) (actualValue)) : ((Object) (cached));                    cached.set(value);                }            }        return (double[])(double[])(value != cached ? value : null);    }}</code></pre><h3 id="Log">@Log</h3><p>根据不同的注解生成不同类型的 log 对象， 但是实例名称都是 log， 有六种可选实现类</p><pre><code class="language-java">@CommonsLogCreates log = org. apache. commons. logging. LogFactory. getLog(LogExample. class) ;@LogCreates log = java. util. logging. Logger. getLogger(LogExample. class. getName() ) ;@Log4jCreates log = org. apache. log4j. Logger. getLogger(LogExample. class) ;@Log4j2Creates log = org. apache. logging. log4j. LogManager. getLogger(LogExample. class) ;@Slf4jCreates log = org. slf4j. LoggerFactory. getLogger(LogExample. class) ;@XSlf4jCreates log = org. slf4j. ext. XLoggerFactory. getXLogger(LogExample. class) ;</code></pre><p>举个栗子，</p><pre><code class="language-java">import lombok.extern.java.Log;import lombok.extern.slf4j.Slf4j;@Logpublic class LogExample {public static void main(String... args) {log.error(&quot;Something's wrong here&quot;);    }}@Slf4jpublic class LogExampleOther {public static void main(String... args) {log.error(&quot;Something else is wrong here&quot;);    }}@CommonsLog(topic=&quot;CounterLog&quot;)public class LogExampleCategory {public static void main(String... args) {log.error(&quot;Calling the 'CounterLog' with a message&quot;);    }}</code></pre><pre><code>@CommonsLog(topic=&quot;CounterLog&quot;)</code></pre><p>这条语句会翻译成这样</p><pre><code class="language-java">private static final org.apache.commons.logging.Log log = org.apache.commons.logging.LogFactory.getLog(&quot;CounterLog&quot;);</code></pre>]]></content>
    
    
    <categories>
      
      <category>quick-start</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>爬虫问题总结</title>
    <link href="/4ada5477.html"/>
    <url>/4ada5477.html</url>
    
    <content type="html"><![CDATA[<p>本文档对日常学习中用 python 做数据爬取时所遇到的一些问题做简要记录，以便日后查阅，部分问题可能因为认识不到位会存在一些误解，敬请告知，万分感谢，共同进步。</p><a id="more"></a><h2 id="估算网站规模">估算网站规模</h2><p>该小节主要针对于整站爬取的情况。<br>爬取整站之前，肯定是要先对一个网站的规模进行估计。这是可以使用 google 搜索查看大概有多少个网址，这里使用到 google 搜索的一个小技巧。</p><pre><code class="language-othe">site:url 地址</code></pre><p>有的时候可查看网站的 sitemap.xml，但它有时候会过期或者滞后，不是很准确。</p><h2 id="识别网站所用技术">识别网站所用技术</h2><p>要爬的网站使用的技术会影响到我们所写的代码中的处理手段。<br>推荐使用 <strong>builtwith</strong> 这个第三方包，可以使用 <strong>pip</strong> 来安装。<br>简单使用如下：</p><pre><code class="language-python">In [1]: import builtwithIn [2]: builtwith.parse('http://example.webscraping.com/')Out[2]:{u'javascript-frameworks': [u'jQuery', u'Modernizr', u'jQuery UI'], u'programming-languages': [u'Python'], u'web-frameworks': [u'Web2py', u'Twitter Bootstrap'], u'web-servers': [u'Nginx']}</code></pre><h2 id="伪装成浏览器">伪装成浏览器</h2><p>UA，即 User-Agent，是 Http 协议的一部分，属于头域的组成部分，发送 http 请求时，请求头中会有 <strong>User-Agent</strong>字段。服务器通过该字段来分辨发送请求的浏览器类型、版本、内核以及操作系统信息等。<br>在浏览器 console 可用如下命令来获得该浏览器的 UA 标识 <code>navigator.userAgent</code></p><p>部分网站不想被爬虫爬取就会检查 http 请求头的该字段内容， 所以在用爬虫做抓取时，通常要在请求头加上该字段，以把自己伪装成浏览器。<strong>有时候通过手机浏览器访问得到的页面会更加简洁，更容易抓取，所以伪装成手机浏览器也是一种好方法。</strong><br>网上有很多整理的不同浏览器的 UA ，比如 <a href="http://my.oschina.net/sub/blog/203139" target="_blank" rel="noopener"> 各种浏览器 UserAgent 一览表</a>。<br><a href="http://litten.github.io/2014/09/26/history-of-browser-useragent/" target="_blank" rel="noopener">浏览器野史 UserAgent 列传（上）</a>和 <a href="http://litten.github.io/2014/10/05/history-of-browser-useragent2/" target="_blank" rel="noopener">浏览器野史 UserAgent 列传（下）</a>，这两篇文章细说了 UA 的来龙去脉，去感受下当时波澜壮阔的“浏览器之战”。</p><h2 id="防盗链">防盗链</h2><p>部分服务器会检查 http 请求头的 <strong>Referer</strong> 字段来判断你是否是从指定页面跳转而来的，以达到防盗链的作用。因此在伪装请求头部的时候，该字段也是不容忽视的。</p><h2 id="url- 编码">url 编码</h2><p>我们发现，URL 中有时候存在中文，这是就需要对 url 进行编码。<br>可以先将中文转换成 utf-8 编码，然后使用 urllib2.quote 方法对参数进行 url 编码后传递。</p><pre><code class="language-python">import urllibparam = u'你好'param = param.encode('utf-8')param = urllib.quote(param)</code></pre><p>对于 url 来说，之所以要进行编码，是因为 url 中有些字符会引起歧义。<br>同理使用 unquote 可以解码。</p><h2 id="动态加载问题">动态加载问题</h2><p>经常会遇到这样情况：将网页拖到底部会自动往下加载新的数据，或者有 <strong> 加载更多 </strong> 这样的按钮，这里说的就是 AJAX 了。</p><blockquote><p>AJAX 是 Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）的缩写。它通过使用原有的 web 标准组件，实现了在不重新加载整个页面的情况下，与服务器进行数据交互。例如在新浪微博中，你可以展开一条微博的评论，而不需要重新加载，或者打开一个新的页面。但是这些内容并不是一开始就在页面中的（这样页面就太大了），而是在你点击的时候被加载进来的。这就导致了你抓取这个页面的时候，并不能获得这些评论信息（因为你没有『展开』）。</p><p>AJAX 一般是通过 XMLHttpRequest 对象接口发送请求的，XMLHttpRequest 一般被缩写为 XHR。</p></blockquote><h3 id="通过审查元素找请求的 -js- 地址">通过审查元素找请求的 js 地址</h3><p>这些 js 的名字通常看起来与其他的不太一样。<br>拿 <a href="http://www.thepaper.cn/" target="_blank" rel="noopener"> 澎湃网 </a> 举个栗子，这才是发送请求获得文章的真正地址，</p><center><img src="https://s1.ax1x.com/2018/10/28/icw4xJ.jpg" srcset="/img/loading.gif" width="800" /></center>AJAX 的一种 ** 常见用法 ** 是使用 AJAX 加载 JSON 数据，然后在浏览器端渲染。这种情况很好处理，因为 python 自带的处理 json 的库，举个栗子：[豌豆荚安卓游戏排行榜](http://www.wandoujia.com/top/game)，每次点击更多会加载新的数据。在审查元素里，可以看到每次点击 ** 查看更多 **，都会返回一个包含应用数据详细信息的数据。<center><img src="https://s1.ax1x.com/2018/10/28/icwjRe.jpg" srcset="/img/loading.gif" width="800" /></center>查看请求 json 数据的地址 http://apps.wandoujia.com/api/v1/apps?type=weeklytopgame&max=12&start=60max 参数的值表示这一次请求返回多少个 app 信息， start 参数的值表示从第几个 app 开始，start 从 0 开始。<p>另外，在构建请求头时，应该加上这个参数 <strong>‘X-Requested-With’: ‘XMLHttpRequest’</strong>, 当使用 XHR 发送 AJAX 请求时 Header 会带上这个字段，常被用于判断是不是 AJAX 请求。</p><h3 id="Selenium-PhantomJS">Selenium+PhantomJS</h3><blockquote><p>Selenium 是一个强大的网络数据采集工具，最初是为网站自动测试而开发的。它可以让浏览器自动加载页面，获取所需要的数据，甚至页面截屏，或者判断网站上某些动作事都发生。</p></blockquote><p>对应的 python 库，可以用 pip 安装。<br>PhantomJS 是一个 headless browser，它会把网站加载到内存并执行页面上的 JavaScript，但是不会向用户展示网页的图形界面。<strong>它不是 python 库，需要单独下载 </strong>(喏，你要的<a href="http://phantomjs.org/" target="_blank" rel="noopener"> 官网</a>)。<br>写一个简单的栗子：</p><pre><code class="language-python">from selenium import webdriverfrom selenium.webdriver.common.keys import Keysdriver = webdriver.PhantomJS(executable_path='&lt;Path to PhantomJs&gt;')driver.get(&quot;http://www.python.org&quot;)assert &quot;Python&quot; in driver.titleelem = driver.find_element_by_name(&quot;q&quot;)elem.clear()elem.send_keys(&quot;pycon&quot;)elem.send_keys(Keys.RETURN)assert &quot;No results found.&quot; not in driver.page_sourcedriver.close()</code></pre><p><strong>Path to PhantomJs</strong> 处 需要指定位置，如果该路径已经加入到了环境变量中，那么可以不加这个参数。<br>这里只是个简单的介绍，后续会对 Selenium 的 python 版 API 的使用做单独介绍。</p><h2 id="代理问题">代理问题</h2><p>部分网站对 ip 进行了限制，导致我们无法爬到想要的数据，这个时候可以用代理来做。<br>使用 <strong>requests</strong> 这个第三方库，可以轻松地设置代理。<br>再举个栗子：</p><pre><code class="language-python">import requestsproxies = {  'http': 'http://10.10.1.10:3128',  'https': 'http://10.10.1.10:1080',}requests.get('http://example.org', proxies=proxies)</code></pre><h2 id="发送 -http- 请求">发送 http 请求</h2><p>虽然自带的 urllib 和 urllib2 库可以满足需求，但是不推荐使用。为什么？因为它们的操作太繁琐，尤其在处理一些复杂情况时，这不符合 python 的设计哲学，所以放手抛弃它们吧。<br>推荐使用 <a href="http://docs.python-requests.org/en/latest/" target="_blank" rel="noopener"><strong>requests</strong></a>这个第三方库，正如它标榜的那样–<strong>Requests: HTTP for Humans</strong>，同时也支持 py3。<br>使用 requests 库发送请求是如此的优雅，</p><pre><code class="language-python">import requestsr = requests.get('https://api.github.com/events')print r.text</code></pre><p>具体使用方法可以看官方 API。</p><h2 id="解析页面">解析页面</h2><p>既然获取到了请求页面的源码，那么接下来要做的就是解析工作，一般来说，有下面三个库用得是最多的：<strong>lxml 库， bs4 库，以及正则</strong>。<br><strong>lxml</strong> 解析速度要比 <strong>bs4</strong> 快，据说快好几倍，正则是个终结技，只是写起来有点麻烦。另外， bs4 不支持 <strong>xpath</strong>，而 lxml 支持，总之，视自己的情况选择了。<br>前几天还接触过一个库，名字叫 <strong>pyquery</strong>，它是 jQuery 的 python 实现，可以用于解析 html 网页内容，熟悉 jQuery 语法童鞋的福音。</p><h3 id="另 -bs4- 库解析遇到的一个问题">另:bs4 库解析遇到的一个问题</h3><p>前几天遇到一个问题，问题是这样的，html 页面的数据经过 Beautiful Soup 库的解析后，部分 html 源码丢失，找不到想要的数据了，问题代码如下：</p><pre><code class="language-python">#! /usr/bin/env python# -*- coding:utf-8 -*-import requestsfrom bs4 import BeautifulSoupurl = 'http://product.pconline.com.cn/mobile/'res = requests.get(url)html = res.text# print htmlsoup = BeautifulSoup(html, 'lxml')site = soup.findAll('img', class_='pic')print site</code></pre><p>输出结果为空，没有想要的数据。查看官方文档，bs 库支持的解析库有 lxml, html5lib 和 html.parser。用的最多的是 lxml，因为它的解析速度快，并且容错能力强，默认也是使用该解析器。<br>出现解析后源码丢失的可能原因有 2 个：</p><ul><li>BeautifulSoup 有时候会遇到非法的，不支持的 html 源码而导致无法解析或无法正常解析 html；</li><li>处理的文档太大，而处理的解析器缓存不够造成的信息丢失。<br>这里换一个解析器，换成 <strong>html.parser</strong> 就可以了。</li></ul><h2 id="编码问题">编码问题</h2><p>将编码设置为 <strong>utf-8</strong></p><pre><code class="language-python">import sysreload(sys)sys.setdefaultencoding('utf-8')</code></pre><p>总之，py2 中的编码问题很烦人，只要解码与编码不一致就会出现乱码。对 unicode 可以 编码，其他编码 decode 成 unicode。<br>要注意 **‘hello’** 和 <strong>u’hello’</strong> 的区别。</p><h2 id="多线程爬取">多线程爬取</h2><h2 id="验证码处理">验证码处理</h2><h2 id="模拟登录">模拟登录</h2><p><span style="font-size:18px;"><strong>To be continued…</strong></span></p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sublime text3 配置 [python 篇]</title>
    <link href="/f49a9b8a.html"/>
    <url>/f49a9b8a.html</url>
    
    <content type="html"><![CDATA[<p>古语有云，工欲善其事必先利其器。选择一个好的工具，往往能达到意想不到的效果。因为个人电脑原因，用 pycharm 太卡，所以想起了 sublime text，配置了一下，觉得挺好用。</p><a id="more"></a><h2 id="下载">下载</h2><p>下载 <a href="http://pan.baidu.com/s/1qYoZ5Pa" target="_blank" rel="noopener">Sublime Text3 Build 3080 x64</a>，文件中有 <strong>License</strong>，输入一个即可破解。<br>当然了，还是希望支持 <strong> 正版</strong>。</p><h2 id="配置">配置</h2><p>我的用户配置文件如下：</p><pre><code class="language-othe">{    &quot;auto_complete_commit_on_tab&quot;: true,    &quot;bold_folder_labels&quot;: true, // 侧边栏文件夹加粗&quot;color_scheme&quot;: &quot;Packages/Tomorrow Color Schemes/Tomorrow-Night.tmTheme&quot;,    &quot;draw_minimap_border&quot;: false, // 右侧缩略图边框    &quot;ensure_newline_at_eof_on_save&quot;: true, // 文件末尾自动保留一个空行    &quot;fade_fold_buttons&quot;: false, // 显示代码块的倒三角    &quot;line_numbers&quot;: true, // 是否显示行号，默认显示    // 哪些文件不要被显示到侧边栏    &quot;file_exclude_patterns&quot;:    [        &quot;.DS_Store&quot;,        &quot;*.pid&quot;,        &quot;*.pyc&quot;    ],    // 哪些文件夹不要被显示到侧边栏    &quot;folder_exclude_patterns&quot;:    [        &quot;.git&quot;,        &quot;__pycache__&quot;,        &quot;.idea&quot;,    ],    &quot;font_size&quot;: 11,    // 删除想要忽略的插件，需要重启, 去掉 Vinage 开启 vim 模式    &quot;ignored_packages&quot;:    [&quot;Vintage&quot;],    &quot;line_padding_bottom&quot;: 3, // 设置行间距    &quot;line_padding_top&quot;: 3,    &quot;save_on_focus_lost&quot;: true, // 当前行标亮    &quot;spell_check&quot;: false, // 不进行拼写检查    &quot;tab_size&quot;: 4,  // 1 个 tab=4 个空格    &quot;translate_tabs_to_spaces&quot;: true, // 缩进和遇到 Tab 键时是否使用空格替代    // 保存文件时是否删除每行结束后多余的空格    &quot;trim_trailing_white_space_on_save&quot;: false,    &quot;update_check&quot;: false,  // // 禁止检查更新   &quot;default_encoding&quot;: &quot;UTF-8&quot;, // 默认编码格式   &quot;match_selection&quot;: true, // 全文突出显示和当前选中字符相同的字符, 默认为 true}</code></pre><h2 id="常用快捷键">常用快捷键</h2><p>所有的快捷键都可以在 <code>Preferences -&gt; Key Bindings - Default</code> 这里找到，或者打开命令面板，输入 <code>Key Bindings</code>。</p><pre><code class="language-othe">Ctrl + shift + n 新建窗口ctrl + shift + w 关闭窗口Ctrl + n 新建文件Ctrl + w 关闭当前文件ctrl + tab 在两个标签之间跳转ctrl +　j 在某行末尾敲该快捷键，会将下一行合并上来ctrl + shift + d 将当前行复制到下一行ctrl + shift + up/down 上下交换行ctrl + ]/[  当前行缩进一个级别 / 取消缩进ctrl + l 选择当前行Ctrl+Shift+l 先选中多行，再按下快捷键，会在每行行尾插入光标，即可同时编辑这些行。ctrl + d 选中一个后，按此快捷键可以同时选中另一个，同时多了另一个光标ctrl +　enter 在下面新开一行ctrl +　shift + enter 在上面新开一行Ctrl+Shift+K 删除整行。Ctrl+Shift+[ 选中代码，按下快捷键，折叠代码。Ctrl+Shift+] 选中代码，按下快捷键，展开代码。Ctrl+K+0 展开所有折叠代码。Ctrl+← 向左单位性地移动光标，快速移动光标。Ctrl+→ 向右单位性地移动光标，快速移动光标。shift+↑ 向上选中多行。shift+↓ 向下选中多行。Shift+← 向左选中文本。Shift+→ 向右选中文本。Alt+Shift+1~4 窗口左右分 1-4 屏，恢复默认 1 屏（非小键盘的数字）Alt+Shift+5 等分 4 屏Alt+Shift+8 垂直分屏 -2 屏Alt+Shift+9 垂直分屏 -3 屏Ctrl + g，输入行号，可以快速跳转到该行。Ctrl+K+B 开启 / 关闭侧边栏。Ctrl + \  打开控制行Ctrl + Shift + P 打开命令面板</code></pre><h2 id="常用插件">常用插件</h2><h3 id="Package-Control">Package Control</h3><p>进行包管理的必装插件，<a href="https://packagecontrol.io/installation#st3" target="_blank" rel="noopener">安装方式看这里</a></p><h3 id="SublimeTmpl">SublimeTmpl</h3><p>提供了常用文件的模板，新建文件时很有用。也可以自动定制，模版文件位置在 <code>\Packages\SublimeTmpl\templates\*.tmpl</code>, 模版文件中的 <code>author</code>，<code>Date</code> 等字段的默认值在 <code>Setting-Default </code>中，可以在 <code>Setting-User</code> 中进行重写覆盖。</p><h3 id="Code-Snippets">Code Snippets</h3><p>补全代码片段，可以 <a href="http://9iphp.com/web/html/sublime-text-code-snippets.html" target="_blank" rel="noopener"> 自定义代码片段</a>, 或者直接安装代码片段。</p><h3 id="SublimeCodeIntel">SublimeCodeIntel</h3><p>智能提示插件，这个插件的智能提示功能非常强大，可以自定义提示的内容库，我的 Python 智能提示设置,<br><strong>注意</strong>：我的 python 安装径为<code> D:/Python27/python.exe</code>，请视情况自行调整<br>在该插件的配置文件中添加如下内容（大括号内）：</p><pre><code class="language-othe">&quot;Python&quot;: {        &quot;python&quot;:&quot;D:/Python27/python.exe&quot;,        &quot;pythonExtraPaths&quot;:            [                &quot;D:/Python27&quot;,                 &quot;D:/Python27/DLLs&quot;,                 &quot;D:/Python27/Lib&quot;,                 &quot;D:/Python27/Lib/lib-tk&quot;,                 &quot;D:/Python27/Lib/site-packages&quot;            ]        }</code></pre><h3 id="Anaconda">Anaconda</h3><p>可以提示模块的类和方法，简单设置如下：</p><pre><code class="language-othe">{    &quot;python_interpreter&quot;: &quot;D:/Python27/python.exe&quot;,    &quot;complete_parameters&quot;: true,  // 补齐方法参数    &quot;suppress_word_completions&quot;: true,    &quot;suppress_explicit_completions&quot;: true,    &quot;pep8_ignore&quot;:    [&quot;E501&quot;],  // 忽略每行长度的限定，默认是 79 个字符}</code></pre><p>本插件默认支持 pep8 格式化，可以在默认配置文件中查看。<br>新建一个配置文件 <code>Python.sublime-settings</code>，并把它存放在包安装路径, 即 User 目录下，文件内容如下：</p><pre><code class="language-othe">{    &quot;auto_complete_triggers&quot;:    [{&quot;selector&quot;: &quot;source.python - string - comment - constant.numeric&quot;, &quot;characters&quot;: &quot;.&quot;}]}</code></pre><h3 id="autoPep8">autoPep8</h3><p>格式化 Python 代码<br><code>ctrl+shift+8</code> 进行 pep8 格式化，<code>ctrl+8</code> 进行预览<br>配置一下：</p><pre><code class="language-othe">{    &quot;ignore&quot;: &quot;E501&quot;,    &quot;format_on_save&quot;: true,// 保存时就自动格式化}</code></pre><h3 id="SublimeREPL">SublimeREPL</h3><p>提供 Sublime 可以执行许多脚本语言的直译器环境<br>以 python 为例进行配置，（在自定义配置文件中进行配置）</p><pre><code class="language-otghe">｛    &quot;default_extend_env&quot;: {&quot;PATH&quot;: &quot;{PATH};D:/Python27&quot;}｝</code></pre><p><code>D:/Python27</code> 为本地安装的 python 的路径，打开控制面板，选择 <code>SublimeREPL:Python</code>，就可以打开 python 的命令行，<br>选择 <code>SublimeREPL:Python-RUN current file</code> 就可以运行本文件，还可以使用 pdb 调试程序，<br>** 小问题：** 关于 ipython 没有配置好找了网上的方法也有点问题，先不管了，不影响其他使用。</p><h3 id="BracketHighlighter">BracketHighlighter</h3><p>BracketHighlighter 插件能为 Sublime Text 提供括号，引号这类高亮功能。<br>将默认配置文件复制到自定义配置文件中，然后配置，找到 “bracket_styles” 这一项，<br>style 类型有 outline， underline， highlight 和 solid 四种，对应关系是这样的，</p><pre><code class="language-other">{} － curly() － round[] － square&lt;&gt; － angle“” ” － quote</code></pre><h3 id="SublimeGit">SublimeGit</h3><p><code>ctrl+shift+p</code> 输入 <code>git</code> 可以查看到所有的命令，当然也可以设置快捷键。</p><h3 id="ConvertToUTF8">ConvertToUTF8</h3><p>GBK 编码兼容。</p><h3 id="ColorSublime">ColorSublime</h3><p>用来安装其 <a href="http://colorsublime.com/" target="_blank" rel="noopener"> 官网 </a> 上的所有主题。 安装此插件后，Ctrl+Shift+P，输入 install theme 并回车，等待片刻即缓存其官网所有主题到本地，按上下键可以即时预览效果，回车键安装。</p><h3 id="sidebarenhancement">sidebarenhancement</h3><p>侧边栏增强工具，<a href="https://segmentfault.com/a/1190000004464318" target="_blank" rel="noopener">sublime text 3 扩展插件 SideBarEnhancements 用法教程–使用浏览器快捷预览网页</a></p><h3 id="SyncedSidebarBg">SyncedSidebarBg</h3><p>同步侧边栏的颜色与主题一致</p><h3 id="material-theme"><a href="https://github.com/equinusocio/material-theme" target="_blank" rel="noopener"><strong>material-theme</strong></a></h3><p>一款扁平化主题，自认为是用过的最好的一款</p><h2 id="运行">运行</h2><p>可以直接使用 <strong>ctrl+b</strong> 在运行，也可以是使用 REPL 中的 <strong>RUN pythpn</strong></p><p><strong>注：</strong> 若出现 Package Control 不能使用的情况，可以将插件下载下来以后，放在 \Data\Packages 路径下</p><h2 id="参考">参考</h2><ol><li><a href="https://gist.github.com/MattDMo/6cb1dfbe8a124e1ca5af" target="_blank" rel="noopener">MattDMo/ipy_repl.py</a></li><li><a href="http://www.dbpoo.com/sublime-text3-brackethighlighter/" target="_blank" rel="noopener">Sublime Text3 BracketHighlighter 色彩配置</a></li><li><a href="https://www.zybuluo.com/king/note/47271" target="_blank" rel="noopener">Sublime Text 3 配置和使用方法</a></li><li><a href="http://blog.csdn.net/hexrain/article/details/13997565" target="_blank" rel="noopener"> Sublime Text 3 配置分析与我的配置</a></li><li><a href="http://www.imooc.com/article/1356" target="_blank" rel="noopener">Sublime Text 3 使用心得</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>sublime</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Scrapy Demo</title>
    <link href="/24aff268.html"/>
    <url>/24aff268.html</url>
    
    <content type="html"><![CDATA[<h2 id="Scrapy- 是什么">Scrapy 是什么</h2><blockquote><p>Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了页面抓取 (更确切来说, 网络抓取)所设计的， 也可以应用在获取 API 所返回的数据(例如 Amazon Associates Web Services) 或者通用的网络爬虫。Scrapy 用途广泛，可以用于数据挖掘、监测和自动化测试。<br>现在最新版本为 1.0，同时支持 2.7.x 和 3.x。</p></blockquote><a id="more"></a><ul><li><a href="http://scrapy.org/" target="_blank" rel="noopener">官方网站</a></li><li><a href="http://scrapy-chs.readthedocs.org/zh_CN/1.0/intro/tutorial.html" target="_blank" rel="noopener">中文版 document</a></li></ul><h2 id="Scrapy- 架构">Scrapy 架构</h2><p>Scrapy 使用了 Twisted 异步网络库来处理网络通讯, 整体架构大致如下：</p><center><img src="https://s1.ax1x.com/2018/10/28/icwTq1.jpg" srcset="/img/loading.gif" width="700" /></center><p>Scrapy 主要包括了以下组件：</p><ul><li>Scrapy Engine：用来处理整个系统的数据流处理，触发事务。</li><li>Scheduler：用来接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。</li><li>Downloader：用于下载网页内容，并将网页内容返回给 Spiders。</li><li>Spiders：Spiders 是主要干活的，用它来制订特定域名或网页的解析规则。</li><li>Item Pipeline：负责处理由 Spiders 从网页中抽取的项目，它的主要任务是清晰、验证和存储数据。当页面被 Spiders 解析后，将被发送到 Item Pipeline，并经过几个特定的次序处理数据。</li><li>Downloader 中间件：位于 Scrapy 引擎和下载器之间的钩子框架，主要是处理 Scrapy 引擎与下载器之间的请求及响应。</li><li>Spider 中间件：介于 Scrapy 引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。</li><li>Scheduler 中间件：介于 Scrapy 引擎和调度之间的中间件，从 Scrapy 引擎发送到调度的请求和响应。</li></ul><p>使用 Scrapy 可以很方便的完成网上数据的采集工作，它为我们完成了大量的工作，而不需要自己费大力气去开发。</p><h2 id="下载安装">下载安装</h2><pre><code class="language-python">pip install scrapy</code></pre><h2 id="Hello-World">Hello World</h2><h3 id="创建工程">创建工程</h3><p>在 cmd 下切换到想创建 scrapy 项目的地方，然后使用命名</p><pre><code class="language-python">scrapy startproject tutorial</code></pre><p><strong>注</strong>：tutorial 为工程名<br>然后就会发现在当前位置会多出一个文件夹，名字是 tutorial。它的目录结构是这样的：</p><pre><code class="language-python">tutorial/    scrapy.cfg    tutorial/        spiders/            __init__.py        __init__.py        items.py        pipelines.py        settings.py</code></pre><p><strong>注</strong>：<br>scrapy.cfg 是该项目的全局配置文件<br>tutorial/: 该项目的 python 模块。<br>tutorial/items.py: 项目中的 item 文件.<br>tutorial/pipelines.py: 项目中的 pipelines 文件.<br>tutorial/settings.py: 项目的设置文件.<br>tutorial/spiders/: 放置 spider 代码的目录.</p><h3 id="定义 -Item">定义 Item</h3><p>Item 是保存爬取到的数据的容器；其使用方法和 python 字典类似。虽然您也可以在 Scrapy 中直接使用 dict，但是 Item 提供了额外保护机制来避免拼写错误导致的未定义字段错误。<br>这里这样写</p><pre><code class="language-python"># -*- coding: utf-8 -*-import scrapyclass DmozItem(scrapy.Item):    title = scrapy.Field()    link = scrapy.Field()    desc = scrapy.Field()</code></pre><p>DmozItem 为该 Item 的名字， 该类是一个 scrapy.Item 类。<br>我这里想获取到的信息是 title、link 和 desc 这三个字段，它们都是 scrapy.Field 类型的。</p><h3 id="编写爬虫">编写爬虫</h3><p>在 <code>tutorial/spiders/</code>下创建一个 py 文件 <code>dmoz_spider.py</code>，它是这样定义的：</p><pre><code class="language-python">import scrapyfrom tutorial.items import DmozItemclass DmozSpider(scrapy.Spider):    name = 'dmoz'    allowed_domains = ['dmoz.org']    start_urls = [        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;,        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;    ]    def parse(self, response):        sel = Selector(response)        sites = sel.xpath('//ul[@class=&quot;directory-url&quot;]/li')        for sel in sites:            item = DmozItem() # 实例化一个 DmozItem 类            item['title'] = sel.xpath('a/text()').extract()            item['link'] = sel.xpath('a/@href').extract()            item['desc'] = sel.xpath('text()').extract()            yield item</code></pre><p>爬虫类必须继承自<code> scrapy.Spider</code> 类， 且定义一些属性:</p><p><strong>name</strong>: 用于区别 Spider。 该名字必须是唯一的，不可以为不同的 Spider 设定相同的名字。<br><strong>start_urls</strong>: 包含了 Spider 在启动时进行爬取的 url 列表。 因此，第一个被获取到的页面将是其中之一， 后续的 URL 则从初始的 URL 获取到的数据中提取。<br><code>parse()</code> 是 spider 的一个方法。 被调用时，每个初始 URL 完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据 (response data)，提取数据(生成 item) 以及生成需要进一步处理的 URL 的 Request 对象。scrapy 为 Spider 的 start_urls 属性中的每个 URL 创建了 scrapy.Request 对象，并将 parse 方法作为回调函数 (callback) 赋值给了 Request。Request 对象经过调度，执行生成 scrapy.http.Response 对象并送回给 spider parse() 方法, 一般返回 Item 实例。</p><h3 id="爬取">爬取</h3><p>进入该工程目录，本例中就是 tutorial/, 在命令行执行</p><pre><code class="language-python">scrapy crawl dmoz</code></pre><h3 id="保存">保存</h3><p>可以使用如下命令</p><pre><code class="language-python">scrapy crawl dmoz -o items.json</code></pre><p>该命令是说将结果保存在 items.json 文件中。</p><h2 id="常用的命令行工具">常用的命令行工具</h2><pre><code class="language-other"># 创建项目scrapy startproject myproject# 帮助信息scrapy &lt;command&gt; -h# 帮助信息scrapy -h# 使用下载器下载指定的 url，并将获取到的内容送到标准输出scrapy fetch &lt;url&gt;# 在浏览器中打开给定的 URL，并以 Scrapy spider 获取到的形式展现scrapy view &lt;url&gt;# 以给定的 URL(如果给出)或者空 (没有给出 URL) 启动 Scrapy shellscrapy shell [url]#在未创建项目的情况下，运行一个编写在 Python 文件中的 spiderscrapy runspider &lt;spider_file.py&gt;# 获取 Scrapy 的设定scrapy settings [options]------------------------- 以上不需要项目，以下需要在项目中 ----------------------------------------# 使用 template 模版来信创建一个 spider， name 值为 &lt;name&gt;, allowed_domains 值为 &lt;domain&gt;scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;# 查看可用的模版，默认有 basic、crawl、csvfeed 和 xmlfeed 4 个scrapy genspider -l# 查看 TEMPLATE 信息scrapy genspider -d TEMPLATE# 使用 &lt;spider&gt; 进行爬取数据scrapy crawl &lt;spider&gt;# 列出当前项目中所有可用的 spiderscrapy list# 运行 contract 检查。scrapy check [-l] &lt;spider&gt;# 获取给定的 URL 并使用相应的 spider 分析处理，可以解析成自己写的 itemscrapy parse &lt;url&gt; [options]</code></pre>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo + gitpages 搭建博客</title>
    <link href="/5e988508.html"/>
    <url>/5e988508.html</url>
    
    <content type="html"><![CDATA[<p>本篇文章主要记录用 hexo 搭建博客，并部署在 github 上的大概过程。</p><a id="more"></a><h2 id="搭建博客并部署">搭建博客并部署</h2><h3 id="安装 -node-js">安装 node.js</h3><p><a href="https://nodejs.org/en/" target="_blank" rel="noopener">安装 node.js</a><br>默认 npm 源可能比较慢，建议换一下，参考这个 <a href="https://npm.taobao.org/" target="_blank" rel="noopener">淘宝 NPM 镜像</a>。</p><h3 id="安装 -git">安装 git</h3><p><a href="https://git-scm.com/download/" target="_blank" rel="noopener">安装 git</a><br>进行简要的配置，详细信息参照 <a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener"> 廖雪峰 git 教程</a></p><h3 id="创建 -github-repo，并关联本地库">创建 github repo，并关联本地库</h3><p>repo 名为 <code>github 账号名.github.io</code>，如 <code>AlexVon.github.io</code></p><h3 id="安装 -hexo">安装 hexo</h3><p>使用 npm 安装 hexo</p><pre><code class="language-shell"># 如果没有按照上面换淘宝的 npm 的话，使用 npm 命令，而不是 cnpmcnpm install hexo --save</code></pre><h3 id="初始化 -hexo- 文件夹">初始化 hexo 文件夹</h3><p>在 git 本地库中</p><pre><code class="language-othe">hexo initnpm install#新建完成后，指定文件夹的目录如下.├── _config.yml  #全局配置文件├── package.json├── scaffolds   # 模版文件, 新建文章时会根据 scaffold 里对应 md 生成文件├── scripts    ├── public      # hexo g 后产生的文件夹，后面部署时上传的也是这个文件夹├── source|      └── _posts # 发布的文章└── themes  #主题文件</code></pre><h3 id="安装 -hexo 插件">安装 hexo 插件</h3><pre><code class="language-shell"># 在部署的时候使用npm install hexo-deployer-git --save</code></pre><h3 id="查看效果">查看效果</h3><pre><code class="language-shell">hexo g # 生成 public 静态文件hexo s # 开启服务器</code></pre><p>如果没有错误，可以在本地打开浏览器，打开网址 <em><a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></em></p><h3 id="部署到 github">部署到 github</h3><p>在根目录下使用 <code>hexo d</code> 命令进行部署，不过在第一次部署之前，需要在<br><span id="inline-blue">站点配置文件</span> 配置 <code>deploy</code> 项：</p><pre><code class="language-yml">deploy:  type: git  repo: &lt;repository url&gt;  branch: [branch]  message: [message]</code></pre><p>若没有发生错误，就可以正常访问 <a href="http://vonalex.github.io/">http://vonalex.github.io/</a> 了。<br>部署后，会在根目录多出一个名为 <code>.deploy_git</code> 的文件夹。</p><p>每次都用 <code>hexo cl</code>/<code>hexo g</code>/<code>hexo d</code> 等命令会比较繁琐，可以在博客根目录下找到 <code>package.json</code> 文件，添加以下代码后，只需要运行 <code>npm run deploy</code>即可！</p><pre><code class="language-json">  &quot;scripts&quot;: {    &quot;deploy&quot;: &quot;hexo clean &amp;&amp; hexo g &amp;&amp; hexo d&quot;,    &quot;test&quot;: &quot;hexo clean &amp;&amp; hexo g  &amp;&amp; hexo s&quot;,    &quot;dev&quot;: &quot;hexo clean &amp;&amp; hexo g&quot;  }</code></pre><h2 id="主题配置">主题配置</h2><p>本教程采用的是 <strong>next</strong> 主题，这个主题的优化配置比较好找。</p><h3 id="下载主题">下载主题</h3><pre><code class="language-shell">git clone https://github.com/iissnan/hexo-theme-next themes/next</code></pre><p>这时在 <code>themes</code> 文件夹下就多出了一个 <code>next</code> 的主题文件夹。</p><h3 id="配置">配置</h3><h4 id="添加分类页面">添加分类页面</h4><pre><code class="language-shell">hexo new page categories</code></pre><p>这时候，根目录下 <code>source</code> 文件夹下多出来一个 <code>categories</code> 文件夹，修改该文件下的<code>index.md</code> 文件如下：</p><pre><code class="language-oth">---title: categoriesdate: 2016-04-02 21:38:55type: &quot;categories&quot;---</code></pre><h4 id="添加标签页面">添加标签页面</h4><pre><code class="language-shell">hexo new page tags</code></pre><p>修改 <code>source\tags\index.md</code> 文件如下：</p><pre><code class="language-oth">---title: tagsdate: 2016-04-02 21:40:22type: &quot;tags&quot;---</code></pre><p>同理可以使用 <code>hexo new page 页面名</code> 来添加其他的页面，然后在主题配置文件中加上图标对应关系，若使用的是中文主题，那还要在主题文件夹下的 <code>language</code> 文件下的中文文件中进行设置，不然会出现英文。<br>menu 的 <code> 根目录 /</code>是 <code>source</code> 文件夹。</p><h3 id="导航栏新加页面">导航栏新加页面</h3><p>大体方法跟上面添加 tags 类似，这里举一个具体的栗子，因为有一些在线文档需要经常查看，所以我要增加一个在线文档的页面：<br>【1】 <code>hexo new page docs</code>，docs 为新页面名，这时会出现 <code>source/docs/index.md</code> 这个文件。因为这个页面不需要评论，所以添加一行代码 <code>comments: false</code>。<br>【2】 <span id="inline-purple"> 主题配置文件 </span>，在 menu 这个项目中添加 <code>docs: /docs</code>，就是让导航栏能够找到这个页面。然后为新加的页面增加一个想要的图标，大概这样 <code>docs: /docs || envira</code>。<br>【3】 <strong>themes/next/languages/zh-Hans.yml</strong> 中找到 menu 这个项，配置要让新的页面显示什么中文名字，如 <code> docs: 在线文档</code></p><h4 id="添加 -fork-me-on-github">添加 fork me on github</h4><p><a href="https://github.com/blog/273-github-ribbons" target="_blank" rel="noopener">github 官方教程 </a>，把代码插入到任意一个全局的模板文件中就行，比如<code>_layout.swig</code> 的末尾。</p><h4 id="添加音乐链接">添加音乐链接</h4><p>在网易云音乐网页版上找到自己喜欢的音乐或者歌单，点开到播放界面，生成外链播放器，可以将生成的插件代码放入 html 文件中或 md 文件中。<br><img src="https://s1.ax1x.com/2018/10/28/icworR.md.jpg" srcset="/img/loading.gif" alt="icworR.jpg" border="0" /></p><h3 id="其他">其他</h3><h4 id="图标问题">图标问题</h4><p>next 主题的图标采用的是 <a href="http://www.fontawesome.com.cn/faicons/" target="_blank" rel="noopener">fontawesome</a> 免费图标，比如在页面中加入这条语句就可以引用 github-alt 这个图标。<br><code>&lt;i class=&quot;fa fa-github-alt&quot;&gt;&lt;/i&gt;</code>，效果如下 <i class="fa fa-github-alt"></i><br>还可以用 <code>&lt;i class=&quot;fa fa-github-alt fa-2x&quot;&gt;&lt;/i&gt;</code> 来增大图标，效果如下 <i class="fa fa-github-alt fa-2x"></i>，以此类推！</p><h4 id="修改内容区域的宽度">修改内容区域的宽度</h4><p>NexT 对于内容的宽度的设定如下：</p><ul><li>700px，当屏幕宽度 &lt; 1600px</li><li>900px，当屏幕宽度 &gt;= 1600px</li><li>移动设备下，宽度自适应</li></ul><p>果你需要修改内容的宽度，同样需要编辑样式文件，在 Mist 和 Muse 风格可以用下面的方法：<br>编辑主题的 <code>source/css/_variables/custom.styl</code> 文件，新增变量：</p><pre><code class="language-css">// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px</code></pre><p>当你使用 Pisces 风格时可以用下面的方法：</p><pre><code class="language-css">header{width: 90%;}.container .main-inner {width: 90%;}.content-wrap {width: calc(100% - 260px); }</code></pre><h4 id="代码主题">代码主题</h4><p>我比较喜欢的是 MacPanel 代码样式，像本博客中的这样。<br>关于如何设置，可以参考这篇博客<a href="https://blog.shadowy.me/2018/03/16/hexo-next-macpanel-improved/" target="_blank" rel="noopener">Hexo 博客 NexT 主题代码高亮 MacPanel 特效配置</a></p><h4 id="md 文件中插图问题">md 文件中插图问题</h4><h5 id="插图方法">插图方法</h5><ol><li>可以用 md 中的语法<code>![]()</code>，图片大小不可控。</li><li>使用 <code>&lt;img&gt;</code> 标签，因为 html 的标签可以无缝使用。</li></ol><h5 id="图片位置">图片位置</h5><ol><li>可以单独建立一个文件夹，专门存放图片。比如 hexo 下，可以在 <code>source</code> 文件夹下新建 <code>images</code> 文件夹，用于存放图片。一旦你决定长期写下去，这样并不好！</li><li>使用图床，有一些免费图床, 可以搜索到，还可以使用七牛、又拍等的云存储服务。我使用的是这款 <a href="https://imgchr.com/" target="_blank" rel="noopener"> 路过图床</a></li></ol><h4 id="设置网站图标">设置网站图标</h4><p>默认的网站图标是一个 N 的字样，下载喜欢的 png 图片，放在 <code>themes/next/source/images/</code> 文件夹下，在 <span id="inline-purple">主题配置文件 </span> 的<code>favicon</code>项进行配置，如：</p><pre><code>favicon:  medium: /images/dolphin.png</code></pre><h4 id="URL 持久化">URL 持久化</h4><p>hexo 默认生成的文章地址路径是 <code> 网站名称 / 年 / 月 / 日 / 文章名称</code>. 这种链接对搜索爬虫是很不友好的, 所以这里修改一下。</p><pre><code># 安装插件$ npm install hexo-abbrlink --save</code></pre><p>在 <span id="inline-blue"> 站点配置文件 </span> 中添加如下配置：</p><pre><code># permalink: :title/permalink: :abbrlink.htmlabbrlink:  alg: crc32  # 算法：crc16(default) and crc32  rep: hex    # 进制：dec(default) and hex</code></pre><p>html 前缀为：对标题 + 时间进行 md5 然后再转 base64</p><p>上面很多配置在新本中已经内置，因此有的可能已经过期！详情想参考 http://theme-next.iissnan.com/</p><h3 id="参考链接">参考链接</h3><ol><li><a href="http://codingbubble.github.io/2015/05/08/custom-your-Hexo/" target="_blank" rel="noopener">个性化你的 Hexo- 笔记</a></li><li><a href="http://blog.csdn.net/anonymalias/article/details/50528946" target="_blank" rel="noopener">通过 Hexo 在 GitHub 搭站全记录</a></li><li><a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">next 官方使用文档</a></li><li><a href="http://www.arao.me/2015/hexo-next-theme-optimize-base/" target="_blank" rel="noopener">動動手指，NexT 主題與 Hexo 更搭哦（基礎篇）</a></li><li><a href="https://segmentfault.com/a/1190000002632530" target="_blank" rel="noopener">hexo 常用命令笔记</a></li><li><a href="http://jijiaxin89.com/2015/08/21/%E7%8E%A9%E8%BD%AChexo%E5%8D%9A%E5%AE%A2%E4%B9%8Bnext/" target="_blank" rel="noopener">玩转 Hexo 博客之 Next</a></li><li><a href="http://www.mmuuii360.com/duoshuo-css.html" target="_blank" rel="noopener">多说评论框 css 样式表自定义</a></li><li><a href="http://zhiho.github.io/2015/09/29/hexo-next/" target="_blank" rel="noopener">Hexo 搭建 GitHub 博客（三）- NexT 主题配置使用</a></li><li><a href="http://ppting.me/2015/01/25/sitemap/" target="_blank" rel="noopener">hexo 优化–向 Google 提交 sitemap</a></li><li><a href="http://ibruce.info/2013/11/22/hexo-your-blog/" target="_blank" rel="noopener">hexo 你的博客</a></li><li><a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html" target="_blank" rel="noopener">hexo 的 next 主题个性化教程: 打造炫酷网站</a></li><li><a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#%E9%99%84%E4%B8%8A%E6%88%91%E7%9A%84-custom-styl" target="_blank" rel="noopener">打造个性超赞博客 Hexo+NexT+GithubPages 的超深度优化</a></li><li><a href="https://www.vincentqin.tech/2016/08/09/build-a-website-using-hexo/#%E5%A2%9E%E5%8A%A0Gitter" target="_blank" rel="noopener">HEXO 建站备忘录</a></li><li><a href="https://www.jianshu.com/p/3884e5cb63e5" target="_blank" rel="noopener">hexo 定制 &amp; 优化</a></li><li><a href="https://blog.csdn.net/human8848/article/details/51479920" target="_blank" rel="noopener">解决 Local gulp not found in</a></li></ol><hr><h3 id="i-class-fa-fa-exclamation-triangle-i- 附录"><i class="fa fa-exclamation-triangle"></i>附录</h3><h4 id="常用的 -hexo- 命令">常用的 hexo 命令</h4><p>** 注意：** 这些命令要在根目录下使用</p><pre><code>npm install hexo -g #安装npm update hexo -g #升级hexo init # 初始化hexo cl == hexo clean 清理之前生成的 public 文件夹hexo new page 页面名 #新建页面# 新建文章（文章名不用加引号），在站点下 source\_posts 下生成 &quot; 文章名.md&quot;hexo n  文章名 == hexo new 文章名hexo g == hexo g # 生成要发布博客的所有静态资源hexo s == hexo server #  开启本地服务器可以进行预览hexo d  == hexo deploy # 部署hexo deploy -g # 生成并部署hexo server -g # 生成并预览hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IP</code></pre><h4 id="安装的插件">安装的插件</h4><pre><code>hexo-wordcount  // 统计字数hexo-deployer-git // 部署使用hexo-abbrlink // 持久化连接hexo-generator-baidu-sitemap // 百度 sitemaphexo-generator-sitemap //google sitemapgulp // 静态资源压缩有关gulp-minify-cssgulp-htmlmingulp-htmlcleangulp-uglify</code></pre>]]></content>
    
    
    <categories>
      
      <category>tools</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
