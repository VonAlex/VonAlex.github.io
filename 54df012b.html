<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/images/dolphin.png"><link rel="icon" type="image/png" href="/images/dolphin.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="Happen"><meta name="keywords" content=""><title>Redis 源码之故障转移 - Happen&#39;s Memo</title><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css"><link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"><link rel="stylesheet" href="/css/main.css"><link defer="defer" rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/custom.css"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"> <a class="navbar-brand" href="/">&nbsp;<strong>Happen's Memo</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="fa fa-home" aria-hidden="true"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="fa fa-archive" aria-hidden="true"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="fa fa-map-signs" aria-hidden="true"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="fa fa-tags" aria-hidden="true"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="fa fa-child" aria-hidden="true"></i> 关于</a></li><li class="nav-item" id="search-btn"> <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a></li></ul></div></div></nav><div class="view intro-2" id="background" parallax="true" style="background:url(/images/about-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask rgba-black-light flex-center"><div class="container text-center white-text fadeInUp"><span class="h2" id="subtitle"></span><p class="mt-3 post-meta"><i class="fas fa-calendar-alt" aria-hidden="true"></i> 2019/01/31, 星期四, 16:13</p><p class="mt-1"><span class="post-meta"><i class="far fa-chart-bar"></i> 7.3k 字</span><span class="post-meta"><i class="far fa-clock"></i> 33 分钟</span><span id="busuanzi_container_page_pv" class="post-meta" style="display:none"><i class="far fa-eye" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span> 次</span></p></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5 z-depth-3" id="board"><div class="post-content mx-auto" id="post"><p class="note note-warning">本文最后更新于：2020/04/03, 星期五, 01:45</p><div class="markdown-body"><p>在 Redis cluster 中故障转移是个很重要的功能，下面就从故障发现到故障转移整个流程做一下详细分析。</p><a id="more"></a><h2 id="1- 故障检测">1. 故障检测</h2><h3 id="1-1-PFAIL- 标记">1.1 PFAIL 标记</h3><p>集群中每个节点都会定期向其他节点发送 <strong>PING</strong> 消息，以此来检测对方是否在线，如果接收 <strong>PING</strong> 消息的节点 B 没有在规定时间（<strong>cluster_node_timeout</strong>）内回应节点 A <strong>PONG</strong> 消息，那么节点 A 就会将节点 B 标记为疑似下线（probable fail, <strong>PFAIL</strong>）。</p><pre><code class="language-c">void clusterCron(void) {
    // ...
    di = dictGetSafeIterator(server.cluster-&gt;nodes);
    while((de = dictNext(di)) != NULL) {clusterNode *node = dictGetVal(de);
        now = mstime(); /* Use an updated time at every iteration. */
        // ...
        delay = now - node-&gt;ping_sent;
        if (delay &gt; server.cluster_node_timeout) {
            /* Timeout reached. Set the node as possibly failing if it is
             * not already in this state. */
            if (!(node-&gt;flags &amp; (CLUSTER_NODE_PFAIL|CLUSTER_NODE_FAIL))) {
                node-&gt;flags |= CLUSTER_NODE_PFAIL;
                update_state = 1;
            }
        }
    }
    dictReleaseIterator(di);
    // ...
}
</code></pre><p>可以看到，在 <code>clusterCron</code> 函数中如果对节点 B 发出 PING 消息，在 <strong>server.cluster_node_timeout</strong> 时间内没有收到其返回的 PONG 消息，如果节点 B 现在没有被标记成 <strong>CLUSTER_NODE_PFAIL</strong> 状态，那么现在就做下这个标记。<br> 可以根据 <strong>ping_sent</strong> 参数进行判断的依据如下，</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {
    // ...
    if (link-&gt;node &amp;&amp; type == CLUSTERMSG_TYPE_PONG) {link-&gt;node-&gt;pong_received = mstime();
        link-&gt;node-&gt;ping_sent = 0;
        // ...
    }
    // ...
}
</code></pre><p>当节点 A 接收到节点 B 的 PONG 消息时，会把 <strong>ping_sent</strong> 更新成 0，同时记下收到本次 PONG 消息的时间。<br> 上面提到的 clusterNode 与 clusterLink 有如下关联关系：<br> <img src="http://ww1.sinaimg.cn/large/71ca8e3cly1fzpznib0gij20ff07qjrt.jpg" srcset="/img/loading.gif" alt=""></p><p>可以看出， clusterLink 就是为了接收对端 gossip 消息而设置的。<br> 另外，我们发现， 在上面的 <code>clusterCron</code> 函数中将节点标记成 PFAIL 时，会将 update_state 变量置为 1，这会引发后面更改集群状态的逻辑。</p><pre><code class="language-c">if (update_state || server.cluster-&gt;state == CLUSTER_FAIL)
    clusterUpdateState();
</code></pre><p>集群有两个状态，<strong>CLUSTER_OK</strong> 和 <strong>CLUSTER_FAIL</strong>，如果集群目前状态是 CLUSTER_FAIL，且设置了参数 <code>cluster-require-full-coverage yes</code>，那么此时访问集群会返回错误，意思是可能有某些 slot 没有被 server 接管。<br> <code>clusterUpdateState</code> 函数负责更新集群状态，该部分逻辑与本篇博文要讲的主逻辑关系不大，所以放到了后面的 <strong>补充章节</strong> 中了。</p><h3 id="1-2-FAIL- 标记">1.2 FAIL 标记</h3><h4 id="1-2-1- 主动标记 -FAIL">1.2.1 主动标记 FAIL</h4><p>被节点 A 标记成 FAIL/ PFAIL 的节点如何让节点 C 知道呢？这主要是通过平常发送的 PING/PONG 消息实现的，在 3.x 的版本时，会尽最大努力把这样的节点放到 gossip 消息的流言部分，到后面的 4.x 版本的代码中每次的 PING/PONG 消息都会把 PFAIL 节点都带上。<br> <code>clusterProcessGossipSection</code> 函数用来处理 gossip 消息的流言部分。</p><pre><code class="language-c">void clusterProcessGossipSection(clusterMsg *hdr, clusterLink *link) {uint16_t count = ntohs(hdr-&gt;count);
    clusterMsgDataGossip *g = (clusterMsgDataGossip*) hdr-&gt;data.ping.gossip;
    clusterNode *sender = link-&gt;node ? link-&gt;node : clusterLookupNode(hdr-&gt;sender);
    while(count--) {
        // ...
        node = clusterLookupNode(g-&gt;nodename);
        if (node) {if (sender &amp;&amp; nodeIsMaster(sender) &amp;&amp; node != myself) {if (flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL)) {if (clusterNodeAddFailureReport(node,sender)) {
                        serverLog(LL_VERBOSE,
                           &quot;Node %.40s reported node %.40s as not reachable.&quot;,
                            sender-&gt;name, node-&gt;name);
                    }
                    markNodeAsFailingIfNeeded(node);
                } else {// ...}
            }
        // ...
        }
    // ...
    }
    // ...
}
</code></pre><p>该函数依次处理 gossip 消息流言部分携带的各节点信息（总节点数的 1/10）。当发现带有 CLUSTER_NODE_FAIL 或者 CLUSTER_NODE_PFAIL 时会调用 <code>clusterNodeAddFailureReport</code> 函数。</p><pre><code class="language-c">int clusterNodeAddFailureReport(clusterNode *failing, clusterNode *sender) {
    list *l = failing-&gt;fail_reports;
    listNode *ln;
    listIter li;
    clusterNodeFailReport *fr;

    /* If a failure report from the same sender already exists, just update
     * the timestamp. */
    listRewind(l,&amp;li);
    while ((ln = listNext(&amp;li)) != NULL) {
        fr = ln-&gt;value;
        if (fr-&gt;node == sender) {fr-&gt;time = mstime();
            return 0;
        }
    }

    /* Otherwise create a new report. */
    fr = zmalloc(sizeof(*fr));
    fr-&gt;node = sender;
    fr-&gt;time = mstime();
    listAddNodeTail(l,fr);
    return 1;
}
</code></pre><p>每一个节点都有一个名为 fail_reports 的 list 结构的变量，用来搜集该异常节点获得了集群中哪些节点的 PFAIL 状态投票。fail_reports 每个成员都是一个 clusterNodeFailReport 结构。</p><pre><code class="language-c">typedef struct clusterNodeFailReport {
    struct clusterNode *node;  /* Node reporting the failure condition. */
    mstime_t time;             /* Time of the last report from this node. */
} clusterNodeFailReport;
</code></pre><p>clusterNodeFailReport 中带有时间戳，标记这个节点上一次被报上来处于异常状态的时间。<br> 每次调用 <code>clusterNodeAddFailureReport</code> 函数时，先会检查 sender 是否已经为该异常节点投票过了，如果有，更新时间戳，如果没有，把 sender 加入到投票节点中。<br> 简单点说就是，在 A 节点看来 B 节点是 PFAIL 状态，在 gossip 通信中把它告诉了 C 节点，C 节点发现这个异常状态的节点，检查一下为 B 节点投过票的节点中有没有 A 节点，如果没有就加进去。</p><p>然后下面就是判断 PFAIL 状态是不是要转变成 FAIL 状态的关键。</p><pre><code class="language-c">void markNodeAsFailingIfNeeded(clusterNode *node) {
    int failures;
    int needed_quorum = (server.cluster-&gt;size / 2) + 1;

    if (!nodeTimedOut(node)) return; /* We can reach it. */
    if (nodeFailed(node)) return; /* Already FAILing. */

    failures = clusterNodeFailureReportsCount(node);
    /* Also count myself as a voter if I'm a master. */
    if (nodeIsMaster(myself)) failures++;
    if (failures &lt; needed_quorum) return; /* No weak agreement from masters. */

    serverLog(LL_NOTICE, &quot;Marking node %.40s as failing (quorum reached).&quot;, node-&gt;name);

    /* Mark the node as failing. */
    node-&gt;flags &amp;= ~CLUSTER_NODE_PFAIL;
    node-&gt;flags |= CLUSTER_NODE_FAIL;
    node-&gt;fail_time = mstime();

    /* Broadcast the failing node name to everybody, forcing all the other
     * reachable nodes to flag the node as FAIL. */
    if (nodeIsMaster(myself)) clusterSendFail(node-&gt;name); /* 广播这个节点的 fail 消息 */
    clusterDoBeforeSleep(CLUSTER_TODO_UPDATE_STATE|CLUSTER_TODO_SAVE_CONFIG);
}
</code></pre><p>C 节点收到消息，检查下 A 报过来的异常节点 B，在自己看来是否也是 PFAIL 状态的，如果不是，那么不理会 A 节点本次 report。如果在节点 C 看来，节点 B 已经被标记成 FAIL 了，那么就不需要进行下面的判定了。</p><p>在函数 <code>clusterNodeFailureReportsCount</code> 中会判断计算出把 B 节点标记成 PFAIL 状态的节点的数量 sum，如果 <strong>sum 值小于集群 size 的一半</strong> ，为防止误判，忽略掉这条信息。在函数 <code>clusterNodeFailureReportsCount</code> 中会检查关于 B 节点的 <strong>clusterNodeFailReport</strong>，清理掉那些 <strong>过期的</strong> 投票，过期时间为 2 倍的 <strong>server.cluster_node_timeout</strong>。</p><p>如果满足条件，节点 C 将节点 B 的 PFAIL 状态消除，标记成 FAIL，同时记下 fail_time，如果 C 节点是个 master，那么将 B 节点 FAIL 的消息广播出去，以便让集群中其他节点尽快知道。</p><pre><code class="language-c">void clusterSendFail(char *nodename) {unsigned char buf[sizeof(clusterMsg)];
    clusterMsg *hdr = (clusterMsg*) buf;
    clusterBuildMessageHdr(hdr,CLUSTERMSG_TYPE_FAIL);
    memcpy(hdr-&gt;data.fail.about.nodename,nodename,CLUSTER_NAMELEN);
    clusterBroadcastMessage(buf,ntohl(hdr-&gt;totlen));
}
</code></pre><p>发送的 gossip 消息类型为 CLUSTERMSG_TYPE_FAIL，广播的节点排除自身和处于 HANDSHAKE 状态节点。</p><h4 id="1-2-2-Gossip- 被动感知 -FAIL">1.2.2 Gossip 被动感知 FAIL</h4><p>前面说过，gossip 消息的处理函数为 <code>clusterProcessPacket</code>，下面看 CLUSTERMSG_TYPE_FAIL 类型的消息如何处理。</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {
    // ...
    uint16_t type = ntohs(hdr-&gt;type);
    // ...
    if (type == CLUSTERMSG_TYPE_FAIL) { // fail
        clusterNode *failing;
        if (sender) {failing = clusterLookupNode(hdr-&gt;data.fail.about.nodename);
            if (failing &amp;&amp; !(failing-&gt;flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_MYSELF)))
            {
                serverLog(LL_NOTICE,
                    &quot;FAIL message received from %.40s about %.40s&quot;,
                    hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);
                failing-&gt;flags |= CLUSTER_NODE_FAIL;
                failing-&gt;fail_time = mstime();
                failing-&gt;flags &amp;= ~CLUSTER_NODE_PFAIL;
                clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG|
                                     CLUSTER_TODO_UPDATE_STATE);
            }
        } else {
            serverLog(LL_NOTICE,
                &quot;Ignoring FAIL message from unknown node %.40s about %.40s&quot;,
                hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);
        }
    }
    // ...
}
</code></pre><p>集群中另一个节点 D 收到节点 B 广播过来的消息：B 节点 FAIL 了。如果 D 还没有把 B 标记成 FAIL，那么标记成 CLUSTER_NODE_FAIL，并取消 CLUSTER_NODE_PFAIL 标记；否则，忽略，因为 D 已经知道 B 是 FAIL 节点了。</p><h2 id="2- 故障转移">2. 故障转移</h2><p>failover 分为两类，主动 failover（主动切主从）以及被动 failover（被动切主从），下面挨个进行分析。</p><h3 id="2-1- 被动 -failover">2.1 被动 failover</h3><h4 id="2-1-1- 先验条件及初始化">2.1.1 先验条件及初始化</h4><pre><code class="language-c">void clusterCron(void) {
    // ...
    if (nodeIsSlave(myself)) {clusterHandleSlaveFailover();
        // ...
    }
    // ...
}
</code></pre><p>是否要做被动主从切换，在 <code>clusterHandleSlaveFailover</code> 函数中有如下的判断逻辑，</p><pre><code class="language-c">if (nodeIsMaster(myself) ||
    myself-&gt;slaveof == NULL ||
    (!nodeFailed(myself-&gt;slaveof) &amp;&amp; !manual_failover) ||
    myself-&gt;slaveof-&gt;numslots == 0)
{
    /* There are no reasons to failover, so we set the reason why we
     * are returning without failing over to NONE. */
    server.cluster-&gt;cant_failover_reason = CLUSTER_CANT_FAILOVER_NONE;
    return;
}
</code></pre><p>只有满足如下条件的节点才有资格做 failover：</p><ul><li>slave 节点</li><li>master 不为空</li><li>master 负责的 slot 数量不为空</li><li>master 被标记成了 FAIL，或者这是一个主动 failover（manual_failover 为真）</li></ul><p>假设，现在 B 节点的 slave Bx 节点检测到 B 节点挂掉了，通过了以上的条件测试，接下来就会进行 failover。<br> 那么下面 Bx 节点就开始在集群中进行拉票，该逻辑也在 <code>clusterHandleSlaveFailover</code> 函数中。</p><pre><code class="language-c">mstime_t auth_age = mstime() - server.cluster-&gt;failover_auth_time;
int needed_quorum = (server.cluster-&gt;size / 2) + 1;
mstime_t auth_timeout, auth_retry_time;

auth_timeout = server.cluster_node_timeout*2;
if (auth_timeout &lt; 2000) auth_timeout =2000 ;
auth_retry_time = auth_timeout*2;
</code></pre><p>cluster 的 <strong>failover_auth_time</strong> 属性，表示 slave 节点开始进行故障转移的时刻。集群初始化时该属性置为 0，一旦满足 failover 的条件后，该属性就置为 <strong>未来的某个时间点</strong>（不是立马执行），在该时间点，slave 节点才开始进行拉票。<strong>auth_age</strong> 变量表示从发起 failover 流程开始到现在，已经过去了多长时间。<br> <strong>needed_quorum</strong> 变量表示当前 slave 节点必须至少获得多少选票，才能成为新的 master。<br> <strong>auth_timeout</strong> 变量表示当前 slave 发起投票后，等待回应的超时时间，至少为 2s。如果超过该时间还没有获得足够的选票，那么表示本次 failover 失败。<br> <strong>auth_retry_time</strong> 变量用来判断是否可以开始发起下一次 failover 的时间间隔。</p><pre><code class="language-c">if (server.repl_state == REPL_STATE_CONNECTED) {data_age = (mstime_t)(server.unixtime - server.master-&gt;lastinteraction) * 1000;
} else {data_age = (mstime_t)(server.unixtime - server.repl_down_since) * 1000;
}
if (data_age &gt; server.cluster_node_timeout)
    data_age -= server.cluster_node_timeout;
</code></pre><p><strong>data_age</strong> 变量表示距离上一次与我的 master 节点交互过去了多长时间。经过 cluster_node_timeout 时间还没有收到 PONG 消息才会将节点标记为 PFAIL 状态。实际上 data_age 表示在 master 节点下线之前，当前 slave 节点有多长时间没有与其交互过了。</p><blockquote><p>data_age 主要用于判断当前 slave 节点的数据新鲜度；如果 data_age 超过了一定时间，表示当前 slave 节点的数据已经太老了，不能替换掉下线 master 节点，因此在不是手动强制故障转移的情况下，直接返回。</p></blockquote><h4 id="2-1-2- 制定 -failover- 时间">2.1.2 制定 failover 时间</h4><pre><code class="language-c">void clusterHandleSlaveFailover(void) {
    // ...
    if (auth_age &gt; auth_retry_time) {server.cluster-&gt;failover_auth_time = mstime() +
            500 + /* Fixed delay of 500 milliseconds, let FAIL msg propagate. */
            random() % 500; /* Random delay between 0 and 500 milliseconds. */
        server.cluster-&gt;failover_auth_count = 0;
        server.cluster-&gt;failover_auth_sent = 0;
        server.cluster-&gt;failover_auth_rank = clusterGetSlaveRank();
        /* We add another delay that is proportional to the slave rank.
         * Specifically 1 second * rank. This way slaves that have a probably
         * less updated replication offset, are penalized.
         * */
        server.cluster-&gt;failover_auth_time +=
            server.cluster-&gt;failover_auth_rank * 1000;
        if (server.cluster-&gt;mf_end) {server.cluster-&gt;failover_auth_time = mstime();
            server.cluster-&gt;failover_auth_rank = 0;
        }
        // ...
        clusterBroadcastPong(CLUSTER_BROADCAST_LOCAL_SLAVES);
        return;
    }
    // ...
}
</code></pre><p>满足条件（<strong>auth_age &gt; auth_retry_time</strong>）后，发起故障转移流程。<br> 首先设置故障转移发起时刻，即设置 failover_auth_time 时间。</p><pre><code class="language-c">mstime() + 500 + random()%500 + rank*1000
</code></pre><p>固定延时 500ms 是为了让 master fail 的消息能够广泛传播到集群，这样集群中的其他节点才可能投票。<br> 随机延时是为了避免多个你 slave 节点同时发起 failover 流程。<br> rank 表示 slave 节点的排名，计算方式如下，</p><pre><code class="language-c">int clusterGetSlaveRank(void) {
    long long myoffset;
    int j, rank = 0;
    clusterNode *master;

    serverAssert(nodeIsSlave(myself));
    master = myself-&gt;slaveof;
    if (master == NULL) return 0; /* Never called by slaves without master. */

    myoffset = replicationGetSlaveOffset();
    for (j = 0; j &lt; master-&gt;numslaves; j++)
        if (master-&gt;slaves[j] != myself &amp;&amp;
            master-&gt;slaves[j]-&gt;repl_offset &gt; myoffset) rank++;
    return rank;
}
</code></pre><p>可以看出，排名主要是根据复制数据量来定，复制数据量越多，排名越靠前（rank 值越小）。这样做是为了做 failover 时尽量选择一个复制数据量较多的 slave，以尽最大努力保留数据。在没有开始拉选票之前，<strong>每隔一段时间</strong> （每次调用<code>clusterHandleSlaveFailover</code> 函数，也就是每次 cron 的时间）就会调用一次 <code>clusterGetSlaveRank</code> 函数，以更新当前 slave 节点的排名。</p><p><strong>注意</strong>，如果是 mf，那么 failover_auth_time 和 failover_auth_rank 都置为 0，表示该 slave 节点现在就可以执行故障转移。</p><p>最后向该 master 的所有 slave 广播 PONG 消息，主要是为了更新复制偏移量，以便其他 slave 计算出 failover 时间点。<br> 这时，函数返回，就此开始了一轮新的故障转移，当已经处在某一轮故障转移时，执行接下来的逻辑。</p><h4 id="2-1-3-slave- 拉选票">2.1.3 slave 拉选票</h4><p>首先对于一些不合理的 failover 要过滤掉。</p><pre><code class="language-c">/* Return ASAP if we can't still start the election.
 */
if (mstime() &lt; server.cluster-&gt;failover_auth_time) {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_WAITING_DELAY);
    return;
}

/* Return ASAP if the election is too old to be valid.
 * failover 超时
 */
if (auth_age &gt; auth_timeout) {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_EXPIRED);
    return;
}
</code></pre><p>然后开始拉选票。</p><pre><code class="language-c">if (server.cluster-&gt;failover_auth_sent == 0) {
    server.cluster-&gt;currentEpoch++; // 增加当前节点的 currentEpoch 的值，表示要开始新一轮选举了
    server.cluster-&gt;failover_auth_epoch = server.cluster-&gt;currentEpoch;
    serverLog(LL_WARNING,&quot;Starting a failover election for epoch %llu.&quot;,
              (unsigned long long) server.cluster-&gt;currentEpoch);

    /* 向所有节点发送 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，开始拉票 */
    clusterRequestFailoverAuth();
    server.cluster-&gt;failover_auth_sent = 1; // 表示已经发起了故障转移流程
    clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG|
                         CLUSTER_TODO_UPDATE_STATE|
                         CLUSTER_TODO_FSYNC_CONFIG);
    return; /* Wait for replies. */
}
</code></pre><p>如果 <strong>failover_auth_sent</strong> 为 0，表示没有发起过投票，那么将 currentEpoch 加 1，记录 failover_auth_epoch 为 currentEpoch，函数 <code>clusterRequestFailoverAuth</code> 用来发起投票，failover_auth_sent 置 1，表示该 slave 已经发起过投票了。</p><pre><code class="language-c">void clusterRequestFailoverAuth(void) {unsigned char buf[sizeof(clusterMsg)];
    clusterMsg *hdr = (clusterMsg*) buf;
    uint32_t totlen;

    clusterBuildMessageHdr(hdr,CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST);
    /* If this is a manual failover, set the CLUSTERMSG_FLAG0_FORCEACK bit
     * in the header to communicate the nodes receiving the message that
     * they should authorized the failover even if the master is working. */
    if (server.cluster-&gt;mf_end) hdr-&gt;mflags[0] |= CLUSTERMSG_FLAG0_FORCEACK;
    totlen = sizeof(clusterMsg)-sizeof(union clusterMsgData);
    hdr-&gt;totlen = htonl(totlen);
    clusterBroadcastMessage(buf,totlen);
}
</code></pre><p><code>clusterRequestFailoverAuth</code> 函数向集群广播 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</strong> 类型的 gossip 信息，这类型的信息就是向集群中的 master 节点索要本轮选举中的选票。另外，如果是 mf，那么会在 gossip hdr 中带上 <strong>CLUSTERMSG_FLAG0_FORCEACK</strong> 信息。</p><h4 id="2-1-4- 其他 -master- 投票">2.1.4 其他 master 投票</h4><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST) {if (!sender) return 1;  /* We don't know that node. */
    clusterSendFailoverAuthIfNeeded(sender,hdr);
}
</code></pre><p>在 <code>clusterProcessPacket</code> 函数中处理 gossip 消息，当接收到 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</strong> 类型的消息时，调用 <code>clusterSendFailoverAuthIfNeeded</code> 函数处理，在满足条件的基础上，给 sender 投票。</p><p>注：以下若不进行特殊说明，都是 <code>clusterSendFailoverAuthIfNeeded</code> 函数处理逻辑。</p><h5 id="2-1-4-1- 筛掉没资格投票的节点">2.1.4.1 筛掉没资格投票的节点</h5><pre><code class="language-c"> if (nodeIsSlave(myself) || myself-&gt;numslots == 0) return;
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> slave 节点或者不负责 slot 的 master 节点</p><h5 id="2-1-4-2- 筛掉不需要投票的 -sender">2.1.4.2 筛掉不需要投票的 sender</h5><pre><code class="language-c">uint64_t requestCurrentEpoch = ntohu64(request-&gt;currentEpoch);
if (requestCurrentEpoch &lt; server.cluster-&gt;currentEpoch) {
    serverLog(LL_WARNING,
              &quot;Failover auth denied to %.40s: reqEpoch (%llu) &lt; curEpoch(%llu)&quot;,
              node-&gt;name,
              (unsigned long long) requestCurrentEpoch,
              (unsigned long long) server.cluster-&gt;currentEpoch);
    return;
}
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> sender 节点集群信息过旧。<br> 正常来说，如果 receiver 在接收到 sender 的 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息之前接收了 PING/PONG 消息，会更新自己的 currentEpoch，这时 currentEpoch 会增加，因为 sender 发起选举之前，会先增加自身的 currentEpoch；否则的话，receiver 的 currentEpoch 应该小于 sender。因此 sender 的 currentEpoch 应该 <strong>&gt;=</strong> receiver 的。有可能 sender 是个长时间下线的节点刚刚上线，这样的节点不能给他投票，因为它的集群信息过旧。</p><pre><code class="language-c">if (server.cluster-&gt;lastVoteEpoch == server.cluster-&gt;currentEpoch) {
    serverLog(LL_WARNING,
              &quot;Failover auth denied to %.40s: already voted for epoch %llu&quot;,
              node-&gt;name,
              (unsigned long long) server.cluster-&gt;currentEpoch);
    return;
}
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> receiver 节点在本轮选举中已经投过票了，避免两个 slave 节点同时赢得本界选举。<br> lastVoteEpoch 记录了在本轮投票中 receiver 投过票的 sender 的 currentEpoch。各 slave 节点独立发起选举，currentEpoch 是相同的，都在原来的基础上加 1。</p><pre><code class="language-c">clusterNode *master = node-&gt;slaveof;
if (nodeIsMaster(node) || master == NULL || (!nodeFailed(master) &amp;&amp; !force_ack))
{if (nodeIsMaster(node)) {
        serverLog(LL_WARNING,
                  &quot;Failover auth denied to %.40s: it is a master node&quot;,
                  node-&gt;name);
    } else if (master == NULL) {
        serverLog(LL_WARNING,
                  &quot;Failover auth denied to %.40s: I don't know its master&quot;,
                  node-&gt;name);
    } else if (!nodeFailed(master)) {
        serverLog(LL_WARNING,
                  &quot;Failover auth denied to %.40s: its master is up&quot;,
                  node-&gt;name);
    }
    return;
}
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> sender 是个 master。<br><i class="fa fa-times" aria-hidden="true"></i> sender 是个没有 master 的 slave。<br><i class="fa fa-times" aria-hidden="true"></i> sender 的 master 没有 fail，且不是个 mf。</p><pre><code class="language-c">if (mstime() - node-&gt;slaveof-&gt;voted_time &lt; server.cluster_node_timeout * 2)
{
    serverLog(LL_WARNING,
              &quot;Failover auth denied to %.40s: &quot;
              &quot;can't vote about this master before %lld milliseconds&quot;,
              node-&gt;name,
              (long long) ((server.cluster_node_timeout*2) - (mstime() - node-&gt;slaveof-&gt;voted_time)));
    return;
}
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> 两次投票时间间隔 <strong>不能少于 2 倍 的 cluster_node_timeout</strong>。<br> 这个裕量时间，使得获得赢得选举的 slave 将新的主从关系周知集群其他节点，避免其他 slave 发起新一轮的投票。</p><pre><code class="language-c">uint64_t requestConfigEpoch = ntohu64(request-&gt;configEpoch);
unsigned char *claimed_slots = request-&gt;myslots;
for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (bitmapTestBit(claimed_slots, j) == 0) continue;
    if (server.cluster-&gt;slots[j] == NULL ||
        server.cluster-&gt;slots[j]-&gt;configEpoch &lt;= requestConfigEpoch)
    {continue;}
    /* If we reached this point we found a slot that in our current slots
         * is served by a master with a greater configEpoch than the one claimed
         * by the slave requesting our vote. Refuse to vote for this slave. */
    serverLog(LL_WARNING,
              &quot;Failover auth denied to %.40s: &quot;
              &quot;slot %d epoch (%llu) &gt; reqEpoch (%llu)&quot;,
              node-&gt;name, j,
              (unsigned long long) server.cluster-&gt;slots[j]-&gt;configEpoch,
              (unsigned long long) requestConfigEpoch);
    return;
}
</code></pre><p><i class="fa fa-times" aria-hidden="true"></i> sender 节点声称要接管的 slots，在 receiver 节点看来其中有个别 slot 原来负责节点的 configEpoch 要比 sender 的大，这说明 sender 看到的集群消息太旧了，这可能是一个长时间下线又重新上线的节点。</p><h5 id="2-1-4-3- 在本轮选举投票">2.1.4.3 在本轮选举投票</h5><pre><code class="language-c">clusterSendFailoverAuth(node);
server.cluster-&gt;lastVoteEpoch = server.cluster-&gt;currentEpoch;
node-&gt;slaveof-&gt;voted_time = mstime(); // 更新投票时间
</code></pre><p><code>clusterSendFailoverAuth</code> 函数中发送 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</strong> 类型的 gossip 消息，这就算在本轮选举中投票了，并记录本轮投票的 epoch 以及投票时间。</p><h4 id="2-1-5-slave- 统计选票">2.1.5 slave 统计选票</h4><p>slave 接收到 <strong>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</strong> 类型的 gossip 消息，就算统计到一票。</p><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK) { // slave 统计票数
    if (!sender) return 1;  /* We don't know that node. */
    /* We consider this vote only if the sender is a master serving
         * a non zero number of slots, and its currentEpoch is greater or
         * equal to epoch where this node started the election. */
    if (nodeIsMaster(sender) &amp;&amp; sender-&gt;numslots &gt; 0 &amp;&amp;
        senderCurrentEpoch &gt;= server.cluster-&gt;failover_auth_epoch)
    {
        server.cluster-&gt;failover_auth_count++;
        /* Maybe we reached a quorum here, set a flag to make sure
             * we check ASAP. */
        clusterDoBeforeSleep(CLUSTER_TODO_HANDLE_FAILOVER);
    }
}
</code></pre><p>sender 是个负责 slot 的 master 并且满足 currentEpoch 的要求，那么这张选票有效。出现 <code>senderCurrentEpoch &lt; server.cluster-&gt;failover_auth_epoch</code> 的情况时有可能的，如果这张选票是上一轮选举的获得选票，就不能作数。<br> failover_auth_count 变量中记录了 slave 在本轮选举中获得选票数目。</p><h4 id="2-1-6-slave- 做主从切换">2.1.6 slave 做主从切换</h4><pre><code class="language-c">void clusterHandleSlaveFailover(void) {
    // ...
    int needed_quorum = (server.cluster-&gt;size / 2) + 1;
    if (server.cluster-&gt;failover_auth_count &gt;= needed_quorum) {
        /* We have the quorum, we can finally failover the master. */
        serverLog(LL_WARNING,
                  &quot;Failover election won: I'm the new master.&quot;);

        /* Update my configEpoch to the epoch of the election. */
        if (myself-&gt;configEpoch &lt; server.cluster-&gt;failover_auth_epoch) {
            myself-&gt;configEpoch = server.cluster-&gt;failover_auth_epoch;
            serverLog(LL_WARNING,
                      &quot;configEpoch set to %llu after successful failover&quot;,
                      (unsigned long long) myself-&gt;configEpoch);
        }

        /* Take responsability for the cluster slots. */
        clusterFailoverReplaceYourMaster();} else {clusterLogCantFailover(CLUSTER_CANT_FAILOVER_WAITING_VOTES);
    }
}
</code></pre><p>slave 节点获得足够多选票后， 成为新的 master 节点。<br> 更新自己的 configEpoch 为 <strong>选举协商</strong> 的 failover_auth_epoch，这是本节点就获得了最新当前集群最大的 configEpoch，表明它看到的集群信息现在是最新的。<br> 最后调用 <code>clusterFailoverReplaceYourMaster</code> 函数取代下线主节点，成为新的主节点，并向其他节点广播这种变化。</p><pre><code class="language-c">void clusterFailoverReplaceYourMaster(void) {
    int j;
    clusterNode *oldmaster = myself-&gt;slaveof;

    if (nodeIsMaster(myself) || oldmaster == NULL) return;

    /* 1) Turn this node into a master. */
    /* 把 myself 标记为 master，并从原 master 里删掉，更新原 master 的涉及 slave 的参数，
     * 如果 slave 数量为 0, 去掉它的 CLUSTER_NODE_MIGRATE_TO 标记
     */
    clusterSetNodeAsMaster(myself);

    /* 取消主从复制过程，将当前节点升级为主节点 *、
    replicationUnsetMaster();

    /* 2) Claim all the slots assigned to our master.
     * 接手老的 master 节点负责的槽位
     */
    for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (clusterNodeGetSlotBit(oldmaster,j)) {clusterDelSlot(j);
            clusterAddSlot(myself,j);
        }
    }

    /* 3) Update state and save config. */
    clusterUpdateState();
    clusterSaveConfigOrDie(1);

    /* 4) Pong all the other nodes so that they can update the state
     *    accordingly and detect that we switched to master role. */
    clusterBroadcastPong(CLUSTER_BROADCAST_ALL);

    /* 5) If there was a manual failover in progress, clear the state. */
    resetManualFailover();}
</code></pre><p>进行必要的 flag 设置和 slots 交接，向集群广播 PONG 消息，并进行善后处理。</p><h4 id="2-1-7- 集群其他节点感知主从变化">2.1.7 集群其他节点感知主从变化</h4><pre><code class="language-c">if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_PONG || type == CLUSTERMSG_TYPE_MEET) {
    // ...
    /* Check for role switch: slave -&gt; master or master -&gt; slave. */
    if (sender) {if (!memcmp(hdr-&gt;slaveof, CLUSTER_NODE_NULL_NAME, sizeof(hdr-&gt;slaveof)))
        {
            /* Node is a master. set master flag for sender */
            clusterSetNodeAsMaster(sender);
        }
        // ...
    }
    clusterNode *sender_master = NULL; /* Sender or its master if slave. */
    int dirty_slots = 0; /* Sender claimed slots don't match my view? */

    if (sender) {sender_master = nodeIsMaster(sender) ? sender : sender-&gt;slaveof;
        if (sender_master) {dirty_slots = memcmp(sender_master-&gt;slots, hdr-&gt;myslots, sizeof(hdr-&gt;myslots)) != 0;
        }
    }

    if (sender &amp;&amp; nodeIsMaster(sender) &amp;&amp; dirty_slots)
        clusterUpdateSlotsConfigWith(sender,senderConfigEpoch,hdr-&gt;myslots);
    // ...
}
</code></pre><p>集群中其他节点接收到 PONG 消息后，对 sender 进行正确的 role 标记，以某节点 D 为例。<br> 对于刚刚做完故障转移的 slave，也即现在 master，在节点 D 看来它负责的 slot 是空的，所以 dirty_slots 为 1。<br> 之后调用 <code>clusterUpdateSlotsConfigWith</code> 函数处理 slots 的 dirty diff 信息。</p><p>至此 failover 的逻辑就已经基本完成。</p><h3 id="2-2- 主动 -failover">2.2 主动 failover</h3><p>除了上面的发现故障后集群自动 failover，也可以进行主动的主从切换。</p><h4 id="2-2-1-slave- 节点接受 -cluster-failover- 命令">2.2.1 slave 节点接受 cluster failover 命令</h4><p>主动 failover 是通过 redis 命令实现的，命令格式为 <code>CLUSTER FAILOVER [FORCE|TAKEOVER]</code>，该命令使用详情可以参考这篇 <a href="http://www.redis.cn/commands/cluster-failover.html" target="_blank" rel="noopener">文档</a>。</p><pre><code class="language-c">#define CLUSTER_MF_TIMEOUT 5000
else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,&quot;failover&quot;) &amp;&amp; (c-&gt;argc == 2 || c-&gt;argc == 3)){/* CLUSTER FAILOVER [FORCE|TAKEOVER] */
    int force = 0, takeover = 0;

    if (c-&gt;argc == 3) {
        /* 不与 master 沟通，主节点也不会阻塞其客户端，需要经过选举 */
        if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,&quot;force&quot;)) {
            force = 1;
        /* 不与 master 沟通，不经过选举 */
        } else if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,&quot;takeover&quot;)) {
            takeover = 1;
            force = 1; /* Takeover also implies force. */
        /* 与 master 沟通，需要经过选举 */
        } else {addReply(c,shared.syntaxerr);
            return;
        }
    }
    // ...
    server.cluster-&gt;mf_end = mstime() + CLUSTER_MF_TIMEOUT; // mf 的超时时间为 5s}
</code></pre><p>cluster failover 命令有三种不同的选项，各有不同的含义，如上面注释所说。takeover 变量标记是否要经过选举， force 变量标记是否需要与 master 沟通。<br> 另外，mf 过程有一个过期时间，目前定义为 5s，同时， mf_end 也表示现在正在做 mf。<br> 不同的选项有不同的处理方式，如下，</p><pre><code class="language-c">if (takeover) {
    // takeover 不会做任何初始化校验。
    // 不经过其他节点选举协商，直接将该节点的 current epoch 加 1，然后广播这个新的配置
    serverLog(LL_WARNING,&quot;Taking over the master (user request).&quot;);
    clusterBumpConfigEpochWithoutConsensus();
    clusterFailoverReplaceYourMaster();} else if (force) {
    /* If this is a forced failover, we don't need to talk with our
     * master to agree about the offset. We just failover taking over
     * it without coordination. */
    serverLog(LL_WARNING,&quot;Forced failover user request accepted.&quot;);
    server.cluster-&gt;mf_can_start = 1;// 可以直接开始选举过程
} else {serverLog(LL_WARNING,&quot;Manual failover user request accepted.&quot;);
    clusterSendMFStart(myself-&gt;slaveof); // 发送带有 CLUSTERMSG_TYPE_MFSTART 标记的 gossip 包 (只有消息头) 给我的 master
}
</code></pre><p>takeover 方式最为粗暴，slave 节点不发起选举，而是直接将自己升级为 master，接手原主节点的槽位，增加自己的 configEpoch 后更新配置。<code>clusterFailoverReplaceYourMaster</code> 的逻辑在前面讲过，只有在本轮选举中获得足够多的选票才会调用该函数。<br> force 方式表示可以直接开始选举过程，选举过程也在前面说过了。<br> 现在来看看默认方式，处理逻辑为 <code>clusterSendMFStart</code> 函数。该函数主要逻辑就是发送向要做 failover 的 slave 的 master 发送 <code>CLUSTERMSG_TYPE_MFSTART</code> 类型的 gossip 消息。</p><h4 id="2-2-2-master- 节点做 -mf- 准备">2.2.2 master 节点做 mf 准备</h4><pre><code class="language-c">else if (type == CLUSTERMSG_TYPE_MFSTART) {
    /* This message is acceptable only if I'm a master and the sender
     * is one of my slaves. */
    if (!sender || sender-&gt;slaveof != myself) return 1;
    /* Manual failover requested from slaves.
     * Initialize the state accordingly.
     * master 收到消息，重置 mf 状态
     */
    resetManualFailover();
    server.cluster-&gt;mf_end = mstime() + CLUSTER_MF_TIMEOUT;
    server.cluster-&gt;mf_slave = sender;
    pauseClients(mstime()+(CLUSTER_MF_TIMEOUT*2)); // 阻塞客户端 10s
    serverLog(LL_WARNING,&quot;Manual failover requested by slave %.40s.&quot;,
              sender-&gt;name);
}
</code></pre><p><code>resetManualFailover</code> 函数中重置与 mf 相关的参数，表示这是一次新的 mf。<br> 设置 mf_end，将它的 master 指向 sender（就是那个搞事情的 slave），同时阻塞 client 10s 钟。<br> 随后，标记在做 mf 的 master 发送 PING 信息时 hdr 会带上 <strong>CLUSTERMSG_FLAG0_PAUSED</strong> 标记。</p><pre><code class="language-c">void clusterBuildMessageHdr(clusterMsg *hdr, int type) {
    // ...
      /* Set the message flags. */
    if (nodeIsMaster(myself) &amp;&amp; server.cluster-&gt;mf_end)
        hdr-&gt;mflags[0] |= CLUSTERMSG_FLAG0_PAUSED;
    // ...
}
</code></pre><p>mflags 记录与 mf 相关的 flag。</p><h4 id="2-2-3-slave- 处理">2.2.3 slave 处理</h4><h5 id="2-2-3-1- 获得 -master- 的 -repl-offset">2.2.3.1 获得 master 的 repl offset</h5><p>slave 节点处理带有 <strong>CLUSTERMSG_FLAG0_PAUSED</strong> 标记的 gossip 消息。</p><pre><code class="language-c">int clusterProcessPacket(clusterLink *link) {
    // ...
    sender = clusterLookupNode(hdr-&gt;sender);
    if (sender &amp;&amp; !nodeInHandshake(sender)) {
        // ...
        if (server.cluster-&gt;mf_end &amp;&amp; // 处于 mf 状态
            nodeIsSlave(myself) &amp;&amp;   // 我是 slave
            myself-&gt;slaveof == sender &amp;&amp; // 我的 master 是 sender
            hdr-&gt;mflags[0] &amp; CLUSTERMSG_FLAG0_PAUSED &amp;&amp;
            server.cluster-&gt;mf_master_offset == 0) // 还没有正式开始时，mf_master_offset 设置为 0
        {
            server.cluster-&gt;mf_master_offset = sender-&gt;repl_offset; // 从 sender 获得 repl_offset
            serverLog(LL_WARNING,
                      &quot;Received replication offset for paused &quot;
                      &quot;master manual failover: %lld&quot;,
                      server.cluster-&gt;mf_master_offset);
        }
    }
    // ...
}
</code></pre><p>对于那个发起 failover 的 slave，记下其 master 的 repl_offset，如果之前还没有记录下的话。</p><h5 id="2-2-3-2- 向 -maser- 追平 -repl-offset">2.2.3.2 向 maser 追平 repl offset</h5><pre><code class="language-c">void clusterCron(void) {
    // ...
    if (nodeIsSlave(myself)) {clusterHandleManualFailover();
        // ...
    }
    // ...
}

void clusterHandleManualFailover(void) {
    /* Return ASAP if no manual failover is in progress. */
    if (server.cluster-&gt;mf_end == 0) return;

    /* If mf_can_start is non-zero, the failover was already triggered so the
     * next steps are performed by clusterHandleSlaveFailover(). */
    if (server.cluster-&gt;mf_can_start) return;

    if (server.cluster-&gt;mf_master_offset == 0) return; /* Wait for offset... */

    if (server.cluster-&gt;mf_master_offset == replicationGetSlaveOffset()) {
        /* Our replication offset matches the master replication offset
         * announced after clients were paused. We can start the failover. */
        server.cluster-&gt;mf_can_start = 1;
        serverLog(LL_WARNING,
                  &quot;All master replication stream processed, &quot;
                  &quot;manual failover can start.&quot;);
    }
}
</code></pre><p>在 <code>clusterCron</code> 函数里有 <code>clusterHandleManualFailover</code> 的逻辑。<br> mf_end 为 0，说明此时没有 mf 发生。<br> mf_can_start 非 0 值，表示现在可以此 slave 可以发起选举了。<br> mf_master_offset 为 0，说明现在还没有获得 master 的复制偏移量，需要等一会儿。当 mf_master_offset 值等于 <code>replicationGetSlaveOffset</code> 函数的返回值时，把 mf_can_start 置为 1。另外，应该记得，使用带有 force 选项的 <code>CLUSTER FAILOVER</code> 命令，直接就会把 mf_can_start 置为 1，而 <code>replicationGetSlaveOffset</code> 函数的作用就是检查当前的主从复制偏移量，也就是说主从复制偏移量一定要达到 mf_master_offset 时，slave 才会发起选举，即默认选项有一个追平 repl offset 的过程。</p><p>其他一些选举什么的流程跟被动 failover 没有区别。</p><h4 id="2-2-4- 过期清理 -mf">2.2.4 过期清理 mf</h4><p>主从节点在周期性的<code>clusterCron</code> 中都有一个检查本次 mf 是否过期的函数。</p><pre><code class="language-c">void manualFailoverCheckTimeout(void) {if (server.cluster-&gt;mf_end &amp;&amp; server.cluster-&gt;mf_end &lt; mstime()) {serverLog(LL_WARNING,&quot;Manual failover timed out.&quot;);
        resetManualFailover();}
}

void resetManualFailover(void) {if (server.cluster-&gt;mf_end &amp;&amp; clientsArePaused()) {
        server.clients_pause_end_time = 0;
        clientsArePaused(); /* Just use the side effect of the function. */}
    server.cluster-&gt;mf_end = 0; /* No manual failover in progress. */
    server.cluster-&gt;mf_can_start = 0;
    server.cluster-&gt;mf_slave = NULL;
    server.cluster-&gt;mf_master_offset = 0;
}
</code></pre><p>如果过期没有做 mf ，那么就会重置它的相关参数。</p><h2 id="3- 附录">3. 附录</h2><h3 id="3-1-epoch- 概念">3.1 epoch 概念</h3><p>在 Redis cluster 里 epoch 是个非常重要的概念，类似于 raft 算法中的 term 概念。Redis cluster 里主要是两种：currentEpoch 和 configEpoch。</p><h4 id="3-1-1-currentEpoch">3.1.1 currentEpoch</h4><blockquote><p>这是一个集群状态相关的概念，可以当做记录集群状态变更的递增版本号。每个集群节点，都会通过 server.cluster-&gt;currentEpoch 记录当前的 currentEpoch。</p><p>集群节点创建时，不管是主节点还是从节点，都置 currentEpoch 为 0。当前节点接收到来自其他节点的包时，如果发送者的 currentEpoch（消息头部会包含发送者的 currentEpoch）大于当前节点的 currentEpoch，那么当前节点会更新 currentEpoch 为发送者的 currentEpoch。因此，集群中所有节点的 currentEpoch 最终会达成一致，相当于对集群状态的认知达成了一致。</p></blockquote><p>currentEpoch 作用在于，集群状态发生改变时，某节点会先增加自身 currentEpoch 的值，然后向集群中其他节点征求同意，以便执行某些动作。目前，仅用于 slave 节点的故障转移流程，在上面分析中也看到了，在发起选举之前，slave 会增加自己的 currentEpoch，并且得到的 currentEpoch 表示这一轮选举的 voteEpoch，当获得了足够多的选票后才会执行故障转移。</p><h4 id="3-1-2-configEpoch">3.1.2 configEpoch</h4><blockquote><p>这是一个集群节点配置相关的概念，每个集群节点都有自己独一无二的 configepoch。所谓的节点配置，实际上是指节点所负责的 slot 信息。</p></blockquote><p>configEpoch 主要用于解决不同的节点就 slot 归属认知发生冲突的情况。公说公有理婆说婆有理，到底听谁的，configEpoch 越大，看到的集群节点配置信息越新，就越有话语权。对于冲突的情况，后面会有博客进行详细分析。</p><p>以下几种情况 configEpoch 会更新：</p><ol><li>新节点加入；</li><li>槽节点映射冲突检测；（slot 归属变更）</li><li>从节点投票选举冲突检测。(主从切换)</li></ol><p>递增 node epoch 称为 bump epoch。关于 configEpoch 有三个原则：</p><ol><li>如果 epoch 不变, 集群就不应该有变更(包括选举和迁移槽位)。</li><li>每个节点的 node epoch 都是独一无二的。</li><li>拥有越高 epoch 的节点, 集群信息越新。</li></ol><h3 id="3-2-clusterUpdateState- 函数逻辑">3.2 clusterUpdateState 函数逻辑</h3><pre><code class="language-c">#define CLUSTER_MAX_REJOIN_DELAY 5000
#define CLUSTER_MIN_REJOIN_DELAY 500
#define CLUSTER_WRITABLE_DELAY 2000
void clusterUpdateState(void) {
    // ...
    static mstime_t among_minority_time;
    static mstime_t first_call_time = 0;
    server.cluster-&gt;todo_before_sleep &amp;= ~CLUSTER_TODO_UPDATE_STATE;

    /* 时间从第一次调用该函数算起，是为了跳过 DB load 时间。
     * cluster 启动时，状态为 CLUSTER_FAIL，
     * 这里要等待一定的时间 (2s) 让 cluster 变为 CLUSTER_OK 状态。
     */
    if (first_call_time == 0) first_call_time = mstime();
    if (nodeIsMaster(myself) &amp;&amp;
        server.cluster-&gt;state == CLUSTER_FAIL &amp;&amp;
        mstime() - first_call_time &lt; CLUSTER_WRITABLE_DELAY) return;

    /* 先假设集群状态为 CLUSTER_OK，
     * 然后遍历 16384 个 slot，如果发现有 slot 被有被接管，
     * 或者接管某 slot 的 node 是 fail 状态，那么把集群设置为 CLUSTER_FAIL，退出循环
     */
    new_state = CLUSTER_OK;
    if (server.cluster_require_full_coverage) {for (j = 0; j &lt; CLUSTER_SLOTS; j++) {if (server.cluster-&gt;slots[j] == NULL ||
                server.cluster-&gt;slots[j]-&gt;flags &amp; (CLUSTER_NODE_FAIL))
            {
                new_state = CLUSTER_FAIL;
                break;
            }
        }
    }
    {
       /* 计算 cluster size，计数的是那些至少负责一个 slot 的 node
        * 计算 reachable_masters，计数基于 cluster size，
        * 加入筛选条件(不带有 CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL) 标记
        */
        dictIterator *di;
        dictEntry *de;
        server.cluster-&gt;size = 0;
        di = dictGetSafeIterator(server.cluster-&gt;nodes);
        while((de = dictNext(di)) != NULL) {clusterNode *node = dictGetVal(de);

            if (nodeIsMaster(node) &amp;&amp; node-&gt;numslots) {
                server.cluster-&gt;size++;
                if ((node-&gt;flags &amp; (CLUSTER_NODE_FAIL|CLUSTER_NODE_PFAIL)) == 0)
                    reachable_masters++;
            }
        }
        dictReleaseIterator(di);
    }
    {/* 如果 reachable_masters 不到 cluster size 一半(a minority partition)，
         * 就将集群标记为 CLUSTER_FAIL
         */
        int needed_quorum = (server.cluster-&gt;size / 2) + 1;
        if (reachable_masters &lt; needed_quorum) {
            new_state = CLUSTER_FAIL;
            among_minority_time = mstime();}
    }

    if (new_state != server.cluster-&gt;state) {
        mstime_t rejoin_delay = server.cluster_node_timeout;

        if (rejoin_delay &gt; CLUSTER_MAX_REJOIN_DELAY)
            rejoin_delay = CLUSTER_MAX_REJOIN_DELAY;
        if (rejoin_delay &lt; CLUSTER_MIN_REJOIN_DELAY)
            rejoin_delay = CLUSTER_MIN_REJOIN_DELAY;
        /* 处于 minority partition 的时间没有超过 cluster_node_timeout，
         * 那么此次不更新集群状态。
         */
        if (new_state == CLUSTER_OK &amp;&amp;
            nodeIsMaster(myself) &amp;&amp;
            mstime() - among_minority_time &lt; rejoin_delay)
        {return;}

        /* Change the state and log the event. */
        serverLog(LL_WARNING,&quot;Cluster state changed: %s&quot;,
            new_state == CLUSTER_OK ? &quot;ok&quot; : &quot;fail&quot;);
        server.cluster-&gt;state = new_state;
    }

</code></pre><h2 id="4- 参考">4. 参考</h2><p><i class="fa fa-link" aria-hidden="true"></i> <a href="https://blog.csdn.net/gqtcgq/article/details/51830428" target="_blank" rel="noopener">Redis 源码解析：27 集群 (三) 主从复制、故障转移</a></p></div><hr><div><p><span><i class="iconfont icon-inbox"></i> <a class="hover-with-bg" href="/categories/%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/">源码系列</a> &nbsp;</span> &nbsp;&nbsp;<span><i class="iconfont icon-tag"></i> <a class="hover-with-bg" href="/tags/redis/">redis</a></span></p><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p><div class="post-prevnext row"><div class="post-prev col-6"><a href="/1bcb9a09.html"><i class="fa fa-chevron-left"></i> <span class="hidden-mobile">Redigo 源码分析</span> <span class="visible-mobile">上一篇</span></a></div><div class="post-next col-6"> <a href="/d15eb256.html"><span class="hidden-mobile">Redis 持久化之 AOF 重写</span> <span class="visible-mobile">下一篇</span><i class="fa fa-chevron-right"></i></a></div></div></div><div class="comments" id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC8zNjg1MS8xMzM4Nw"><script type="text/javascript">!function(e,t){var r,n=e.getElementsByTagName(t)[0];"function"!=typeof LivereTower&&((r=e.createElement(t)).src="https://cdn-city.livere.com/js/embed.dist.js",r.defer=!0,n.parentNode.insertBefore(r,n))}(document,"script")</script><noscript> 为正常使用来必力评论功能请激活JavaScript</noscript></div></div></div></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc-start"></div><div id="toc"><p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div><div class="col-lg-7 mx-auto nopadding-md"><div class="container custom post-content mx-auto"> <img src="https://octodex.github.com/images/jetpacktocat.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-5" style="width:150px;height:150px"></div></div></main><a class="z-depth-1" id="scroll-top-button" href="#" role="button"><i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4> <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"> <span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"> <input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><footer class="mt-5"><div class="text-center py-3"><div> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a><i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><b>Fluid</b></a></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js"></script><script>$(document).ready(function(){var s=$("#navbar").height(),c=$("#toc"),t=$("#board-ctn"),o=t.offset().top,i=2*o+t.height();$(window).scroll(function(){var t=$("#toc-start").offset().top-s,o=document.body.scrollTop+document.documentElement.scrollTop;t<=o&&o<=i?c.css({display:"block",position:"fixed",top:s}):o<=t?c.css({position:"",top:""}):i<o&&c.css("display","none")}),tocbot.init({tocSelector:"#tocbot",contentSelector:".post-content",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,headingsOffset:-o}),0<$(".toc-list-item").length&&$("#toc > p").css("visibility","visible");var l=t.css("margin-right");$("#toc-ctn").css({right:l})})</script><script defer="defer" src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer="defer" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script defer="defer">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?882b48640075e00a238ae94a7eec0d40";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script defer="defer">var _mtac={};!function(){var t=document.createElement("script");t.src="//pingjs.qq.com/h5/stats.js?v2.0.4",t.setAttribute("name","MTAH5"),t.setAttribute("sid","");var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js"></script><script>$(document).ready(function(){$("pre").addClass("prettyprint  "),prettyPrint()})</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","Redis 源码之故障转移&nbsp;"],cursorChar:"_",typeSpeed:80,loop:!1});typed.stop(),$(document).ready(function(){$(".typed-cursor").addClass("h2"),typed.start()})</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){getSearchFile(path),this.onclick=null}</script><script defer="defer" src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><script>$("#post img:not(.no-zoom img, img[no-zoom])").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script></body></html>